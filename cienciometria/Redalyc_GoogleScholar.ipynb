{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uu-sf4Ukvbb-"
   },
   "source": [
    "# Google Scholar \n",
    "Try avoid robots by explicit clicking on the previously loaded \n",
    "page\n",
    "\n",
    "See: https://academia.stackexchange.com/q/2567\n",
    "\n",
    "Check for https://github.com/ckreibich/scholar.py/blob/master/scholar.py\n",
    "\n",
    "https://pypi.org/project/googletrans/\n",
    "\n",
    "See also: lookup fields:\n",
    "https://scholar.google.co.in/scholar_lookup?title=Estimates+for+the+number+of+sums+and+products+and+for+exponential+sums+in+fields+of+prime+order&author=Jean+Bourgain&author=AA+Glibichuk&author=SERGEI+VLADIMIROVICH+Konyagin&year=2006&doi=10.1112/S0024610706022721&publisher=Oxford+University+Press&journal=Journal+of+the+London+Mathematical+Society&volume=73&issue=2&pages=380-398&hl=en\n",
    "\n",
    "https://portal.ictp.it/icts/howto/proxy.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose between selenium or requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://scholar.google.com'\n",
    "CITES=False\n",
    "if CITES:\n",
    "    url=url+'/scholar?cites=16729892078990709043&as_sdt=2005&sciodt=0,5&hl=es'\n",
    "SELENIUM=False\n",
    "if SELENIUM:\n",
    "    #pip3 install webdriver_manager\n",
    "    from webdriver_manager.firefox import GeckoDriverManager\n",
    "    from selenium import webdriver\n",
    "    from pathlib import Path\n",
    "    home = str(Path.home())\n",
    "    try:\n",
    "        browser = webdriver.Firefox(executable_path=\n",
    "          '/home/restrepo/.wdm/geckodriver/v0.23.0/linux64/geckodriver')\n",
    "    except:\n",
    "        browser = webdriver.Firefox(\n",
    "            executable_path= GeckoDriverManager().install())\n",
    "    \n",
    "    browser.get(url)\n",
    "    #TODO: Authentication:\n",
    "    # Login page\n",
    "    # gs_hdr_act_s by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element_by_id(\"gs_hdr_act_s\").click()\n",
    "\n",
    "browser.find_element_by_id(\"identifierId\").clear()\n",
    "\n",
    "browser.find_element_by_id(\"identifierId\").send_keys(\"admin@fisica.udea.edu.co\")\n",
    "\n",
    "browser.find_element_by_class_name(\"RveJvd\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "password=getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_element_by_class_name(\"whsOnd\").send_keys(password)\n",
    "\n",
    "browser.find_element_by_class_name(\"RveJvd\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SELENIUM:\n",
    "    import requests\n",
    "    headers_Get = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:49.0) Gecko/20100101 Firefox/49.0',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'DNT': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1'\n",
    "        }\n",
    "    r=requests.Session()\n",
    "    browser=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import googlescholar as gs\n",
    "#%%writefile ../cienciometria/googlescholar.py\n",
    "import Levenshtein\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import scholarly\n",
    "\n",
    "def scholarly_to_gs(d):\n",
    "    if not d:\n",
    "        return d\n",
    "    gsr={}\n",
    "    try:\n",
    "        gsr['cites']=d.citedby\n",
    "        gsr['cites_link']=d.id_scholarcitedby\n",
    "    except AttributeError:\n",
    "        gsr['cites']=0\n",
    "        gsr['cites_link']=''\n",
    "    gsr['title']=d.bib.get('title')\n",
    "    gsr['ref']=d.bib.get('author').replace(' and',',')\n",
    "    gsr['authors']=gsr['ref'].split('-')[0].strip()\n",
    "    gsr['PDF']=d.bib.get('eprint')\n",
    "    \n",
    "    try:\n",
    "        jy=gsr['ref'].split('-')[1].strip()\n",
    "        gsr['Journal']=jy.split(',')[0]\n",
    "        try:\n",
    "            gsr['Year']=eval(jy.split(',')[1])\n",
    "        except:\n",
    "            gsr['Year']=-1\n",
    "    except:\n",
    "        gsr['Journal']=''\n",
    "\n",
    "    gsr['abstract']=d.bib.get('abstract')\n",
    "    return gsr\n",
    "\n",
    "def firefox_get(url,browser=browser):\n",
    "    try:\n",
    "        if browser:\n",
    "            if url.find('scholar_lookup?')==-1:\n",
    "                q=url.split('=')[-1]\n",
    "                browser.find_element_by_id(\"gs_hdr_tsi\").clear()\n",
    "                browser.find_element_by_id(\"gs_hdr_tsi\").send_keys(q)\n",
    "                browser.find_element_by_id('gs_hdr_tsb').click()\n",
    "            else:\n",
    "                browser.get(url)\n",
    "        else:\n",
    "            rget=r.get(url,headers=headers_Get)\n",
    "    except:\n",
    "        return 'FAILED'\n",
    "    \n",
    "    if browser:\n",
    "        html=browser.page_source\n",
    "    else:\n",
    "        html = rget.text\n",
    "    if html.lower().find('gs_captcha_f')>-1:\n",
    "        if browser:\n",
    "            input('check robots')\n",
    "        else:\n",
    "            sys.exit('ERROR: Captcha anti-robots requested!\\n Aborting execution.')\n",
    "    #if html.find('Sorry')>-1:\n",
    "    #    input('check sorry')\n",
    "\n",
    "    return html\n",
    "\n",
    "def get_google_scholar(record):\n",
    "    '''\n",
    "    Analyise the BeautifulSoup record for an article \n",
    "    in Google Scholar.\n",
    "    Output is a Python dictionary with keys: \n",
    "    'title', 'authors','profiles','Jornal','Year',\n",
    "    'abstract','cites','cites_link'\n",
    "    '''\n",
    "    import random\n",
    "    import time\n",
    "    gsr={}\n",
    "    try:\n",
    "        cites=record.find_all('a',{\"href\":re.compile( \"/scholar\\?cites=\" )})[0]\n",
    "        try:\n",
    "            gsr['cites']=int( cites.text.split()[-1] )\n",
    "            gsr['cites_link']=cites.attrs.get('href')\n",
    "        except:\n",
    "            gsr['cites']=0\n",
    "    except:\n",
    "        cites=None\n",
    "\n",
    "    # Title\n",
    "    try:\n",
    "        #The .split('XXX')[-1]  does not afect the result when .text does no contains 'XXX'\n",
    "        tc=record.find_all('h3',{\"class\":\"gs_rt\"})[0].text.split('[CITATION][C] ')[-1]\n",
    "    except:\n",
    "        tc=''\n",
    "\n",
    "    gsr['title']=tc.strip().split('[HTML][HTML] ')[-1].split(\n",
    "                                  '[PDF][PDF] '  )[-1]\n",
    "    \n",
    "    # Explore authors, google scholar profile - Journal, Year - Publisher\n",
    "    gpa=None\n",
    "    try:\n",
    "        gpa=record.find_all('div',{\"class\":\"gs_a\"})[0]\n",
    "        #Full ref with authors, google scholar profile - Journal, Year - Publisher\n",
    "        ref=gpa.text\n",
    "        gsr['ref']=ref.strip()\n",
    "        refparts=ref.split('\\xa0-')\n",
    "    except IndexError:\n",
    "        gsr['ref']=''\n",
    "        refparts=[]\n",
    "\n",
    "    try:\n",
    "        gsr['authors']=refparts[0]\n",
    "    except IndexError:    \n",
    "        gsr['authors']=''\n",
    "        \n",
    "    try:\n",
    "        journalparts=refparts[-1].strip().split(' - ')\n",
    "        gsr['publisher']=journalparts[-1]\n",
    "        gsr['Journal']=journalparts[0].split(',')[0]\n",
    "        gsr['Year']=journalparts[0].split(',')[-1].strip()\n",
    "    except IndexError:\n",
    "        gsr['publisher']=''\n",
    "        gsr['Journal']=''\n",
    "        gsr['Year']\n",
    "\n",
    "    #Abstract:\n",
    "    try:\n",
    "        gsr['abstract']=record.find_all('div',{'class':'gs_rs'})[0].text.replace('\\xa0…','')\n",
    "    except:\n",
    "        gsr['abstract']=''\n",
    "    # citations\n",
    "    if gpa:\n",
    "        lpr=gpa.find_all(\"a\",{ \"href\":re.compile(\"/citations\\?user=*\")   } )\n",
    "        prf={}\n",
    "        for pr in lpr:\n",
    "            prf[ pr.text ]=pr.attrs.get('href').split('?')[-1].split('&')[0].split('user=')[-1]\n",
    "        gsr['profiles']=prf\n",
    "    \n",
    "    time.sleep( random.randint(1,3)  ) # avoid robots\n",
    "    return gsr\n",
    "\n",
    "def request_google_scholar_url(url):\n",
    "    return requests.get(url)\n",
    "\n",
    "def google_scholar_page(html):\n",
    "    '''\n",
    "    Convert a Google Scholar page into a list\n",
    "    of dictionaries with metadata info\n",
    "    '''\n",
    "    if html.lower().find('gs_captcha_f')>-1:\n",
    "        input('check robots')\n",
    "   \n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    rgs=soup.find_all('div', {'class':'gs_ri' })\n",
    "\n",
    "    citations=[]\n",
    "    for record in rgs:\n",
    "        citations.append( get_google_scholar(record) )\n",
    "        \n",
    "    return citations\n",
    "\n",
    "def google_scholar_query(title='', author='', coauthors=[], DOI='', year=0, publisher='',\n",
    "                         journal='', volume='', issue='', pages=0,\n",
    "                         DEBUG=False,Scholarly=False):\n",
    "    '''\n",
    "    Search Google scholar with `sholar_lookup` full fields.\n",
    "    Only the first result is analized. The output includes \n",
    "    a quality measurements between the query and the results \n",
    "    Output is a Python dictionary with keys: \n",
    "    'title', 'authors','profiles','cites','cites_link',\n",
    "    'quality_title','quality_author'\n",
    "    '''\n",
    "    gs={}\n",
    "    # + → %2B in query formula:\n",
    "    baseurl='https://scholar.google.com/'\n",
    "    q='scholar_lookup?'\n",
    "    \n",
    "    nl=0\n",
    "    if title:\n",
    "        nl=nl+1\n",
    "        q= q+'title={}'.format(title.replace(' ','+'))\n",
    "    if author:\n",
    "        if nl: q= q+'&'\n",
    "        nl=nl+1\n",
    "        q= q+'author={}'.format(author.replace(' ','+'))\n",
    "    if DOI:\n",
    "        if nl: q= q+'&'\n",
    "        nl=nl+1    \n",
    "        q= q+'doi={}'.format(DOI)\n",
    "    if year:\n",
    "        if nl: q= q+'&'\n",
    "        nl=nl+1\n",
    "        q= q+'year={}'.format(year)\n",
    "    if publisher:\n",
    "        if nl: q= q+'&'\n",
    "        nl=nl+1\n",
    "        q= q+'publisher={}'.format(publisher.replace(' ','+'))\n",
    "    if journal:\n",
    "        if nl: q= q+'&'\n",
    "        nl=nl+1     \n",
    "        q= q+'journal={}'.format(journal.replace(' ','+'))\n",
    "    if volume:\n",
    "        if nl: q= q+'&'\n",
    "        nl=nl+1\n",
    "        q= q+'volume={}'.format(volume)\n",
    "    if issue:\n",
    "        if nl: q= q+'&'\n",
    "        nl=nl+1\n",
    "        q= q+'issue={}'.format(issue)   \n",
    "    if pages:\n",
    "        if nl: q= q+'&'\n",
    "        nl=nl+1\n",
    "        q= q+'pages={}'.format(pages)\n",
    "    if coauthors:\n",
    "        for i in coauthors :\n",
    "            if nl: q= q+'&'\n",
    "            nl=nl+1\n",
    "            q= q+'author={}'.format(i.replace(' ','+'))    \n",
    "    url=baseurl+q\n",
    "    if DEBUG:\n",
    "        print(url)   \n",
    "    \n",
    "    #s = requests.Session()\n",
    "    if not Scholarly:\n",
    "        rtext=firefox_get(url)\n",
    "\n",
    "        #soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        soup = BeautifulSoup(rtext, \"html.parser\")\n",
    "\n",
    "\n",
    "        # Main contents:\n",
    "        rgs=soup.find_all('div', {'class':'gs_ri' })\n",
    "\n",
    "        try:\n",
    "            record=rgs[0]\n",
    "        except IndexError:\n",
    "            #exit if record not found and returns empty dictionary\n",
    "            return gs\n",
    "    \n",
    "        gs.update(get_google_scholar(record))\n",
    "    else:\n",
    "        search_query = scholarly.search_pubs_query(q)\n",
    "\n",
    "        try:\n",
    "            d=next(search_query)\n",
    "        except StopIteration:\n",
    "            return {}     \n",
    "        gs=scholarly_to_gs(d)\n",
    "    \n",
    "    #Check if author is in authors list\n",
    "    if gs and author:\n",
    "        sau=0\n",
    "        for a in gs['authors'].split(','):\n",
    "            saun=Levenshtein.ratio(author.lower(),a.lower().strip())\n",
    "            if saun>sau:\n",
    "                sau=saun\n",
    "                \n",
    "        gs['quality_author']=round(sau,2)\n",
    "    else:\n",
    "        gs['quality_author']=-1 #-1 means not checked\n",
    "        \n",
    "    if gs and title:\n",
    "        gs['quality_title']=round( Levenshtein.ratio(\n",
    "                   title.lower(),gs['title'].lower() ),2 )\n",
    "    else:\n",
    "        gs['quality_title'] =-1 #-1 means not checked\n",
    "        \n",
    "    #EXTRA FIELDS:\n",
    "    #PDF\n",
    "    if not Scholarly:\n",
    "        try:\n",
    "            gs['PDF']=soup.find_all('div',\n",
    "                        {\"class\":\"gs_or_ggsm\"})[0].find_all('a')[0].get(\"href\")\n",
    "        except:\n",
    "            gs['PDF']=''\n",
    "\n",
    "    if DEBUG:\n",
    "        print('='*80)\n",
    "        print(record)\n",
    "        \n",
    "        return gs,record\n",
    "    else:\n",
    "        return gs\n",
    "\n",
    "def get_cites_refs(browser,url,maxcites=65,t=60):\n",
    "    import random\n",
    "    import time\n",
    "    url='https://scholar.google.com'+url\n",
    "    browser.get(url)\n",
    "     \n",
    "    endpage=int(maxcites/10)+1\n",
    "    refs=''\n",
    "    \n",
    "    kk=google_scholar_page( browser.page_source )\n",
    "    try:\n",
    "        refs=refs+'\\n'.join( list((pd.DataFrame(kk)['title']+'; '\n",
    "                                  +pd.DataFrame(kk)['ref']).values) )+'\\n' \n",
    "    except:\n",
    "        refs=''\n",
    "    \n",
    "    \n",
    "    for i in range(endpage):\n",
    "        try:\n",
    "            browser.find_element_by_class_name('gs_ico_nav_next').click()\n",
    "            kk=google_scholar_page( browser.page_source )\n",
    "            try:\n",
    "                refs=refs+'\\n'.join( list( (pd.DataFrame(kk)['title']+'; '\n",
    "                                +pd.DataFrame(kk)['ref']).values ) )+'\\n' \n",
    "            except:\n",
    "                refs=''\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    time.sleep(random.uniform(0.9*t,1.1*t))\n",
    "    return refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wosplus as wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting drive.cfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile drive.cfg\n",
    "[FILES]\n",
    "DOIS.xlsx               = 1bikNT7Gmp4G7dfeMuGsF-az7D8lskK0O\n",
    "UDEA_WOS_SCI_SCP.xlsx   = 1o9otmklgh-0w18Avv2ZTKOXr3vZbjwvj\n",
    "oaudea.xlsx             = 1CcwobiEFACIbffNzNdLxpdxQukr8cZ5x\n",
    "oaudea.json             = 1BmqRoQDgfpOFjXBVEfI999uaN6XX6Fkd\n",
    "datos1.csv              = 11CyLRZZwVbgw6YAC-igRJ3mrkIwk0aaiXnd-EOofYTI\n",
    "RedalycMetadatosArticulos.csv= #See Redalyc_GoogleScholar_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa=wp.wosplus('drive.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2901: DtypeWarning: Columns (6,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "oaudea=oa.read_drive_csv('RedalycMetadatosArticulos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oaudea=wp.fill_NaN(oaudea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629851, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oaudea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos=oaudea.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST START AFTER FINISH REDALYC\n",
    "nini=0# initial doi\n",
    "n=3000 # Total of DOIs\n",
    "nend=nini+n\n",
    "T=12 #hours of search\n",
    "t=T/n*3600 # [s] query time\n",
    "t=60\n",
    "day=24*3600 #s\n",
    "mintime=0.9*t*n # [s] minimal time search\n",
    "wait=30#day-mintime # maximum wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos=datos[datos.DOI!=''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REVISTA', 'INSTITUCION_REVISTA', 'PAIS_REVISTA', 'IDARTICULO',\n",
       "       'TITULO', 'Autor(es)', 'DOI', 'ANIO', 'VOLUMEN', 'NUMERO', 'PAGINAS',\n",
       "       'IDIOMA', 'RESUMEN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('10.4067/S0717-554X2017000100013',\n",
       " 'Ventajas del análisis sistémico aplicado a los espacios locales',\n",
       " 'Manuela Ortega ,M. Concepción Segovia ',\n",
       " [],\n",
       " 2017,\n",
       " 'Cinta de Moebio')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii=1\n",
    "(datos.loc[ii,'DOI'],\n",
    " datos.loc[ii,'TITULO'],\n",
    " datos.loc[ii,'Autor(es)'].split(', ')[0],\n",
    " datos.loc[ii,'Autor(es)'].split('\\n')[1:4],\n",
    " datos.loc[ii,'ANIO'],\n",
    " datos.loc[ii,'REVISTA'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18815, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=3000, step=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos[nini:n].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.loc[ii,'ANIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Journal': 'Cinta de moebio',\n",
       " 'PDF': 'https://scielo.conicyt.cl/scielo.php?pid=S0717-554X2017000100013&script=sci_arttext',\n",
       " 'Year': '2017',\n",
       " 'abstract': 'This paper shows how system analysis applied to local spaces facilitate the generation of proposals for integral development in the field of sustainability. Regions are composed of physical and social components generating products that benefit or harm themselves. These resources can be exploited or remained idle for lack of actors to develop them. They react to internal and external actions, both human and natural. Among these actions are the policies for local development. For these policies to be efficient, they need comprehensive studies',\n",
       " 'authors': 'M Ortega, MC Segovia',\n",
       " 'cites': 1,\n",
       " 'cites_link': '/scholar?cites=14403974261697570786&as_sdt=2005&sciodt=0,5&hl=en',\n",
       " 'profiles': {'M Ortega': 'GkYFaLMAAAAJ'},\n",
       " 'publisher': 'scielo.conicyt.cl',\n",
       " 'quality_author': 0.42,\n",
       " 'quality_title': 1.0,\n",
       " 'ref': 'M Ortega, MC Segovia\\xa0- Cinta de moebio, 2017 - scielo.conicyt.cl',\n",
       " 'title': 'Ventajas del análisis sistémico aplicado a los espacios locales'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "Scholarly=False\n",
    "doi='DOI'\n",
    "title_simple='TITULO'\n",
    "article_id='IDARTICULO'\n",
    "\n",
    "d=google_scholar_query(title=datos.loc[ii,title_simple],\n",
    "                    author=datos.loc[ii,'Autor(es)'].split(', ')[0],\n",
    "                    coauthors=datos.loc[ii,'Autor(es)'].split(', ')[1:4],\n",
    "                    DOI=datos.loc[ii,doi],\n",
    "                    year=datos.loc[ii,'ANIO'],\n",
    "                    journal=datos.loc[ii,'REVISTA'],Scholarly=Scholarly)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "Scholarly=False\n",
    "doi='DOI'\n",
    "title_simple='TITULO'\n",
    "article_id='IDARTICULO'\n",
    "dfgs=pd.DataFrame()\n",
    "ibrkn=0\n",
    "maxibrn=400\n",
    "\n",
    "for ii in datos[nini:n].index:\n",
    "    print(ii,datos.loc[ii,doi])\n",
    "    #gsd=google_scholar_query(DOI=doi)\n",
    "    gsd=google_scholar_query(title=datos.loc[ii,title_simple],\n",
    "                    author=datos.loc[ii,'Autor(es)'].split(', ')[0],\n",
    "                    coauthors=datos.loc[ii,'Autor(es)'].split(', ')[1:4],\n",
    "                    DOI=datos.loc[ii,doi],\n",
    "                    year=datos.loc[ii,'ANIO'],\n",
    "                    journal=datos.loc[ii,'REVISTA'],Scholarly=Scholarly )\n",
    "            \n",
    "    gsd['old_title']=datos.loc[ii,'TITULO']\n",
    "    gsd['DOI']=datos.loc[ii,'DOI']\n",
    "    gsd['ID_ARTICLE']=datos.loc[ii,article_id]\n",
    "    dfgs=dfgs.append(gsd,ignore_index=True )\n",
    "    dfgs.to_json('rdlycdoi.json')\n",
    "    time.sleep(random.uniform(0.9*t,1.1*t))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of OpenAccess.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
