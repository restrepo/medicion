{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/restrepo/medicion/blob/master/cienciometria/WOS_SCI_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDnqho-CsEwj"
   },
   "source": [
    "# WOS+SCI+SCP+PTJ+GS+LNS\n",
    "Merge the bibliographic datasets for \n",
    "* Web of Science, \n",
    "* Scielo \n",
    "* Scopus \n",
    "* Google Scholar\n",
    "* Puntaje\n",
    "* Lens\n",
    "of the scientific articles of Universidad de Antioquia\n",
    "\n",
    "For details see [merge.ipynb in Colaboratory](https://colab.research.google.com/github/restrepo/medicion/blob/master/cienciometria/merge.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "def get_author_info(x):\n",
    "    sep='; '\n",
    "    authors=[{'WOS_author':x[0].split(sep)[0],'affiliation':[x[0].split(sep)[-1]],'i':0}]\n",
    "    iau=1\n",
    "    for y  in x:\n",
    "        y2=y.replace('[','').replace('] ',sep).split(sep)\n",
    "        for z in y2[:-1]:\n",
    "            aulist=[ d.get('WOS_author') for d in authors]\n",
    "            if z not in aulist:\n",
    "                authors.append({'WOS_author':z,'affiliation':[y2[-1]],'i':iau})\n",
    "                iau=iau+1\n",
    "            else:\n",
    "                if y2[-1] not in [ d.get('affiliation') for d in authors if d.get('WOS_author')==z][0]:\n",
    "                    index_author=[ d.get('i') for d in authors if d.get('WOS_author')==z][0]\n",
    "                    authors[index_author]['affiliation'].append(y2[-1])\n",
    "    return authors\n",
    "\n",
    "def dictionary_list_add_columns(df,df_dl,df_dl_key,df_dl_i,df_columns):\n",
    "    '''\n",
    "    For a\n",
    "     df: Pandas DataFrame \n",
    "    with a:\n",
    "     df_dl: column of list of dictionaries, with\n",
    "     df_dl_key: dictionary key: e.g x=[{df_dl_key:1},{df_dl_key:2}]\n",
    "    for the element df_dl_i of the list:\n",
    "    Update the dictionary with:\n",
    "        df_dl_key==x[df_dl_i][df_dl_key]\n",
    "    with the dictionaries { df_columns[i]: df_columns[i].values }\n",
    "    '''\n",
    "    dff=df.copy()\n",
    "    for key in df_columns:\n",
    "        tmp=dff[df_dl].combine(dff[key],\n",
    "                func=lambda x,y: y if pd.isna(y) \n",
    "                                   else \n",
    "                                     [z.update({key:y}) \n",
    "                                     if z.get(df_dl_key)==x[df_dl_i][df_dl_key] \n",
    "                                     else z \n",
    "                                 for z in x  ] )\n",
    "    return dff\n",
    "\n",
    "def split_full_names(y,full_name='full_name'):\n",
    "    \"\"\"\n",
    "    From an input dictionary with {full_name:'APPELLIDO1 APPELLIDO2 NOMBRES'}\n",
    "    Obtain a dictionary with the several name parts.\n",
    "    \"\"\"    \n",
    "    yy=y.get(full_name).title()\n",
    "    lfn=len(y[full_name].split())\n",
    "    aps=0\n",
    "    d={ 'PRIMER APELLIDO':yy.split()[aps] }\n",
    "    aps=aps+1\n",
    "    if lfn>=4:\n",
    "        names=-2\n",
    "        if lfn==5: # Extra name or last name\n",
    "            yyy=yy.split()\n",
    "            ll=pd.np.array( [len(n) for n in yyy ] )\n",
    "            if ll[3:][ ll[3:]  <= 3 ].shape[0]:\n",
    "                # last_names first_first_name de(l) second_first_name\n",
    "                yy=' '.join( [ y for y in yyy if len(y)>=3] )\n",
    "            else: \n",
    "                # first_last name de(l) second_last_name first_names\n",
    "                tmpll=yyy.pop() # internal memory\n",
    "                yy=' '.join( yyy )  \n",
    "        if len( d['PRIMER APELLIDO'] )<=3:\n",
    "            d['PRIMER APELLIDO']=d['PRIMER APELLIDO']+' '+yy.split()[aps]\n",
    "            aps=aps+1\n",
    "            d.update(  {'SEGUNDO APELLIDO':yy.split()[aps]} )\n",
    "            names=names+1\n",
    "            \n",
    "        d.update({'SEGUNDO APELLIDO':yy.split()[aps]})\n",
    "        aps=aps+1\n",
    "        if len( d['SEGUNDO APELLIDO'] )<=3:\n",
    "            d['SEGUNDO APELLIDO']=d['SEGUNDO APELLIDO']+' '+yy.split()[aps]\n",
    "            if names==-2:\n",
    "                names=names+1\n",
    "    elif lfn>=3:        \n",
    "        d.update({'SEGUNDO APELLIDO':yy.split()[aps]})\n",
    "        names=-1\n",
    "    else: #Colombian interpretation (TODO: Includes Brazilian interpretation)    \n",
    "        names=-1\n",
    "    d.update({'NOMBRES':' '.join( yy.split()[names:]),\n",
    "              'INICIALES':' '.join( [z[0]+'.' for z in yy.split()[names:]] ),\n",
    "              })\n",
    "    if not d.get('SEGUNDO APELLIDO'):\n",
    "        d['SEGUNDO APELLIDO']=''\n",
    "    #if not d.get('NOMBRE COMPLETO'):\n",
    "    #    d['NOMBRE COMPLETO']=''        \n",
    "    return d\n",
    "\n",
    "# Creates mask Search key in a list of dictionay\n",
    "# First apply convert null values to string\n",
    "# Second apply: implement a mask\n",
    "def find_key_in_list_of_dictionaries(df,column,key,pattern):\n",
    "    return df[column].apply(lambda x: \n",
    "                [ '' if pd.isnull( y.get(key)) else y for y in x ]  ).apply(\n",
    "                            lambda x: \n",
    "                [ True if y.get(key).find(pattern)>-1 else False for y in x  ][0]  )\n",
    "\n",
    "def key_contains_in_list_of_dictionaries(df,pattern,column='authors_WOS',key='WOS_author'):\n",
    "    #TODO: loop in column len\n",
    "    i=0\n",
    "    r=df[ df[column].str[i].apply(lambda x: {} if pd.isnull(x) else x).apply(\n",
    "                       lambda x: x.get(key) if x else '').str.contains(\n",
    "        pattern) ][column].reset_index(drop=True)\n",
    "    return r\n",
    "\n",
    "def update_institutional_authors(kkn,AU,authors_column='UDEA_authors',authors_column_key='full_name',\n",
    "                                        AU_first_last_name='PRIMER APELLIDO',\n",
    "                                        AU_second_last_name='SEGUNDO APELLIDO',\n",
    "                                        AU_first_names='NOMBRES'\n",
    "                                ):\n",
    "    '''\n",
    "    For a Data base containing full names of the authors of the articles: SIU,\n",
    "    include detailed information from other database                    : AU.\n",
    "      authors_column    : kkn Column with dictionary to be updated\n",
    "      authors_column_key: Key with full name as a value in  authors_column of kkn\n",
    "      For Spaniard name, e.g \"Juan Pedro Restrepo Correa\"\n",
    "      AU_first_last_name: AU column with \"Restrepo\"\n",
    "      AU_second_last_name: AU column with \"Correa\"\n",
    "      AU_first_names: AU column with \"Juan Pedro\"\n",
    "      full_name: Colum in AU with full name\n",
    "      \n",
    "    '''\n",
    "    full_name='name_tmp'\n",
    "    AU_columns=list( AU.columns.values )\n",
    "\n",
    "    AU[full_name]=(AU[AU_first_last_name]+' '+AU[AU_second_last_name]+' '+AU[AU_first_names]\n",
    "                  ).str.lower().str.strip().apply( unidecode.unidecode )\n",
    "\n",
    "    maxau=kkn[authors_column].apply(lambda x: [y.get(full_name) for y in x ]).apply(len).max()\n",
    "\n",
    "    newcolumns=[full_name]+AU_columns\n",
    "    for i in range(maxau):\n",
    "        print(i)\n",
    "        kkn[full_name]=kkn[authors_column].apply(lambda x: [y.get(authors_column_key) for y in x ]\n",
    "                            ).str[i].apply( lambda x: unidecode.unidecode( x.lower().strip()) \n",
    "                                                      if not pd.isna(x) else x)\n",
    "        if not kkn[~kkn[full_name].isna()].empty:\n",
    "            kkn=kkn.merge(AU[newcolumns],on=full_name,how='left').reset_index(drop=True)\n",
    "            kkn=dictionary_list_add_columns(kkn,authors_column,authors_column_key,i,AU_columns)\n",
    "            kkn=kkn.drop(newcolumns,axis='columns')\n",
    "    return kkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhk2ZGEDd2Yo"
   },
   "outputs": [],
   "source": [
    "import wosplus as wp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "pd.set_option('display.max_colwidth',200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "JS7jD1f47JUN"
   },
   "source": [
    "##  Configure public links of  files in Google Drive\n",
    "* If it is a Google Spreadsheet the corresponding file is downloaded as CSV\n",
    "* If it is in excel or text file the file is downloaded  directly\n",
    "\n",
    "To define your  own labeled IDs for public google drive files edit the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "hidden": true,
    "id": "T4Rmd2dF7JUQ",
    "outputId": "39a5835e-1b38-48b6-f1a5-e9964c846123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting drive.cfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile drive.cfg\n",
    "[FILES]\n",
    "UDEA_WOS.xlsx       = 1px2IcrjCrkyu7t78Q7PAE5nzV_yuPt9t\n",
    "UDEA_SCI.xlsx       = 1pWMY5P72j0Ca6D-cm7dn7Q4TBGTs4PWV\n",
    "UDEA_SCP.xlsx       = 1ulCsFHzDiTmuL9TH8F58ulh0u8Z2ylKh\n",
    "UDEA_WOS_SCI_SCP.xlsx   = 1o9otmklgh-0w18Avv2ZTKOXr3vZbjwvj\n",
    "WOS_SCI_SCP_PTJ.json=1RTDCh5pl0vapjJT_e9ZwadHPGBKGGv6Y\n",
    "WOS_SCI_SCP_PTJ.json.gz=19E1C1kRk4I0V3uXojqko8-NEicWaPp1j\n",
    "WOS_SCP_UDEA_SJR_SIU.xlsx=0BxoOXsn2EUNIQ3R4WDhvSzVLQ2s\n",
    "Base_de_datos_investigadores_Definitiva.csv=12oalgUeKhpvzkTPBP8pXCeHTrF-KO223dy9ov9w9QKs\n",
    "UDEA_authors_with_WOS_info.json=1o1eVT4JD0FMMICq_oxrTJOzWh47veBMw\n",
    "produccion_fecha_vig_2003_2018.xlsx=1WbtX4K__TTLxXRjuLvqUYz9tuHCIlS5v\n",
    "Sample_WOS.xlsx = 1--LJZ4mYyQcaJ93xBdbnYj-ZzdjO2Wq2\n",
    "UDEA_WOS_SCI_SCP_PTJ.json.gz=1SI2s0IkMnddgrUeR1ssVLFjSvsM1Mnyc\n",
    "UDEA_WOS_SCI_SCP_PTJ.json=1OkVytKbxJwGvXZDkynkSoUDtkUOTaT4A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0D0hEdAMXUX"
   },
   "source": [
    "##  Load data bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "occzrIeCS7aQ",
    "outputId": "17b144f3-eef0-4c8a-c2b4-10c8fe55802c"
   },
   "outputs": [],
   "source": [
    "affil='Univ Antioquia'\n",
    "drive_files=wp.wosplus('drive.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEBUG: if False stop in UDEA_PTJ!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oq9QM3cBYH0a"
   },
   "outputs": [],
   "source": [
    "UDEAjsonfile='WOS_SCI_SCP_PTJ.json.gz'\n",
    "if os.path.exists(UDEAjsonfile):\n",
    "    UDEA=               pd.read_json(UDEAjsonfile,compression='gzip').reset_index(drop=True)\n",
    "else:    \n",
    "    UDEA=drive_files.read_drive_json(UDEAjsonfile,compression='gzip').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOS:1646\n",
      "WOS_SCP:5268\n",
      "SCP:2157\n",
      "WOS_UDEA:238\n",
      "WOS_SCP_UDEA:553\n",
      "WOS_SCI_SCP_UDEA:129\n",
      "SCI:2396\n",
      "SCI_SCP_UDEA:372\n",
      "SCP_UDEA:418\n",
      "WOS_SCI_UDEA:37\n",
      "SCI_UDEA:497\n",
      "WOS_SCI_SCP:639\n",
      "SCI_SCP:1244\n",
      "WOS_SCI:110\n"
     ]
    }
   ],
   "source": [
    "for t in UDEA.Tipo.unique():\n",
    "    print( '{}:{}'.format( t, UDEA[ UDEA.Tipo==t].shape[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15704, 181)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AU=drive_files.read_drive_excel('Base_de_datos_investigadores_Definitiva.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extract  affiliation from C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Prepare UDEA.C1\n",
    "UDEA['C1']=UDEA['C1'].apply(lambda s: s if s!='' else None)\n",
    "UDEA_SCI=UDEA.SCI_C1.combine(UDEA['Tipo'],func=lambda x,y: x if y.find('SCI')>-1 and y.find('WOS')==-1 else None)\n",
    "UDEA_SCI=UDEA_SCI.apply(lambda x:x.replace(\n",
    "    'Universidad de Antioquia',affil).replace(\n",
    "    'Univ. de Antioquia',affil) if not pd.isnull(x) else x)\n",
    "#Update only if not filled already\n",
    "UDEA['C1']=UDEA_SCI.combine(UDEA['C1'],lambda x,y:x if pd.isnull(y) else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update C1 from SCP if neccesary\n",
    "rename='[\\w\\-\\.\\s]+'\n",
    "SCP2WOS=UDEA['SCP_Authors with affiliations'].str.replace(\n",
    "                                    '; ','\\n').str.replace(\n",
    "                                    '^({},{}),'.format( rename,rename),r'[\\1]',re.UNICODE).str.replace(\n",
    "                                    '\\n({},{}),'.format(rename,rename),r'\\n[\\1]',re.UNICODE).str.replace(\n",
    "                                    '(,\\s+\\w\\.)(\\w\\.\\])'.format(rename,rename),r'\\1 \\2',re.UNICODE)\n",
    "i=0\n",
    "SCP2WOS.loc[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 181)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize to WOS \n",
    "SCP2WOS=SCP2WOS.str.replace('Universi[dadty]{2,3}\\s+[deofDEOF]{2}\\s+Antioqu[ií]a',affil\n",
    "      ).str.replace('U[\\.niv]{1,4}\\s+[deofDEOF]{0,2}\\s*Antioqu[ií]a',affil\n",
    "      ).str.replace('Antioqu[ií]a\\s+[deofDEOF]{0,2}\\s*Universi[dadty]{2,3}',affil\n",
    "      )\n",
    "UDEA_SCP=SCP2WOS.combine(UDEA['Tipo'],func=lambda x,y: x if y=='SCP' else None)\n",
    "#Update only if not filled already\n",
    "UDEA['C1']=UDEA_SCP.combine(UDEA['C1'],lambda x,y:x if pd.isnull(y) else y)\n",
    "UDEA[UDEA['C1'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Duque, Luis F.; Montoya, Nilton; Restrepo, Alexandra] Univ Antioquia, Sch Publ Hlth, Medellin, Colombia.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[UDEA.Tipo=='WOS'].reset_index(drop=True).C1.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA['authors_WOS']=UDEA.C1.apply(lambda x: x.split('\\n') if x else x).apply(\n",
    "    lambda x:   [y.replace('[','').replace('] ','; ') for y in x if y.find(affil)>-1 ] if x else x ).apply(\n",
    "     lambda x: get_author_info(x) if x else x)\n",
    "\n",
    "# Improve normalization: remove C1s with only affiliation (from Scielo)\n",
    "UDEA['authors_WOS']=UDEA['authors_WOS'].apply( \n",
    "    lambda x: [d for d in x if d.get('WOS_author').find(affil)==-1] if type(x)==list else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'WOS_author': 'Márquez Arabia, J. J.',\n",
       "  'affiliation': ['Instituto Universitario de Educación Física, Univ Antioquia, Medellín, Colombia'],\n",
       "  'i': 0},\n",
       " {'WOS_author': 'Ramón Suárez, G.',\n",
       "  'affiliation': ['Instituto Universitario de Educación Física, Univ Antioquia, Medellín, Colombia'],\n",
       "  'i': 1}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[UDEA.Tipo=='SCP'].reset_index(drop=True).loc[0].authors_WOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load trained old data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MERGE_WITH_TRAINED=False\n",
    "if MERGE_WITH_TRAINED:\n",
    "    if os.path.exists('WOS_SCP_UDEA_SJR_SIU.xlsx'):\n",
    "        SIU=pd.read_excel('WOS_SCP_UDEA_SJR_SIU.xlsx')\n",
    "    else:    \n",
    "        SIU=drive_files.read_drive_excel('WOS_SCP_UDEA_SJR_SIU.xlsx')\n",
    "\n",
    "    SIU.Tipo.unique()\n",
    "\n",
    "    SIU=SIU[SIU.Tipo.str.contains('\\+UDEA')].reset_index(drop=True)\n",
    "\n",
    "    SIU['UDEA_autores']=SIU['UDEA_autores'].str.replace('\\s+',' ')\n",
    "\n",
    "    SIU['UDEA_authors']=SIU.UDEA_autores.str.split(';').apply(lambda x: [{'full_name':y} for y in x ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Merge with official researcher list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    kkn=SIU.copy()\n",
    "    \n",
    "    AU=drive_files.read_drive_excel('Base_de_datos_investigadores_Definitiva.csv')\n",
    "    kkn=update_institutional_authors(kkn,AU)\n",
    "\n",
    "    print(kkn.shape,SIU.shape)\n",
    "\n",
    "    SIU=kkn.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    SIU[ find_key_in_list_of_dictionaries(SIU,'UDEA_authors','full_name','ZAPATA') ].UDEA_authors.loc[241]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Merge WOS_SCP_SCI with trained data set PTJ_CTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Merge requires split in DI and TI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    #Be sure that always be True. The columns will be obtaied from SIU\n",
    "    REMOVE_UDEA_columns=True\n",
    "    if REMOVE_UDEA_columns:\n",
    "        UDEA_columns=[c for c in UDEA.columns if c.find('UDEA_')>-1]\n",
    "        UDEA=UDEA.drop(UDEA_columns,axis='columns')\n",
    "\n",
    "    udea_columns=[       'UDEA_autores',\n",
    "           'UDEA_año realiz', 'UDEA_doi', 'UDEA_fecha aplicación',\n",
    "           'UDEA_idioma', 'UDEA_item adic', 'UDEA_material', 'UDEA_nombre',\n",
    "           'UDEA_nombre revista o premio', 'UDEA_nro autores', 'UDEA_país',\n",
    "           'UDEA_procodigo', 'UDEA_ptos', 'UDEA_simple_doi', 'UDEA_título',\n",
    "           'UDEA_valor item','UDEA_authors']\n",
    "\n",
    "    SIUDI=SIU[~SIU.DI.isna()].drop_duplicates('DI').reset_index(drop=True)\n",
    "    SIUTI=SIU[ SIU.DI.isna()].drop_duplicates('TI').reset_index(drop=True)\n",
    "    SIUTI=SIUTI[SIUTI!=''].reset_index(drop=True)\n",
    "    SIUTI=SIUTI[~SIUTI.TI.isnull()].reset_index(drop=True)\n",
    "    SIUTI=SIUTI[ SIUTI.TI.apply(len)>20 ].reset_index(drop=True)\n",
    "\n",
    "    UDEADI=UDEA[UDEA.DI!=''].drop_duplicates('DI').reset_index(drop=True)\n",
    "    UDEATI=UDEA[UDEA.DI==''].drop_duplicates('TI').reset_index(drop=True)\n",
    "\n",
    "    UDEA_mergeDI=UDEADI.merge( SIUDI[ ['DI']+udea_columns ],on='DI',how='left' )\n",
    "\n",
    "    UDEA_PTJ=pd.DataFrame()\n",
    "    UDEA_PTJ_NOT=pd.DataFrame()\n",
    "    UDEA_PTJ=UDEA_mergeDI[~UDEA_mergeDI.UDEA_autores.isna()].reset_index(drop=True)\n",
    "    UDEA_PTJ_NOT=UDEA_mergeDI[UDEA_mergeDI.UDEA_autores.isna()].reset_index(drop=True)\n",
    "\n",
    "    UDEATI['tmptitle']=UDEATI.TI.str.strip()\n",
    "    SIUTI['tmptitle']=SIUTI.TI.str.strip()\n",
    "\n",
    "    kk=UDEATI.merge( SIUTI[ ['tmptitle']+udea_columns ],on='tmptitle',how='left' ).drop('tmptitle',axis='columns')\n",
    "\n",
    "    UDEA_PTJ=UDEA_PTJ.append( kk[ ~kk.UDEA_autores.isna() ] ).reset_index(drop=True)\n",
    "    UDEA_PTJ_NOT=UDEA_PTJ_NOT.append( kk[ kk.UDEA_autores.isna() ] ).reset_index(drop=True)\n",
    "\n",
    "    print(UDEA_PTJ.shape[0]+UDEA_PTJ_NOT.shape[0],UDEA.shape)\n",
    "\n",
    "    print(UDEA_PTJ.shape,UDEA_PTJ_NOT.shape)\n",
    "\n",
    "    UDEA=UDEA_PTJ.append(\n",
    "        UDEA_PTJ_NOT).reset_index(\n",
    "        drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [{'i': 0, 'WOS_author': 'Granda-Restrepo, Diana', 'affiliation': ['Univ Antioquia, Fac Quim Farmaceut, Dept Alimentos, Grp Invest Biotecnol Alimentos BIOALI, Medellin, Colombia.']}, {'i': 1, 'WOS_...\n",
       "2    [{'i': 0, 'WOS_author': 'Restrepo, Diego', 'affiliation': ['Univ Antioquia, Inst Fis, Calle 70 52-21,Apartado Aereo 1226, Medellin, Colombia.']}, {'i': 1, 'WOS_author': 'Zapata, Oscar', 'affiliati...\n",
       "Name: authors_WOS, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_contains_in_list_of_dictionaries(UDEA,'Restrepo, D',column='authors_WOS',key='WOS_author').loc[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    UDEA.to_json('UDEAtmp.json')\n",
    "    RECOVER=False\n",
    "    if RECOVER:\n",
    "        UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add `UDEA.authors_WOS` info* within `UDEA.UDEA_authors` data**\n",
    "(\\*) obtained from `UDEA.C1`\n",
    "\n",
    "(\\*\\*) Obtained from [puntaje trained old UDEA data](./WOS_SCI_SCP_PTJ_GS_LNS.ipynb#Merge-with-trained-data-set) and the [official researcher list](./WOS_SCI_SCP_PTJ_GS_LNS.ipynb#Merge-with-official-researcher-list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Obtain name parts and initials from full name in `UDEA_authors` dictionary and update `UDEA_authors` with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'UDEA_authors' not in UDEA.columns:\n",
    "    sys.exit('Make MERGE_WITH_TRAINED True and run again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-22-c94594b6b28f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-c94594b6b28f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print 1\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tmp is for update dict\n",
    "dictupdatetmp=UDEA['UDEA_authors'].apply(lambda x: [y.update( \n",
    "                split_full_names(y,full_name='full_name')  ) if not pd.isnull(\n",
    "                y.get('full_name')) else y for y in x] \n",
    "                                   if type(x)==list \n",
    "                                   else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y=UDEA['authors_WOS'].combine( UDEA['UDEA_authors'], func=lambda x,y:(x,y) ).loc[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def wos_names_append(wos_names,last_name,first_names,initials):\n",
    "    wos_names=wos_names+[           last_name+', '+first_names]\n",
    "    if len( first_names.split())>1:\n",
    "        wos_names=wos_names+[ last_name+', '+first_names.split()[0] ]\n",
    "    if len( first_names.split())==2 and  len(first_names.split()[-1]):\n",
    "        wos_names=wos_names+[ last_name+', '+first_names.split()[-1] ]\n",
    "    wos_names=wos_names+[ last_name+', '+initials]\n",
    "    if len( initials.split())>1:\n",
    "        wos_names=wos_names+[ last_name+', '+initials.split()[0]]\n",
    "    if len(initials.split())==2:\n",
    "        wos_names=wos_names+[\n",
    "              last_name+', '+first_names.split()[0]+' '+initials.split()[-1] ]\n",
    "        wos_names=wos_names+[last_name+', '+initials.split()[-1] ]\n",
    "    return wos_names\n",
    "    \n",
    "def wos_names_list(dy ,y_keys=['PRIMER APELLIDO','NOMBRES','INICIALES','SEGUNDO APELLIDO','full_name']   ):\n",
    "    last_name= unidecode.unidecode( dy[y_keys[0]]   )\n",
    "    first_names=unidecode.unidecode( dy[y_keys[1]]  )\n",
    "    initials=unidecode.unidecode( dy[y_keys[2]]  )\n",
    "\n",
    "    wos_names=[]\n",
    "    wos_names=wos_names_append(wos_names,last_name,first_names,initials)\n",
    "    \n",
    "    if dy.get( y_keys[3] ):\n",
    "        last_names= unidecode.unidecode( dy[y_keys[0]]+'-'+dy[y_keys[3]]   )\n",
    "        wos_names=wos_names_append(wos_names,last_names,first_names,initials)\n",
    "    return wos_names\n",
    "    \n",
    "def combinewos(x,y,x_keys=['WOS_author','affiliation'],\n",
    "                   y_keys=['PRIMER APELLIDO','NOMBRES','INICIALES','SEGUNDO APELLIDO','full_name'],\n",
    "                   xy_keys=['WOS_author','WOS_affiliation']):\n",
    "    if type(x)==list and type(y)==list:\n",
    "        for dx in x:\n",
    "            wos_name=unidecode.unidecode( dx[ x_keys[0] ] )\n",
    "            WOS_affiliation= dx[x_keys[1]]\n",
    "            # Try by buildinng spanish-like names list                                \n",
    "            for i in range( len(y) ):\n",
    "                if wos_name.title() in wos_names_list(y[i] ,y_keys):\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            #Try again but comparing full lists\n",
    "            wos_name_to_list=wos_name.replace(',','').replace('-',' ').title().split()\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=unidecode.unidecode( y[i][y_keys[4]].title() )\n",
    "                if yi_to_list:\n",
    "                    yi_to_list=yi_to_list.split()\n",
    "                else:\n",
    "                    yi_to_list=[]\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            #Try again but comparing full lists with initials\n",
    "            wos_name_to_list=wos_name.replace(',','').replace('-',' ').title().split()\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]] ]+y[i][y_keys[2]].split()\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            #Try again but comparing full lists with first first name and initial\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]],y[i][y_keys[1]].split()[0],\n",
    "                              y[i][y_keys[2]].split()[-1]]\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break                    \n",
    "            #Try again but comparing full lists with second first name and initial\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]],y[i][y_keys[1]].split()[-1],\n",
    "                              y[i][y_keys[2]].split()[0]]\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break                    \n",
    "                    \n",
    "                    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wos_names_list( split_full_names( y[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#kk=UDEA['UDEA_authors'].str[0].apply( lambda d: d if type(d)==dict else pd.np.nan ).dropna()\n",
    "#kk[kk.apply( lambda d: d.get('full_name') if type(d)==dict else pd.np.nan ).isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kk=UDEA['authors_WOS'].combine( UDEA['UDEA_authors'], func=combinewos )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Combines the two list into a single one in  UDEA_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Full query of auhor_WOS in UDEA_authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors'].apply(lambda x: [y  for y in x ][0] if type(x)==list else x).loc[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load output restuls of previous Cell runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "    list_of_dictionaries='UDEA_authors',\n",
    "    dictionary_key='WOS_author'):\n",
    "    #Extract internal value of a dictionary key in a list of dictionaries and empty list otherwise\n",
    "    \n",
    "    return df[list_of_dictionaries].apply(lambda x: [y.get(dictionary_key) \n",
    "                                                        if y.get(dictionary_key) else []   \n",
    "                                                        for y in x  ]\n",
    "                           if type(x)==list else [])\n",
    "\n",
    "def extract_internal_list_as_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "    list_of_dictionaries='UDEA_authors',\n",
    "    dictionary_key='WOS_author'):\n",
    "    #Extract internal list as value of a dictionary key in a list of dictionaries and empty list otherwise\n",
    "    \n",
    "    return extract_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "                    list_of_dictionaries,dictionary_key).apply(lambda x: \n",
    "                           [item for sublist  in x for item in sublist] \n",
    "                            if type(x)==list else x)\n",
    "\n",
    "def mask_on_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "    pattern='RESTREPO QUINTERO DIEGO ALEJANDRO',\n",
    "    list_of_dictionaries='UDEA_authors',dictionary_key='full_name'):\n",
    "    \"\"\"\n",
    "    Build a mask for a Pandas Series of list of dictionaries of label:\n",
    "      list_of_dictionaries. \n",
    "    The:\n",
    "      dictionary_key must be a single value like string or float\n",
    "    \"\"\"\n",
    "    return extract_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "            list_of_dictionaries,dictionary_key).apply( \n",
    "            lambda x: pattern in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pattern='Restrepo, Diego'\n",
    "mask=extract_internal_list_as_value_of_a_dictionary_key_in_a_list_of_dictionaries(\n",
    "            UDEA,list_of_dictionaries='UDEA_authors',dictionary_key='WOS_author').apply( \n",
    "            lambda x: pattern in x)\n",
    "UDEA[mask]['UDEA_authors'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pattern='Restrepo, D.'\n",
    "mask=extract_internal_list_as_value_of_a_dictionary_key_in_a_list_of_dictionaries(\n",
    "            UDEA,list_of_dictionaries='UDEA_authors',dictionary_key='WOS_author').apply( \n",
    "            lambda x: pattern in x)\n",
    "UDEA[mask]['UDEA_authors'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mask=extract_internal_list_as_value_of_a_dictionary_key_in_a_list_of_dictionaries(\n",
    "            UDEA,list_of_dictionaries='UDEA_authors',dictionary_key='WOS_author').apply( \n",
    "            lambda x: pattern in x)\n",
    "UDEA[mask]['UDEA_authors'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_dictionary_from_list(df,list_name,i=0):\n",
    "    return df[list_name].apply( lambda l: [ d for d in l][i] if type(l)==list else l )\n",
    "def extract_key_value_from_series(ds,key):\n",
    "    return ds.apply( lambda d: d.get(key)if type(d)==dict else d  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mask=extract_key_value_from_series( \n",
    "    extract_dictionary_from_list( UDEA,'UDEA_authors',i=0),'WOS_author').str[0].str.contains('\\-').fillna(False)\n",
    "UDEA[mask]['UDEA_authors'].reset_index(drop=True).str[0].loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "TODO: Extract dict or value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build a single profile for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "flatten a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ua=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aumax=UDEA['UDEA_authors'].dropna().apply(len).max() \n",
    "ua=pd.DataFrame()\n",
    "for i in range(aumax):\n",
    "    kkk=pd.DataFrame()\n",
    "    kkk['UDEA_authors']= UDEA['UDEA_authors'].str[i].dropna()\n",
    "    kkk['authors_WOS']= UDEA['authors_WOS']\n",
    "    kkk['SCP_Authors']=UDEA['SCP_Authors']\n",
    "    kkk['tmp_str']=kkk['UDEA_authors'].astype(str)\n",
    "    kkk=kkk.drop_duplicates('tmp_str')\n",
    "    ua=ua.append(kkk).reset_index(drop=True)\n",
    "    #ua['UDEA_authors']= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ua['tmp_author']=ua['UDEA_authors'].apply( lambda d: d.get('full_name') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BUG: `UDEA_authors` without `WOS_author key`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Filter identified WOS articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ua['authors_WOS']=ua['authors_WOS'].apply(lambda l: l if l else pd.np.nan)\n",
    "ua=ua[~ua['authors_WOS'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "full_names=ua['tmp_author'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "full_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ua.shape,full_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "TODO: implement also SCP authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aunly=pd.DataFrame()\n",
    "for f in full_names:\n",
    "    clear_output(wait=True)\n",
    "    print(f)    \n",
    "    kk=pd.DataFrame( { 'tmp_author':[f]  } ).merge(\n",
    "          ua[['tmp_author','UDEA_authors']],on='tmp_author',how='left')\n",
    "\n",
    "    kk['tmp_str']=kk.UDEA_authors.astype(str)\n",
    "\n",
    "    kk=kk.drop_duplicates('tmp_str').dropna()#[['tmp_author','UDEA_authors']]\n",
    "\n",
    "    try:\n",
    "        laff=list( kk['UDEA_authors'].apply(lambda d: d.get( 'WOS_affiliation' )\n",
    "                                     ).dropna().apply(pd.Series).stack().unique() )\n",
    "        lau=list( kk['UDEA_authors'].apply(lambda d: d.get( 'WOS_author' )\n",
    "                                     ).dropna().apply(pd.Series).stack().unique() )\n",
    "    except AttributeError:\n",
    "        laff=[];lau=[]\n",
    "\n",
    "    if len(laff)>0 and len(lau)>0:\n",
    "        tmpupdate=kk['UDEA_authors'].apply(lambda d: d.update({'WOS_author':lau,'WOS_affiliation':laff}) )\n",
    "\n",
    "        kk['tmp_str']=kk['UDEA_authors'].astype(str)\n",
    "\n",
    "        kk=kk.drop_duplicates('tmp_str')\n",
    "\n",
    "        kk['tmp_len']=kk['tmp_str'].apply(len)#.astype(str)\n",
    "\n",
    "        aunly=aunly.append( kk.sort_values('tmp_len',ascending=False).drop(index=kk.index[1:]).drop(\n",
    "               ['tmp_str','tmp_len'],axis='columns') ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DEBUG\n",
    "aunly[aunly.tmp_author.fillna('').str.contains('DUQUE ECHEVERRI CARLOS ALBERTO')\n",
    "      ].reset_index(drop=True).UDEA_authors.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ua['UDEA_authors'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ua['authors_WOS'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aunly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aunly.to_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if RECOVER:\n",
    "    if os.path.exists('UDEA_authors_with_WOS_info.json' ):\n",
    "        aunly=pd.read_json('UDEA_authors_with_WOS_info.json')\n",
    "    else:\n",
    "        aunly=drive_files.read_drive_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aunly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(800, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge UDEA with authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop upon i and j to merge aunly in UDEA such that the full authors and affiliations are registered\n",
    "#UDEA.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_full_wos_author_info(l,WOS_df=aunly,full_name='full_name',full_name_column='tmp_author',\n",
    "                               WOS_column='UDEA_authors',WOS_author='WOS_author',\n",
    "                               WOS_affiliation='WOS_affiliation'):\n",
    "    newl=[]\n",
    "    if type(l)==list:\n",
    "        for d in l:\n",
    "            if d.get('WOS_author'):\n",
    "                #find in aunly\n",
    "                mtch=WOS_df[WOS_df[full_name_column]==d.get(full_name)].reset_index(drop=True)\n",
    "                if mtch.shape[0]==1:\n",
    "                    #update d\n",
    "                    if mtch[WOS_column].loc[0].get(WOS_author):\n",
    "                        d[WOS_author]=mtch[WOS_column].loc[0].get(WOS_author)\n",
    "                        d[WOS_affiliation]=mtch[WOS_column].loc[0].get(WOS_affiliation)\n",
    "            newl.append(d)\n",
    "    else:\n",
    "        newl=l\n",
    "    return newl        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l=UDEA['UDEA_authors'].loc[4]\n",
    "#fill_full_wos_author_info(l,aunly)[0].get('WOS_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(fill_full_wos_author_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation without merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lv\n",
    "def find_author_affiliation(author,affiliation,author_df=aunly,column='UDEA_authors',\n",
    "                            author_key='WOS_author',affiliation_key='WOS_affiliation',ratio=0.9):\n",
    "    '''\n",
    "    find the WOS+\"UDEA puntaje\" dictionary for WOS author:   `author`\n",
    "    and WOS affiliation:                                    `affiliation`\n",
    "    The information is  searched in \n",
    "    WOS+\"UDEA puntaje\" DataFrame:                            `author_df`, \n",
    "    which has the column:                                    `column` \n",
    "    which contains a dictionary with list value for the key: `author_key`\n",
    "    and list value for the key:                              `affiliation_key`.\n",
    "    Affiliation must be similar until a Levenshtein ratio:   `ratio`\n",
    "    '''    \n",
    "    au=author_df[ author_df[column].apply(\n",
    "                lambda d: d.get(author_key) if type(d)==dict else '').apply(\n",
    "                  lambda l: author in l)]#.reset_index(drop=True).loc[0,column]\n",
    "    if au.shape[0]>0:\n",
    "        #Fast\n",
    "        auf=au[au[column].apply(\n",
    "                 lambda d: d.get(affiliation_key) if type(d)==dict else '').apply(\n",
    "                 lambda l: affiliation in l)]\n",
    "        \n",
    "\n",
    "        if auf.shape[0]>0:\n",
    "              return auf.reset_index(drop=True).loc[0,column]          \n",
    "        #Slow\n",
    "        else:\n",
    "            aus=au[au[column].apply(\n",
    "                 lambda d: d.get(affiliation_key) if type(d)==dict else '').apply(\n",
    "                 lambda l: len( [af for af in l if lv.ratio(af,affiliation) > ratio ] )>0 )]\n",
    "\n",
    "            if aus.shape[0]==1: #fix 1 to avoid homonymous\n",
    "                dold=aus.reset_index(drop=True).loc[0,column]\n",
    "                # Dictionary is automatically updated in author_df!\n",
    "                dold[affiliation_key]=dold[affiliation_key]+[affiliation]\n",
    "                return dold\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_UDEA_authors(x,y,x_author_key='WOS_author',x_affiliation_key='affiliation',\n",
    "                        author_df=aunly,column='UDEA_authors',\n",
    "                        author_key='WOS_author',affiliation_key='WOS_affiliation',\n",
    "                        ratio=0.9):\n",
    "    '''\n",
    "    get the WOS+\"UDEA puntaje\" list of dictionaries for WOS author list \n",
    "    and affiliation list in the  list of dictionaries:      `x`, \n",
    "    where each dictionary have the string value for the key: `x_author_key`, \n",
    "    and the list value for the key:                          `x_affiliation_key`.\n",
    "    The information is obtained directly from the \n",
    "    WOS+\"UDEA puntaje\" list:                                 `y` \n",
    "    if already there, or searched in \n",
    "    WOS+\"UDEA puntaje\" DataFrame:                            `author_df`, \n",
    "    which has the column:                                    `column` \n",
    "    which contains a dictionary with list value for the key: `author_key`\n",
    "    and list value for the key:                              `affiliation_key`.\n",
    "    If not foun None is returned.\n",
    "    WOS info can be changed for other standarized dababase info\n",
    "    and \"UDEA puntaje\" can be changed from any other full name author\n",
    "    and affiliation info.\n",
    "    \n",
    "    IMPORTANT:\n",
    "    The list of values in:                                   `affiliation_key` \n",
    "    is automatically updated with the similar first \n",
    "    affiliation value of the list in:                        `x_affiliation_key`\n",
    "    according with the Levenshtein similarity ratio:         `ratio`\n",
    "    '''\n",
    "    if type(y)==list:\n",
    "        #already filled:\n",
    "        return y\n",
    "\n",
    "    au=[]\n",
    "    if ( type(x)==list and x):\n",
    "        for j in range(len(x)):\n",
    "            xx=find_author_affiliation(x[j].get(x_author_key),x[j].get(x_affiliation_key)[0],\n",
    "                                        author_df=author_df,\n",
    "                                        author_key=author_key,\n",
    "                                        affiliation_key=affiliation_key,\n",
    "                                        ratio=ratio )\n",
    "            if xx:\n",
    "                au.append(xx)\n",
    "    if au:\n",
    "        return au\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=6\n",
    "x=UDEA['authors_WOS'].loc[i]\n",
    "y=UDEA['UDEA_authors'].loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_UDEA_authors(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=UDEA.authors_WOS.combine(UDEA.UDEA_authors,func=get_UDEA_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.UDEA_authors.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.UDEA_authors.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aunly.to_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    if os.path.exists('UDEA_authors_with_WOS_info.json' ):\n",
    "        aunly=pd.read_json('UDEA_authors_with_WOS_info.json')\n",
    "    else:\n",
    "        aunly=drive_files.read_drive_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq=UDEA.copy()\n",
    "qq['UDEA_authors']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqq=qq.authors_WOS.combine(qq.UDEA_authors,func=get_UDEA_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq=UDEA.copy()\n",
    "qq['NEW']=qqq\n",
    "qq['EXTRA']=kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(qq[qq.UDEA_authors.isna()][['NEW','EXTRA']].dropna(subset=['NEW']))[qq.EXTRA==None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puntaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: pass pandas.load args\n",
    "tmp=drive_files.load_biblio('produccion_fecha_vig_2003_2018.xlsx',prefix='UDEA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize title translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "septrans=r'(.+)\\((.{10,})\\)$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']['UDEA_título_list']=drive_files.biblio['UDEA'].UDEA_título.str.replace(\n",
    "    septrans,r'\\1;;\\2',re.UNICODE).str.split(';;').apply(\n",
    "   lambda l: [ re.sub( r'^\"','',\n",
    "                      re.sub( r'\"$','', s.strip() )\n",
    "                     ) for s in l] )#.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']['UDEA_DOI']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=drive_files.biblio['UDEA'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA'].Tipo.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0 #1\n",
    "titlec='UDEA_TI'\n",
    "authorc='UDEA_nombre'\n",
    "authorsc='UDEA_nombres'\n",
    "drive_files.biblio['UDEA']['UDEA_TI']=drive_files.biblio['UDEA'].UDEA_título_list.str[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_au=drive_files.biblio['UDEA'][drive_files.biblio['UDEA'].duplicated(subset=[titlec],keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_au=drive_files.biblio['UDEA'][~drive_files.biblio['UDEA'].duplicated(subset=[titlec],keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_au.shape[0]+single_au.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_au=multi_au.sort_values(titlec).reset_index(drop=True)\n",
    "multi_au[[authorc,titlec]][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_old=''\n",
    "au_old=pd.np.nan\n",
    "for i in multi_au.index:\n",
    "    t=multi_au.loc[i,titlec]\n",
    "    if t==t_old:\n",
    "        au_old=au_old+';'+multi_au.loc[i,authorc]\n",
    "        multi_au.loc[i-1,authorsc]=pd.np.nan\n",
    "    else:\n",
    "        t_old=t\n",
    "        multi_au.loc[i-1,authorsc]=au_old\n",
    "        au_old=multi_au.loc[i,authorc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_au[[authorc,authorsc,titlec]][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_au.shape[0],multi_au.dropna(subset=[authorsc]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=(multi_au.dropna(subset=[authorsc]).append(single_au,sort=False)\n",
    "                           ).reset_index(drop=True)\n",
    "drive_files.biblio['UDEA'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOVER=True\n",
    "if RECOVER:\n",
    "    tmp=drive_files.load_biblio('UDEA_WOS_SCI_SCP_PTJ.json')# TODO CHANGE FOR LAST VERSION IN GOOGLE DRIVE\n",
    "#DEBUG\n",
    "#tmp=drive_files.load_biblio('Sample_WOS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.WOS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS'].Tipo.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS']['UDEA_authors']=drive_files.biblio['WOS'].UDEA_authors.apply(lambda x: \n",
    "                                x if type(x)==list else None).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALREADY in PTJ\n",
    "UDEA_PTJ=drive_files.biblio['WOS'][ ~drive_files.biblio['WOS']['UDEA_authors'].isna()].reset_index(drop=True)\n",
    "# Missing PTJ. To be proccesses below\n",
    "UDEA_PTJ_NOT    =drive_files.biblio['WOS'][ drive_files.biblio['WOS']['UDEA_authors'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_PTJ.shape, UDEA_PTJ_NOT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS']=UDEA_PTJ_NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udea_columns=[c for c in drive_files.biblio['WOS'].columns if c.find('UDEA_')>-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS']=drive_files.biblio['WOS'].drop( udea_columns, axis='columns' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG=False\n",
    "if DEBUG:\n",
    "    drive_files.biblio['UDEA']=drive_files.biblio['UDEA'][:10]\n",
    "    drive_files.biblio['WOS']=drive_files.biblio['WOS'][:10]\n",
    "\n",
    "drive_files.UDEA=drive_files.biblio['UDEA']\n",
    "drive_files.WOS =drive_files.biblio['WOS']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=drive_files.merge(left=\"WOS\", right=\"UDEA\",\n",
    "                     left_DOI=\"DI\", left_TI=\"TI\",\n",
    "                     right_DOI=\"UDEA_DOI\", right_TI=\"UDEA_TI\",\n",
    "                     left_author=\"AU\", left_year=\"PY\",\n",
    "                     right_author=\"UDEA_nombre\",right_year=\"UDEA_año realiz\",\n",
    "                     left_extra_journal=\"SO\",\n",
    "                     right_extra_journal=\"UDEA_nombre revista o premio\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare new WOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS_UDEA'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean pure PTJ entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos=drive_files.biblio['WOS_UDEA'][drive_files.WOS_UDEA.Tipo!='UDEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos.shape #expected 7094. Ignoring differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_to_UDEA_PTJ=newwos[newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_to_UDEA_PTJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_not_PTJ=newwos[~newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "new_UDEA_not_PTJ.shape[0]+app_to_UDEA_PTJ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS']=new_UDEA_not_PTJ\n",
    "\n",
    "drive_files.biblio['WOS']=drive_files.biblio['WOS'].drop( \n",
    "     [ c for c in drive_files.biblio['WOS'].columns if c.find('UDEA_')>-1  ],\n",
    "       axis='columns')\n",
    "new_UDEA_not_PTJ.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare new UDEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkk=app_to_UDEA_PTJ[['UDEA_TI','Tipo']].merge(drive_files.biblio['UDEA'],on='UDEA_TI',how='right')\n",
    "drive_files.biblio['UDEA']=kkk[kkk.Tipo_x.isna()].drop('Tipo_x',axis='columns'\n",
    "                                              ).rename({'Tipo_y':'Tipo'},axis='columns'\n",
    "                                              ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "drive_files.biblio['UDEA']['UDEA_TI']=drive_files.biblio['UDEA'].UDEA_título_list.str[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drive_files.biblio['UDEA']=drive_files.biblio['UDEA'].dropna(subset=['UDEA_TI']).reset_index(drop=True)\n",
    "\n",
    "kkk[~kkk.Tipo_x.isna()].shape,drive_files.biblio['UDEA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=wp.fill_NaN(drive_files.biblio['UDEA'])\n",
    "drive_files.biblio['WOS'] =wp.fill_NaN(drive_files.biblio['WOS'])    \n",
    "drive_files.UDEA=drive_files.biblio['UDEA']\n",
    "drive_files.WOS =drive_files.biblio['WOS']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=drive_files.merge(left=\"WOS\", right=\"UDEA\",\n",
    "                     left_DOI=\"DI\", left_TI=\"TI\",\n",
    "                     right_DOI=\"UDEA_DOI\", right_TI=\"UDEA_TI\",\n",
    "                     left_author=\"AU\", left_year=\"PY\",\n",
    "                     right_author=\"UDEA_nombre\",right_year=\"UDEA_año realiz\",\n",
    "                     left_extra_journal=\"SO\",\n",
    "                     right_extra_journal=\"UDEA_nombre revista o premio\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos=drive_files.WOS_UDEA[drive_files.WOS_UDEA.Tipo!='UDEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_to_UDEA_PTJ_2=newwos[newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "app_to_UDEA_PTJ_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_not_PTJ=newwos[~newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "new_UDEA_not_PTJ.shape[0]+app_to_UDEA_PTJ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_2=newwos[~newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "drive_files.biblio['WOS']=new_UDEA_not_PTJ\n",
    "\n",
    "drive_files.biblio['WOS']=drive_files.biblio['WOS'].drop( \n",
    "     [ c for c in drive_files.biblio['WOS'].columns if c.find('UDEA_')>-1  ],\n",
    "       axis='columns')\n",
    "drive_files.biblio['WOS'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UDEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkk=app_to_UDEA_PTJ_2[['UDEA_TI','Tipo']].merge(drive_files.biblio['UDEA'],on='UDEA_TI',how='right')\n",
    "drive_files.biblio['UDEA']=kkk[kkk.Tipo_x.isna()].drop('Tipo_x',axis='columns'\n",
    "                                              ).rename({'Tipo_y':'Tipo'},axis='columns'\n",
    "                                              ).reset_index(drop=True)\n",
    "\n",
    "drive_files.biblio['UDEA']['UDEA_TI']=drive_files.biblio['UDEA'].UDEA_título\n",
    "drive_files.biblio['UDEA']=drive_files.biblio['UDEA'].dropna(subset=['UDEA_TI']).reset_index(drop=True)\n",
    "kkk[~kkk.Tipo_x.isna()].shape,drive_files.biblio['UDEA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=wp.fill_NaN(drive_files.biblio['UDEA'])\n",
    "drive_files.biblio['WOS'] =wp.fill_NaN(drive_files.biblio['WOS'])    \n",
    "drive_files.UDEA=drive_files.biblio['UDEA']\n",
    "drive_files.WOS =drive_files.biblio['WOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=drive_files.merge(left=\"WOS\", right=\"UDEA\",\n",
    "                     left_DOI=\"DI\", left_TI=\"TI\",\n",
    "                     right_DOI=\"UDEA_DOI\", right_TI=\"UDEA_título\",\n",
    "                     left_author=\"AU\", left_year=\"PY\",\n",
    "                     right_author=\"UDEA_nombre\",right_year=\"UDEA_año realiz\",\n",
    "                     left_extra_journal=\"SO\",\n",
    "                     right_extra_journal=\"UDEA_nombre revista o premio\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos=drive_files.WOS_UDEA[drive_files.WOS_UDEA.Tipo!='UDEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_to_UDEA_PTJ_tot=newwos[newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "app_to_UDEA_PTJ_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_not_PTJ=newwos[~newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "new_UDEA_not_PTJ.shape[0]+app_to_UDEA_PTJ_tot.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update aunly and pass again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the total UDEA_PTJ ~2500 runs againt WOS_SCI_SCP_PTJ.json  and add UDEA_authors info and extrapolates new ones ~500. We will have new ~3000 for a total of 11000~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qq=pd.read_json('WOS_SCI_SCP_PTJ.json.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ c for c in drive_files.biblio['WOS'].columns if c.find('UDEA_')>-1  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_PTJ=app_to_UDEA_PTJ.append(app_to_UDEA_PTJ_2).append(app_to_UDEA_PTJ_tot).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_PTJ.shape[0]+new_UDEA_not_PTJ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_UDEA_PTJ=pd.read_json('new_UDEA_PTJ.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_PTJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ c for c in UDEA_PTJ.columns if c.find('UDEA_')>-1  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ c for c in new_UDEA_PTJ.columns if c.find('UDEA_')>-1  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.load_biblio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries left are the ones where there are normalization problemas\n",
    "* Bad written names\n",
    "* Wrong affiliation in WOS\n",
    "* Author appears in AU but not in C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "tmpua=UDEA[UDEA.UDEA_authors.str[i].apply(lambda d: True if type(d)==dict else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpkk=tmpua[ tmpua.UDEA_authors.str[i].apply(lambda d: d.get('WOS_author')).str[0].apply( pd.isna) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=tmpkk[ tmpkk.authors_WOS.apply( lambda l: l if l and type(l)==list else pd.np.nan ).apply( \n",
    "    lambda l: True if type(l)==list else False) ][['authors_WOS','UDEA_authors','UDEA_autores','TI','DI','AU','C1']].reset_index(drop=True)#.loc[4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=204\n",
    "tmp[i:i+1]#.UDEA_authors#.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.UDEA_authors.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.authors_WOS.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.UDEA_autores.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.TI.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp.AU.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp.C1.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tmp['authors_WOS'].reset_index(drop=True).loc[i]\n",
    "y=tmp['UDEA_authors'].reset_index(drop=True).loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "y#[i]['NOMBRE COMPLETO'].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_keys=['PRIMER APELLIDO','NOMBRES','INICIALES','SEGUNDO APELLIDO','full_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "wos_names_list(y[i] ,y_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,\n",
    "  2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinewos(x,y,x_keys=['WOS_author','affiliation'],\n",
    "                   y_keys=['PRIMER APELLIDO','NOMBRES','INICIALES','SEGUNDO APELLIDO','full_name'],\n",
    "                   xy_keys=['WOS_author','WOS_affiliation']):\n",
    "    if type(x)==list and type(y)==list:\n",
    "        for dx in x:\n",
    "            print( dx[ x_keys[0] ] )\n",
    "            wos_name=unidecode.unidecode( dx[ x_keys[0] ] )\n",
    "            WOS_affiliation= dx[x_keys[1]]\n",
    "            print('Name True')\n",
    "            for i in range( len(y) ):\n",
    "                print('+'*20)\n",
    "                print( wos_names_list(y[i] ,y_keys))\n",
    "                print('+'*20)\n",
    "                print(i,wos_name in wos_names_list(y[i] ,y_keys) )\n",
    "                print('='*20)\n",
    "                if wos_name.title() in wos_names_list(y[i] ,y_keys):\n",
    "                    print('*'*20)\n",
    "                    print(wos_name in wos_names_list(y[i] ,y_keys),':',wos_name)\n",
    "                    print('*'*20)\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            # Try by buildong spanish-like names list                    \n",
    "            #Try again but comparing full lists\n",
    "            wos_name_to_list=wos_name.replace(',','').replace('-',' ').title().split()\n",
    "            print(\"-\"*20)\n",
    "            for i in range( len(y) ):\n",
    "                print('--',i)\n",
    "                yi_to_list=unidecode.unidecode( y[i][y_keys[4]].title() )\n",
    "                if yi_to_list:\n",
    "                    yi_to_list=yi_to_list.split()\n",
    "                else:\n",
    "                    yi_to_list=[]\n",
    "                print(i,wos_name_to_list,yi_to_list,  )    \n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            #Try again but comparing full lists with initials\n",
    "            wos_name_to_list=wos_name.replace(',','').replace('-',' ').title().split()\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]] ]+y[i][y_keys[2]].split()\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            #Try again but comparing full lists with first first name and initial\n",
    "            print(\":\"*20)\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]],y[i][y_keys[1]].split()[0],\n",
    "                              y[i][y_keys[2]].split()[-1]]\n",
    "                print(\"::::\",yi_to_list)\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break                    \n",
    "            #Try again but comparing full lists with second first name and initial\n",
    "            print(\":\"*20)\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]],y[i][y_keys[1]].split()[-1],\n",
    "                              y[i][y_keys[2]].split()[0]]\n",
    "                print(\"::::\",yi_to_list)\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinewos(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.np.setdiff1d(['Bastidas', 'Myriam'] ,['Bastidas', 'Acevedo', 'Miryam', 'Del', 'Socorro']).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "800*3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aunly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Try to merge new WOS articles from old `'UDEA_authors'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: whithout split or merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split DataFrame into  \"new\" with UDEA authors not yet identified and \"old\" with full UDEA author info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEAnew=UDEA[UDEA.UDEA_authors.isna()].reset_index(drop=True)\n",
    "UDEAold=UDEA[~UDEA.UDEA_authors.isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge old with news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split \"new\" into the \"Y\" with WOS author info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEAnewY=UDEAnew[ UDEAnew.authors_WOS.apply(lambda x: type(x)==list and len(x)>0) ].reset_index(drop=True)\n",
    "UDEAnewN=UDEAnew[~UDEAnew.authors_WOS.apply(lambda x: type(x)==list and len(x)>0) ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(UDEAnewY.shape,'+',UDEAnewN.shape,'+',UDEAold.shape,'=',\n",
    "   UDEAnewY.shape[0]+UDEAnewN.shape[0]+UDEAold.shape[0],'=',UDEA.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK=False\n",
    "if CHECK:\n",
    "    pattern='Restrepo, D.'\n",
    "    mask=extract_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(\n",
    "                UDEAnewY,list_of_dictionaries='authors_WOS',dictionary_key='WOS_author').apply( \n",
    "                lambda x: pattern in x)\n",
    "    UDEAnewY[mask].authors_WOS.reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECK:\n",
    "    mask=mask_on_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(UDEAnewY,\n",
    "            pattern='Restrepo, D.',list_of_dictionaries='authors_WOS',dictionary_key='WOS_author')                                                                       \n",
    "    UDEAnewY[mask]['authors_WOS'].reset_index(drop=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a specific author with specific affiliation from the WOS author full info into a temporal column\n",
    "i=0\n",
    "aff_i=0\n",
    "UDEAnewY['news_i_j_str']=UDEAnewY.authors_WOS.apply(lambda x: [ {'WOS_author':y.get('WOS_author'),\n",
    "                                                   'affiliation':y.get('affiliation')[aff_i]} for y in x]\n",
    "                                                   ).str[i].astype(str)\n",
    "UDEAnewY['news_i_j_str'].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare trained data set with the j-th author: first UDEA author info into a temporal column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "auth_j=0\n",
    "aff_j=0\n",
    "UDEAold['UDEA_authors_j']=UDEAold['UDEA_authors'].str[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a specific author with specific affiliation from the WOS author full info into a temporal column\n",
    "UDEAold['news_i_j']=UDEAold['UDEA_authors'].apply(lambda l: [ {'WOS_author':d.get('WOS_author')[auth_j], \n",
    "                                           'affiliation':d.get('WOS_affiliation')[aff_j] } if d.get('WOS_author') \n",
    "                                         else pd.np.nan for d in l] ).str[j]#.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma=UDEAold.dropna(subset=['news_i_j']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality critera search:\n",
    "* Affiliation split(', ') > 3\n",
    "* if Author find('.') → 'Author split(' ')  > 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma['news_i_j'].loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** May be filter Homonymous\n",
    "Homonymous=False\n",
    "if Homonymous:\n",
    "    ma=ma[~np.logical_and( ma['news_i_j'].apply(lambda d: d.get('affiliation') \n",
    "                                              if not pd.isna(d) else '' ).str.split(', ').apply(len)<=3,\n",
    "                            ma['news_i_j'].apply(lambda d: d.get('WOS_author') \n",
    "                                              if not pd.isna(d) else '' ).str.split(' ').apply(len)<=2)]\n",
    "#****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma['news_i_j_str']=ma['news_i_j'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract all the mathches for the author\n",
    "kk=UDEAnewY.merge( ma[['news_i_j_str','news_i_j']],on='news_i_j_str',how='left')#.dropna().reset_index(drop=True)#.loc[5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.UDEA_authors.str[i].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk.shape,UDEAnewY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk=kk.dropna(subset=['news_i_j'])#.shape\n",
    "kkk.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "merge.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
