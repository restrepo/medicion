{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/restrepo/medicion/blob/master/cienciometria/WOS_SCI_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDnqho-CsEwj"
   },
   "source": [
    "# WOS+SCI+SCP+PTJ+CTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the bibliographic datasets for \n",
    "* Web of Science (WOS), \n",
    "* Scielo (SCI)\n",
    "* Scopus  (SCP)\n",
    "* Puntaje (UDEA)\n",
    "* Center (CTR)\n",
    "of the scientific articles of Universidad de Antioquia\n",
    "\n",
    "For details see [merge.ipynb in Colaboratory](https://colab.research.google.com/github/restrepo/medicion/blob/master/cienciometria/merge.ipynb)\n",
    "\n",
    "Implementation:\n",
    "The input pure o partially processed database with WOS-SCI-SCP and may be some UDEA entries from PTJ and Center information with additional data about the Full Name UDEA authors.\n",
    "\n",
    "Addtionaly UDEA entries can be captured from:\n",
    "1. A previous WOS-SCI-SCP-UDEA\n",
    "2. A Data Base with a column with full names (FULL LAST NAMES NAMES, e.g VALDEZ GÚZMAN JUAN ALBERTO) and a list of author Aliases in WOS format (Lastname, Name, e.g Valdez-Gúzman, J.A.) with a list of registered affiliations. TODO: Test\n",
    "3. The database from Puntaje (UDEA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete UDEA_columns and start from schratch\n",
    "REBUILD=True\n",
    "MERGE_WITH_TRAINED=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import Levenshtein as lv\n",
    "def get_author_info(x):\n",
    "    sep='; '\n",
    "    authors=[{'WOS_author':x[0].split(sep)[0],'affiliation':[x[0].split(sep)[-1]],'i':0}]\n",
    "    iau=1\n",
    "    for y  in x:\n",
    "        y2=y.replace('[','').replace('] ',sep).split(sep)\n",
    "        for z in y2[:-1]:\n",
    "            aulist=[ d.get('WOS_author') for d in authors]\n",
    "            if z not in aulist:\n",
    "                authors.append({'WOS_author':z,'affiliation':[y2[-1]],'i':iau})\n",
    "                iau=iau+1\n",
    "            else:\n",
    "                if y2[-1] not in [ d.get('affiliation') for d in authors if d.get('WOS_author')==z][0]:\n",
    "                    index_author=[ d.get('i') for d in authors if d.get('WOS_author')==z][0]\n",
    "                    authors[index_author]['affiliation'].append(y2[-1])\n",
    "    return authors\n",
    "\n",
    "def dictionary_list_add_columns(df,df_dl,df_dl_key,df_dl_i,df_columns):\n",
    "    '''\n",
    "    For a\n",
    "     df: Pandas DataFrame \n",
    "    with a:\n",
    "     df_dl: column of list of dictionaries, with\n",
    "     df_dl_key: dictionary key: e.g x=[{df_dl_key:1},{df_dl_key:2}]\n",
    "    for the element df_dl_i of the list:\n",
    "    Update the dictionary with:\n",
    "        df_dl_key==x[df_dl_i][df_dl_key]\n",
    "    with the dictionaries { df_columns[i]: df_columns[i].values }\n",
    "    '''\n",
    "    dff=df.copy()\n",
    "    for key in df_columns:\n",
    "        tmp=dff[df_dl].combine(dff[key],\n",
    "                func=lambda x,y: y if pd.isna(y) \n",
    "                                   else \n",
    "                                     [z.update({key:y}) \n",
    "                                     if z.get(df_dl_key)==x[df_dl_i][df_dl_key] \n",
    "                                     else z \n",
    "                                 for z in x  ] )\n",
    "    return dff\n",
    "\n",
    "def split_full_names(y,full_name='full_name'):\n",
    "    \"\"\"\n",
    "    From an input dictionary with {full_name:'APPELLIDO1 APPELLIDO2 NOMBRES'}\n",
    "    Obtain a dictionary with the several name parts.\n",
    "    \"\"\"    \n",
    "    yy=y.get(full_name).title()\n",
    "    lfn=len(y[full_name].split())\n",
    "    aps=0\n",
    "    d={ 'PRIMER APELLIDO':yy.split()[aps] }\n",
    "    aps=aps+1\n",
    "    if lfn>=4:\n",
    "        names=-2\n",
    "        if lfn==5: # Extra name or last name\n",
    "            yyy=yy.split()\n",
    "            ll=pd.np.array( [len(n) for n in yyy ] )\n",
    "            if ll[3:][ ll[3:]  <= 3 ].shape[0]:\n",
    "                # last_names first_first_name de(l) second_first_name\n",
    "                yy=' '.join( [ y for y in yyy if len(y)>=3] )\n",
    "            else: \n",
    "                # first_last name de(l) second_last_name first_names\n",
    "                tmpll=yyy.pop() # internal memory\n",
    "                yy=' '.join( yyy )  \n",
    "        if len( d['PRIMER APELLIDO'] )<=3:\n",
    "            d['PRIMER APELLIDO']=d['PRIMER APELLIDO']+' '+yy.split()[aps]\n",
    "            aps=aps+1\n",
    "            d.update(  {'SEGUNDO APELLIDO':yy.split()[aps]} )\n",
    "            names=names+1\n",
    "            \n",
    "        d.update({'SEGUNDO APELLIDO':yy.split()[aps]})\n",
    "        aps=aps+1\n",
    "        if len( d['SEGUNDO APELLIDO'] )<=3:\n",
    "            d['SEGUNDO APELLIDO']=d['SEGUNDO APELLIDO']+' '+yy.split()[aps]\n",
    "            if names==-2:\n",
    "                names=names+1\n",
    "    elif lfn>=3:        \n",
    "        d.update({'SEGUNDO APELLIDO':yy.split()[aps]})\n",
    "        names=-1\n",
    "    else: #Colombian interpretation (TODO: Includes Brazilian interpretation)    \n",
    "        names=-1\n",
    "    d.update({'NOMBRES':' '.join( yy.split()[names:]),\n",
    "              'INICIALES':' '.join( [z[0]+'.' for z in yy.split()[names:]] ),\n",
    "              })\n",
    "    if not d.get('SEGUNDO APELLIDO'):\n",
    "        d['SEGUNDO APELLIDO']=''\n",
    "    #if not d.get('NOMBRE COMPLETO'):\n",
    "    #    d['NOMBRE COMPLETO']=''        \n",
    "    return d\n",
    "\n",
    "# Creates mask Search key in a list of dictionay\n",
    "# First apply convert null values to string\n",
    "# Second apply: implement a mask\n",
    "def find_key_in_list_of_dictionaries(df,column,key,pattern):\n",
    "    return df[column].apply(lambda x: \n",
    "                [ '' if pd.isnull( y.get(key)) else y for y in x ]  ).apply(\n",
    "                            lambda x: \n",
    "                [ True if y.get(key).find(pattern)>-1 else False for y in x  ][0]  )\n",
    "\n",
    "def key_contains_in_list_of_dictionaries(df,pattern,column='authors_WOS',key='WOS_author'):\n",
    "    #TODO: loop in column len\n",
    "    i=0\n",
    "    r=df[ df[column].str[i].apply(lambda x: {} if pd.isnull(x) else x).apply(\n",
    "                       lambda x: x.get(key) if x else '').str.contains(\n",
    "        pattern) ][column].reset_index(drop=True)\n",
    "    return r\n",
    "\n",
    "def update_institutional_authors(kkn,AU,authors_column='UDEA_authors',authors_column_key='full_name',\n",
    "                                        AU_first_last_name='PRIMER APELLIDO',\n",
    "                                        AU_second_last_name='SEGUNDO APELLIDO',\n",
    "                                        AU_first_names='NOMBRES'\n",
    "                                ):\n",
    "    '''\n",
    "    For a Data base containing full names of the authors of the articles: SIU,\n",
    "    include detailed information from other database                    : AU.\n",
    "      authors_column    : kkn Column with dictionary to be updated\n",
    "      authors_column_key: Key with full name as a value in  authors_column of kkn\n",
    "      For Spaniard name, e.g \"Juan Pedro Restrepo Correa\"\n",
    "      AU_first_last_name: AU column with \"Restrepo\"\n",
    "      AU_second_last_name: AU column with \"Correa\"\n",
    "      AU_first_names: AU column with \"Juan Pedro\"\n",
    "      full_name: Colum in AU with full name\n",
    "      \n",
    "    '''\n",
    "    full_name='name_tmp'\n",
    "    AU_columns=list( AU.columns.values )\n",
    "\n",
    "    AU[full_name]=(AU[AU_first_last_name]+' '+AU[AU_second_last_name]+' '+AU[AU_first_names]\n",
    "                  ).str.lower().str.strip().apply( unidecode.unidecode )\n",
    "\n",
    "    maxau=kkn[authors_column].apply(lambda l: [d.get(full_name) for d in l ] \n",
    "                                    if type(l)==list else []).apply(len).max()\n",
    "    \n",
    "    newcolumns=[full_name]+AU_columns\n",
    "    for i in range(maxau):\n",
    "        print(i)\n",
    "        kkn[full_name]=kkn[authors_column].apply(lambda l: [d.get(authors_column_key) for d in l ]\n",
    "                        if type(l)==list else ''\n",
    "                            ).str[i].apply( lambda s: unidecode.unidecode( s.lower().strip()) \n",
    "                                                      if not pd.isna(s) else s)\n",
    "        if not kkn[~kkn[full_name].isna()].empty:\n",
    "            kkn=kkn.merge(AU[newcolumns],on=full_name,how='left').reset_index(drop=True)\n",
    "            kkn=dictionary_list_add_columns(kkn,authors_column,authors_column_key,i,AU_columns)\n",
    "            kkn=kkn.drop(newcolumns,axis='columns')\n",
    "    return kkn\n",
    "\n",
    "def SCI_C1_to_C1(UDEA,C1='C1',Tipo='Tipo',WOS='WOS',SCI='SCI',affil='Univ Antioquia',\n",
    "            SCI_C1='SCI_C1',\n",
    "            regex_normalize_affilliation_SCI=['Universidad de Antioquia','Univ. de Antioquia']):\n",
    "    UDEA_SCI=UDEA[SCI_C1].combine(UDEA[Tipo],\n",
    "                    func=lambda x,y: x if y.find(SCI)>-1 and y.find(WOS)==-1 else None)\n",
    "    for bad_affil in regex_normalize_affilliation_SCI:\n",
    "        UDEA_SCI=UDEA_SCI.apply(lambda x:x.replace(\n",
    "            bad_affil,affil) if not pd.isnull(x) else x)\n",
    "    #Update only if not filled already\n",
    "    return UDEA_SCI.combine(UDEA[C1],lambda x,y:x if pd.isnull(y) else y)\n",
    "\n",
    "def SCP_Authors_with_affiliations_to_C1(UDEA,C1='C1',Tipo='Tipo',SCP='SCP',\n",
    "            affil='Univ Antioquia',SCP_C1='SCP_Authors with affiliations',\n",
    "            lastname='[\\w\\-\\.\\s]+',firstname='[\\w\\-\\.]+',\n",
    "            regex_normalize_affilliation_SCP=['Universi[dadty]{2,3}\\s+[deofDEOF]{2}\\s+Antioqu[ií]a',\n",
    "                                              'U[\\.niv]{1,4}\\s+[deofDEOF]{0,2}\\s*Antioqu[ií]a',\n",
    "                                              'Antioqu[ií]a\\s+[deofDEOF]{0,2}\\s*Universi[dadty]{2,3}']):    \n",
    "    #Remove authors without affiliations\n",
    "    SCP2WOS=UDEA[SCP_C1].str.replace('(^|;\\s+)(({},\\s+{};\\s+)+)'.format( \n",
    "                                        lastname,firstname,lastname,firstname),r'\\1',re.UNICODE\n",
    "                                                     )\n",
    "    SCP2WOS=SCP2WOS.str.replace('; ','\\n').str.replace(\n",
    "                                '^({},{}),'.format( lastname,lastname),r'[\\1]',re.UNICODE).str.replace(\n",
    "                                '\\n({},{}),'.format(lastname,lastname),r'\\n[\\1]',re.UNICODE).str.replace(\n",
    "                                '(,\\s+\\w\\.)(\\w\\.\\])'.format(lastname,lastname),r'\\1 \\2',re.UNICODE)\n",
    "    # Normalize to WOS\n",
    "    for bad_affil in regex_normalize_affilliation_SCP:\n",
    "            SCP2WOS=SCP2WOS.str.replace(bad_affil,affil)\n",
    "    UDEA_SCP=SCP2WOS.combine(UDEA[Tipo],func=lambda x,y: x if y==SCP else None)\n",
    "    #Update only if not filled already\n",
    "    return UDEA_SCP.combine(UDEA[C1],lambda x,y:x if pd.isnull(y) else y)\n",
    "\n",
    "def wos_names_append(wos_names,last_name,first_names,initials):\n",
    "    wos_names=wos_names+[           last_name+', '+first_names]\n",
    "    if len( first_names.split())>1:\n",
    "        wos_names=wos_names+[ last_name+', '+first_names.split()[0] ]\n",
    "    if len( first_names.split())==2 and  len(first_names.split()[-1]):\n",
    "        wos_names=wos_names+[ last_name+', '+first_names.split()[-1] ]\n",
    "    wos_names=wos_names+[ last_name+', '+initials]\n",
    "    if len( initials.split())>1:\n",
    "        wos_names=wos_names+[ last_name+', '+initials.split()[0]]\n",
    "    if len(initials.split())==2:\n",
    "        wos_names=wos_names+[\n",
    "              last_name+', '+first_names.split()[0]+' '+initials.split()[-1] ]\n",
    "        wos_names=wos_names+[last_name+', '+initials.split()[-1] ]\n",
    "    return wos_names\n",
    "    \n",
    "def wos_names_list(dy ,y_keys=['PRIMER APELLIDO','NOMBRES','INICIALES','SEGUNDO APELLIDO','full_name']   ):\n",
    "    \"\"\"\n",
    "    Generate a list of WOS names possibilitites from full name parts.\n",
    "    The full name parts are obtained from dictionary: dy\n",
    "    with keys in the strict order:\n",
    "       y_keys=[first_last_name,names,initials,second_first_name,[full_name]]\n",
    "               otptional full_name is used in general function\n",
    "    Output Example:\n",
    "      ['Pabon, Adriana Lucia',\n",
    "       'Pabon, Adriana',\n",
    "       'Pabon, Lucia',\n",
    "       'Pabon, A. L.',\n",
    "       'Pabon, A.',\n",
    "       'Pabon, Adriana L.',\n",
    "       'Pabon, L.',\n",
    "       'Pabon-Vidal, Adriana Lucia',\n",
    "       'Pabon-Vidal, Adriana',\n",
    "       'Pabon-Vidal, Lucia',\n",
    "       'Pabon-Vidal, A. L.',\n",
    "       'Pabon-Vidal, A.',\n",
    "       'Pabon-Vidal, Adriana L.',\n",
    "       'Pabon-Vidal, L.']\n",
    "    TODO: Initial can be internally generated\n",
    "    \"\"\"\n",
    "    last_name= unidecode.unidecode( dy[y_keys[0]]   )\n",
    "    first_names=unidecode.unidecode( dy[y_keys[1]]  )\n",
    "    initials=unidecode.unidecode( dy[y_keys[2]]  )\n",
    "\n",
    "    wos_names=[]\n",
    "    wos_names=wos_names_append(wos_names,last_name,first_names,initials)\n",
    "    \n",
    "    if dy.get( y_keys[3] ):\n",
    "        last_names= unidecode.unidecode( dy[y_keys[0]]+'-'+dy[y_keys[3]]   )\n",
    "        wos_names=wos_names_append(wos_names,last_names,first_names,initials)\n",
    "    return wos_names\n",
    "    \n",
    "def combinewos(x,y,x_keys=['WOS_author','affiliation'],\n",
    "                   y_keys=['PRIMER APELLIDO','NOMBRES','INICIALES','SEGUNDO APELLIDO','full_name'],\n",
    "                   xy_keys=['WOS_author','WOS_affiliation']):\n",
    "    if type(x)==list and type(y)==list:\n",
    "        for dx in x:\n",
    "            wos_name=unidecode.unidecode( dx[ x_keys[0] ] )\n",
    "            WOS_affiliation= dx[x_keys[1]]\n",
    "            # Try by buildinng spanish-like names list                                \n",
    "            for i in range( len(y) ):\n",
    "                if wos_name.title() in wos_names_list(y[i] ,y_keys):\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            #Try again but comparing full lists\n",
    "            wos_name_to_list=wos_name.replace(',','').replace('-',' ').title().split()\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=unidecode.unidecode( y[i][y_keys[4]].title() )\n",
    "                if yi_to_list:\n",
    "                    yi_to_list=yi_to_list.split()\n",
    "                else:\n",
    "                    yi_to_list=[]\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            #Try again but comparing full lists with initials\n",
    "            wos_name_to_list=wos_name.replace(',','').replace('-',' ').title().split()\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]] ]+y[i][y_keys[2]].split()\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break\n",
    "            #Try again but comparing full lists with first first name and initial\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]],y[i][y_keys[1]].split()[0],\n",
    "                              y[i][y_keys[2]].split()[-1]]\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break                    \n",
    "            #Try again but comparing full lists with second first name and initial\n",
    "            for i in range( len(y) ):\n",
    "                yi_to_list=[y[i][y_keys[0]],y[i][y_keys[3]],y[i][y_keys[1]].split()[-1],\n",
    "                              y[i][y_keys[2]].split()[0]]\n",
    "                if not pd.np.setdiff1d(wos_name_to_list,yi_to_list).shape[0]:\n",
    "                    y[i][  xy_keys[0] ]=[ wos_name ]\n",
    "                    y[i][  xy_keys[1] ]=WOS_affiliation\n",
    "                    break                    \n",
    "                    \n",
    "                    \n",
    "    return y\n",
    "\n",
    "def extract_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "    list_of_dictionaries='UDEA_authors',\n",
    "    dictionary_key='WOS_author'):\n",
    "    #Extract internal value of a dictionary key in a list of dictionaries and empty list otherwise\n",
    "    \n",
    "    return df[list_of_dictionaries].apply(lambda x: [y.get(dictionary_key) \n",
    "                                                        if y.get(dictionary_key) else []   \n",
    "                                                        for y in x  ]\n",
    "                           if type(x)==list else [])\n",
    "\n",
    "def extract_internal_list_as_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "    list_of_dictionaries='UDEA_authors',\n",
    "    dictionary_key='WOS_author'):\n",
    "    #Extract internal list as value of a dictionary key in a list of dictionaries and empty list otherwise\n",
    "    \n",
    "    return extract_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "                    list_of_dictionaries,dictionary_key).apply(lambda x: \n",
    "                           [item for sublist  in x for item in sublist] \n",
    "                            if type(x)==list else x)\n",
    "\n",
    "def mask_on_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "    pattern='RESTREPO QUINTERO DIEGO ALEJANDRO',\n",
    "    list_of_dictionaries='UDEA_authors',dictionary_key='full_name'):\n",
    "    \"\"\"\n",
    "    Build a mask for a Pandas Series of list of dictionaries of label:\n",
    "      list_of_dictionaries. \n",
    "    The:\n",
    "      dictionary_key must be a single value like string or float\n",
    "    \"\"\"\n",
    "    return extract_internal_value_of_a_dictionary_key_in_a_list_of_dictionaries(df,\n",
    "            list_of_dictionaries,dictionary_key).apply( \n",
    "            lambda x: pattern in x)\n",
    "\n",
    "def fill_trained_data(UDEA,SIU,UDEA_authors='UDEA_authors',semicolon_authors='UDEA_autores',Tipo='Tipo',\n",
    "                      Tipo_prefix='UDEA',full_name='full_name',DI='DI',TI='TI',\n",
    "                      REMOVE_UDEA_columns=True,\n",
    "                     udea_columns=[       'UDEA_autores',\n",
    "           'UDEA_año realiz', 'UDEA_doi', 'UDEA_fecha aplicación',\n",
    "           'UDEA_idioma', 'UDEA_item adic', 'UDEA_material', 'UDEA_nombre',\n",
    "           'UDEA_nombre revista o premio', 'UDEA_nro autores', 'UDEA_país',\n",
    "           'UDEA_procodigo', 'UDEA_ptos', 'UDEA_simple_doi', 'UDEA_título',\n",
    "           'UDEA_valor item','UDEA_authors']):\n",
    "    SIU=SIU[SIU[Tipo].str.contains('\\+{}'.format(Tipo_prefix))].reset_index(drop=True)\n",
    "\n",
    "    SIU[semicolon_authors]=SIU[semicolon_authors].str.replace('\\s+',' ')\n",
    "\n",
    "    SIU[UDEA_authors]=SIU[semicolon_authors].str.split(';').apply(lambda x: [{full_name:y} for y in x ])\n",
    "    \n",
    "    #Be sure that always be True. The columns will be obtaied from SIU\n",
    "    REMOVE_UDEA_columns=True\n",
    "    if REMOVE_UDEA_columns:\n",
    "        UDEA_columns=[c for c in UDEA.columns if c.find('{}_'.format(Tipo_prefix))>-1]\n",
    "        UDEA=UDEA.drop(UDEA_columns,axis='columns')    \n",
    "\n",
    "    SIUDI=SIU[~SIU[DI].isna()].drop_duplicates(DI).reset_index(drop=True)\n",
    "    SIUTI=SIU[ SIU[DI].isna()].drop_duplicates(TI).reset_index(drop=True)\n",
    "    SIUTI=SIUTI[SIUTI!=''].reset_index(drop=True)\n",
    "    SIUTI=SIUTI[~SIUTI[TI].isnull()].reset_index(drop=True)\n",
    "    SIUTI=SIUTI[ SIUTI[TI].apply(len)>20 ].reset_index(drop=True)\n",
    "\n",
    "    UDEADI=UDEA[UDEA[DI]!=''].drop_duplicates(DI).reset_index(drop=True)\n",
    "    UDEATI=UDEA[UDEA[DI]==''].drop_duplicates(TI).reset_index(drop=True)\n",
    "\n",
    "    UDEA_mergeDI=UDEADI.merge( SIUDI[ [DI]+udea_columns ],on=DI,how='left' )\n",
    "\n",
    "    UDEA_PTJ=pd.DataFrame()\n",
    "    UDEA_PTJ_NOT=pd.DataFrame()\n",
    "    UDEA_PTJ=UDEA_mergeDI[~UDEA_mergeDI[semicolon_authors].isna()].reset_index(drop=True)\n",
    "    UDEA_PTJ_NOT=UDEA_mergeDI[UDEA_mergeDI[semicolon_authors].isna()].reset_index(drop=True)\n",
    "\n",
    "    UDEATI['tmptitle']=UDEATI[TI].str.strip()\n",
    "    SIUTI['tmptitle']=SIUTI[TI].str.strip()\n",
    "\n",
    "    kk=UDEATI.merge( SIUTI[ ['tmptitle']+udea_columns ],on='tmptitle',how='left' ).drop('tmptitle',axis='columns')\n",
    "\n",
    "    UDEA_PTJ=UDEA_PTJ.append( kk[ ~kk[semicolon_authors].isna() ] ).reset_index(drop=True)\n",
    "    UDEA_PTJ_NOT=UDEA_PTJ_NOT.append( kk[ kk[semicolon_authors].isna() ] ).reset_index(drop=True)\n",
    "\n",
    "    print(UDEA_PTJ.shape[0]+UDEA_PTJ_NOT.shape[0],UDEA.shape)\n",
    "\n",
    "    print(UDEA_PTJ.shape,UDEA_PTJ_NOT.shape)\n",
    "\n",
    "    UDEA=UDEA_PTJ.append(\n",
    "        UDEA_PTJ_NOT).reset_index(\n",
    "        drop=True)    \n",
    "    return UDEA,SIU\n",
    "\n",
    "def build_udea_authors(UDEA,UDEA_authors='UDEA_authors',authors_WOS='authors_WOS'):\n",
    "    aumax=UDEA[UDEA_authors].dropna().apply(len).max() \n",
    "    ua=pd.DataFrame()\n",
    "    if type(aumax)!=int:\n",
    "        aumax=1\n",
    "    for i in range(aumax):\n",
    "        kkk=pd.DataFrame()\n",
    "        kkk[UDEA_authors]= UDEA[UDEA_authors].str[i].dropna()\n",
    "        kkk[authors_WOS]= UDEA[authors_WOS]\n",
    "        #kkk['SCP_Authors']=UDEA['SCP_Authors']\n",
    "        kkk['tmp_str']=kkk['UDEA_authors'].astype(str)\n",
    "        kkk=kkk.drop_duplicates('tmp_str')\n",
    "        ua=ua.append(kkk).reset_index(drop=True)\n",
    "\n",
    "    ua['tmp_author']=ua[UDEA_authors].apply( \n",
    "            lambda d: d.get('full_name') if type(d)==dict else d)\n",
    "        \n",
    "    ua[authors_WOS]=ua[authors_WOS].apply(lambda l: l if l else pd.np.nan)\n",
    "    ua=ua[~ua[authors_WOS].isna()].reset_index(drop=True)        \n",
    "    return ua\n",
    "\n",
    "def DataFrame_authors(UDEA,UDEA_authors='UDEA_authors',\n",
    "                      WOS_affiliation='WOS_affiliation',\n",
    "                     WOS_author='WOS_author'):\n",
    "    ua=build_udea_authors(UDEA)\n",
    "    full_names=ua['tmp_author'].unique()\n",
    "    aunly=pd.DataFrame()\n",
    "    for f in full_names:\n",
    "        clear_output(wait=True)\n",
    "        print(f)    \n",
    "        kk=pd.DataFrame( { 'tmp_author':[f]  } ).merge(\n",
    "              ua[['tmp_author','UDEA_authors']],on='tmp_author',how='left')\n",
    "\n",
    "        kk['tmp_str']=kk[UDEA_authors].astype(str)\n",
    "\n",
    "        kk=kk.drop_duplicates('tmp_str').dropna()#[['tmp_author','UDEA_authors']]\n",
    "\n",
    "        try:\n",
    "            laff=list( kk[UDEA_authors].apply(lambda d: d.get( WOS_affiliation )\n",
    "                                         ).dropna().apply(pd.Series).stack().unique() )\n",
    "            lau=list( kk[UDEA_authors].apply(lambda d: d.get( WOS_author )\n",
    "                                         ).dropna().apply(pd.Series).stack().unique() )\n",
    "        except AttributeError:\n",
    "            laff=[];lau=[]\n",
    "\n",
    "        if len(laff)>0 and len(lau)>0:\n",
    "            tmpupdate=kk['UDEA_authors'].apply(lambda d: d.update({WOS_author:lau,WOS_affiliation:laff}) )\n",
    "\n",
    "            kk['tmp_str']=kk[UDEA_authors].astype(str)\n",
    "\n",
    "            kk=kk.drop_duplicates('tmp_str')\n",
    "\n",
    "            kk['tmp_len']=kk['tmp_str'].apply(len)#.astype(str)\n",
    "\n",
    "            aunly=aunly.append( kk.sort_values('tmp_len',ascending=False).drop(index=kk.index[1:]).drop(\n",
    "                   ['tmp_str','tmp_len'],axis='columns') ).reset_index(drop=True)\n",
    "    \n",
    "    return aunly\n",
    "\n",
    "def fill_full_wos_author_info(l,WOS_df,full_name='full_name',full_name_column='tmp_author',\n",
    "                               WOS_column='UDEA_authors',WOS_author='WOS_author',\n",
    "                               WOS_affiliation='WOS_affiliation'):\n",
    "    '''\n",
    "    WOS_df=aunly\n",
    "    '''\n",
    "    newl=[]\n",
    "    if type(l)==list:\n",
    "        for d in l:\n",
    "            if d.get('WOS_author'):\n",
    "                #find in aunly\n",
    "                mtch=WOS_df[WOS_df[full_name_column]==d.get(full_name)].reset_index(drop=True)\n",
    "                if mtch.shape[0]==1:\n",
    "                    #update d\n",
    "                    if mtch[WOS_column].loc[0].get(WOS_author):\n",
    "                        d[WOS_author]=mtch[WOS_column].loc[0].get(WOS_author)\n",
    "                        d[WOS_affiliation]=mtch[WOS_column].loc[0].get(WOS_affiliation)\n",
    "            newl.append(d)\n",
    "    else:\n",
    "        newl=l\n",
    "    return newl\n",
    "\n",
    "\n",
    "def find_author_affiliation(author,affiliation,author_df,column='UDEA_authors',\n",
    "                            author_key='WOS_author',affiliation_key='WOS_affiliation',ratio=0.9):\n",
    "    '''\n",
    "    author_df=aunly\n",
    "    find the WOS+\"UDEA puntaje\" dictionary for WOS author:   `author`\n",
    "    and WOS affiliation:                                    `affiliation`\n",
    "    The information is  searched in \n",
    "    WOS+\"UDEA puntaje\" DataFrame:                            `author_df`, \n",
    "    which has the column:                                    `column` \n",
    "    which contains a dictionary with list value for the key: `author_key`\n",
    "    and list value for the key:                              `affiliation_key`.\n",
    "    Affiliation must be similar until a Levenshtein ratio:   `ratio`\n",
    "    '''\n",
    "    if not author_df.empty:\n",
    "        au=author_df[ author_df[column].apply(\n",
    "                    lambda d: d.get(author_key) if type(d)==dict else '').apply(\n",
    "                      lambda l: author in l)]#.reset_index(drop=True).loc[0,column]\n",
    "    else:\n",
    "        au=pd.DataFrame()\n",
    "        \n",
    "    if au.shape[0]>0:\n",
    "        #Fast\n",
    "        auf=au[au[column].apply(\n",
    "                 lambda d: d.get(affiliation_key) if type(d)==dict else '').apply(\n",
    "                 lambda l: affiliation in l)]\n",
    "        \n",
    "\n",
    "        if auf.shape[0]>0:\n",
    "              return auf.reset_index(drop=True).loc[0,column]          \n",
    "        #Slow\n",
    "        else:\n",
    "            aus=au[au[column].apply(\n",
    "                 lambda d: d.get(affiliation_key) if type(d)==dict else '').apply(\n",
    "                 lambda l: len( [af for af in l if lv.ratio(af,affiliation) > ratio ] )>0 )]\n",
    "\n",
    "            if aus.shape[0]==1: #fix 1 to avoid homonymous\n",
    "                dold=aus.reset_index(drop=True).loc[0,column]\n",
    "                # Dictionary is automatically updated in author_df!\n",
    "                dold[affiliation_key]=dold[affiliation_key]+[affiliation]\n",
    "                return dold\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_UDEA_authors(x,y,author_df,x_author_key='WOS_author',x_affiliation_key='affiliation',\n",
    "                        column='UDEA_authors',\n",
    "                        author_key='WOS_author',affiliation_key='WOS_affiliation',\n",
    "                        ratio=0.9):\n",
    "    '''\n",
    "    author_df=aunly\n",
    "    get the WOS+\"UDEA puntaje\" list of dictionaries for WOS author list \n",
    "    and affiliation list in the  list of dictionaries:      `x`, \n",
    "    where each dictionary have the string value for the key: `x_author_key`, \n",
    "    and the list value for the key:                          `x_affiliation_key`.\n",
    "    The information is obtained directly from the \n",
    "    WOS+\"UDEA puntaje\" list:                                 `y` \n",
    "    if already there, or searched in \n",
    "    WOS+\"UDEA puntaje\" DataFrame:                            `author_df`, \n",
    "    which has the column:                                    `column` \n",
    "    which contains a dictionary with list value for the key: `author_key`\n",
    "    and list value for the key:                              `affiliation_key`.\n",
    "    If not foun None is returned.\n",
    "    WOS info can be changed for other standarized dababase info\n",
    "    and \"UDEA puntaje\" can be changed from any other full name author\n",
    "    and affiliation info.\n",
    "    \n",
    "    IMPORTANT:\n",
    "    The list of values in:                                   `affiliation_key` \n",
    "    is automatically updated with the similar first \n",
    "    affiliation value of the list in:                        `x_affiliation_key`\n",
    "    according with the Levenshtein similarity ratio:         `ratio`\n",
    "    '''\n",
    "    if type(y)==list:\n",
    "        #already filled:\n",
    "        return y\n",
    "\n",
    "    au=[]\n",
    "    if ( type(x)==list and x):\n",
    "        for j in range(len(x)):\n",
    "            xx=find_author_affiliation(x[j].get(x_author_key),x[j].get(x_affiliation_key)[0],\n",
    "                                        author_df=author_df,\n",
    "                                        author_key=author_key,\n",
    "                                        affiliation_key=affiliation_key,\n",
    "                                        ratio=ratio )\n",
    "            if xx:\n",
    "                au.append(xx)\n",
    "    if au:\n",
    "        return au\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhk2ZGEDd2Yo"
   },
   "outputs": [],
   "source": [
    "import wosplus as wp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "pd.set_option('display.max_colwidth',200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "JS7jD1f47JUN"
   },
   "source": [
    "##  Configure public links of  files in Google Drive\n",
    "* If it is a Google Spreadsheet the corresponding file is downloaded as CSV\n",
    "* If it is in excel or text file the file is downloaded  directly\n",
    "\n",
    "To define your  own labeled IDs for public google drive files edit the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "hidden": true,
    "id": "T4Rmd2dF7JUQ",
    "outputId": "39a5835e-1b38-48b6-f1a5-e9964c846123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting drive.cfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile drive.cfg\n",
    "[FILES]\n",
    "WOS_SCI_SCP_PTJ_CTR.json.gz=19E1C1kRk4I0V3uXojqko8-NEicWaPp1j\n",
    "WOS_SCP_UDEA_SJR_SIU.xlsx=0BxoOXsn2EUNIQ3R4WDhvSzVLQ2s\n",
    "Base_de_datos_investigadores_Definitiva.csv=12oalgUeKhpvzkTPBP8pXCeHTrF-KO223dy9ov9w9QKs\n",
    "UDEA_authors_with_WOS_info.json=1o1eVT4JD0FMMICq_oxrTJOzWh47veBMw\n",
    "produccion_fecha_vig_2003_2018.xlsx=1WbtX4K__TTLxXRjuLvqUYz9tuHCIlS5v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0D0hEdAMXUX"
   },
   "source": [
    "##  Load data bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "occzrIeCS7aQ",
    "outputId": "17b144f3-eef0-4c8a-c2b4-10c8fe55802c"
   },
   "outputs": [],
   "source": [
    "affil='Univ Antioquia'\n",
    "drive_files=wp.wosplus('drive.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEBUG: if False stop in UDEA_PTJ!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oq9QM3cBYH0a"
   },
   "outputs": [],
   "source": [
    "UDEAjsonfile='WOS_SCI_SCP_PTJ_CTR.json.gz'\n",
    "if os.path.exists(UDEAjsonfile):\n",
    "    UDEA=               pd.read_json(UDEAjsonfile,compression='gzip').reset_index(drop=True)\n",
    "else:    \n",
    "    UDEA=drive_files.read_drive_json(UDEAjsonfile,compression='gzip').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REBUILD:\n",
    "    UDEA=UDEA.drop([ c for c in UDEA.columns if c.find('UDEA_')>-1  ],axis='columns')\n",
    "    UDEA['UDEA_authors']=None\n",
    "    UDEA['Tipo']=UDEA['Tipo'].str.replace('_{0,1}UDEA','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCI:2892\n",
      "WOS_SCP:5820\n",
      "WOS_SCI_SCP:768\n",
      "SCP:2573\n",
      "SCI_SCP:1616\n",
      "WOS:1884\n",
      "WOS_SCI:147\n"
     ]
    }
   ],
   "source": [
    "for t in UDEA.Tipo.unique():\n",
    "    print( '{}:{}'.format( t, UDEA[ UDEA.Tipo==t].shape[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15700, 153)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fill C1 for not WOS entries in WOS format and extract  affiliation from C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill from SCI_C1\n",
    "UDEA['C1']=SCI_C1_to_C1(UDEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fill from SCP_C1='SCP_Authors with affiliations\n",
    "UDEA['C1']=SCP_Authors_with_affiliations_to_C1(UDEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 153)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[UDEA['C1'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Puerta Suarez, Jenniffer; Sanchez, Leonardo R.; Salazar, Florencia C.; Saka, Hector A.; Rivero, Virginia E.; Motrich, Ruben D.] Univ Natl Cordoba, Fac Ciencias Quim, CONICET, CIBICI,Haya Torre Med Allende, RA-5016 Cordoba, Argentina.\\n[Puerta Suarez, Jenniffer; Cardona Maya, Walter D.] Univ Antioquia, SIU, Fac Med, Grp Reprod, Lab 534, Medellin 1226, Colombia.\\n[Molina, Rosa; Tissera, Andrea] LAR, RA-5016 Cordoba, Argentina.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[UDEA.Tipo=='WOS'].reset_index(drop=True).C1.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA['authors_WOS']=UDEA.C1.apply(lambda x: x.split('\\n') if x else x).apply(\n",
    "    lambda x:   [y.replace('[','').replace('] ','; ') for y in x if y.find(affil)>-1 ] if x else x ).apply(\n",
    "     lambda x: get_author_info(x) if x else x)\n",
    "\n",
    "# Improve normalization: remove C1s with only affiliation (from Scielo)\n",
    "UDEA['authors_WOS']=UDEA['authors_WOS'].apply( \n",
    "    lambda x: [d for d in x if d.get('WOS_author').find(affil)==-1] if type(x)==list else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'WOS_author': 'Páez-Zapata, E.',\n",
       "  'affiliation': ['Univ Antioquia, Medellín, Colombia'],\n",
       "  'i': 0},\n",
       " {'WOS_author': 'Posada, I. C.',\n",
       "  'affiliation': ['Univ Antioquia, Medellín, Colombia'],\n",
       "  'i': 1}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[UDEA.Tipo=='SCP'].reset_index(drop=True).loc[0].authors_WOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load trained old data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Merge WOS_SCP_SCI with trained data set PTJ_CTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Merge requires split in DI and TI\n",
    "\n",
    "\n",
    "15700 (15700, 152)\n",
    "(7072, 169) (8628, 169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15700 (15700, 152)\n",
      "(7072, 169) (8628, 169)\n"
     ]
    }
   ],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    if os.path.exists('WOS_SCP_UDEA_SJR_SIU.xlsx'):\n",
    "        SIU=pd.read_excel('WOS_SCP_UDEA_SJR_SIU.xlsx')\n",
    "    else:    \n",
    "        SIU=drive_files.read_drive_excel('WOS_SCP_UDEA_SJR_SIU.xlsx')\n",
    "        \n",
    "    UDEA,SIU=fill_trained_data(UDEA,SIU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    UDEA.to_json('UDEAtmp.json')\n",
    "    RECOVER=False\n",
    "    if RECOVER:\n",
    "        UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Merge with official researcher list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AU=drive_files.read_drive_excel('Base_de_datos_investigadores_Definitiva.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "(7916, 205) (7916, 205)\n"
     ]
    }
   ],
   "source": [
    "UPDATE_UDEA_authors_with_AU=True\n",
    "if MERGE_WITH_TRAINED:\n",
    "    kkn=SIU.copy()\n",
    "    kkn=update_institutional_authors(kkn,AU)\n",
    "    print(kkn.shape,SIU.shape)\n",
    "    SIU=kkn.copy()\n",
    "    UPDATE_UDEA_authors_with_AU=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (UDEA['UDEA_authors'].dropna().shape[0] and \n",
    "    UPDATE_UDEA_authors_with_AU):\n",
    "    kkn=UDEA.copy()\n",
    "    kkn=update_institutional_authors(kkn,AU)\n",
    "    print(kkn.shape,UDEA.shape)\n",
    "    UDEA=kkn.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'full_name': 'ZAPATA NOREÑA OSCAR ALBERTO', 'CÉDULA': 15386534.0, 'NOMBRE COMPLETO': 'Oscar Alberto Zapata Noreña', 'NOMBRES': 'Oscar Alberto ', 'DEPARTAMENTO': 'Instituto de Física', 'SEGUNDO APELLIDO': 'Noreña', 'PRIMER APELLIDO': 'Zapata', 'GRUPO': 'Grupo de Fenomenologia de Interacciones Fundamentales', 'FACULTAD': 'Facultad de Ciencias Exactas y Naturales'}, {'full_name': 'PONCE GUTIERREZ WILLIAM ANTONIO', 'CÉDULA': 8287417.0, 'NOMBRE COMPLETO': 'William Antonio Ponce Gutierrez', 'NOMBRES': 'William Antonio ', 'DEPARTAMENTO': 'Instituto de Física', 'SEGUNDO APELLIDO': 'Gutierrez', 'PRIMER APELLIDO': 'Ponce', 'GRUPO': 'Grupo de Fenomenologia de Interacciones Fundamentales', 'FACULTAD': 'Facultad de Ciencias Exactas y Naturales'}]\n"
     ]
    }
   ],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    print( SIU[ find_key_in_list_of_dictionaries(SIU,'UDEA_authors','full_name','ZAPATA')\n",
    "              ].UDEA_authors.loc[241] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [{'i': 0, 'WOS_author': 'Granda-Restrepo, Diana', 'affiliation': ['Univ Antioquia, Medellin, Colombia.']}]\n",
       "2    [{'i': 0, 'WOS_author': 'Restrepo, D.', 'affiliation': ['Univ Antioquia, Inst Fis, Medellin, Colombia.']}]\n",
       "Name: authors_WOS, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_contains_in_list_of_dictionaries(UDEA,'Restrepo, D',column='authors_WOS',key='WOS_author').loc[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if UPDATE_UDEA_authors_with_AU:\n",
    "    UDEA.to_json('UDEAtmp.json')\n",
    "    RECOVER=False\n",
    "    if RECOVER:\n",
    "        UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add `UDEA.authors_WOS` info* within `UDEA.UDEA_authors` data**\n",
    "(\\*) obtained from `UDEA.C1`\n",
    "\n",
    "(\\*\\*) Obtained from [puntaje trained old UDEA data](./WOS_SCI_SCP_PTJ_GS_LNS.ipynb#Merge-with-trained-data-set) and the [official researcher list](./WOS_SCI_SCP_PTJ_GS_LNS.ipynb#Merge-with-official-researcher-list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Obtain name parts and initials from full name in `UDEA_authors` dictionary and update `UDEA_authors` with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'UDEA_authors' not in UDEA.columns and REBUILD==False:\n",
    "    sys.exit('Make MERGE_WITH_TRAINED True and run again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain spanish name parts from full name\n",
    "dictupdatetmp=UDEA['UDEA_authors'].apply(lambda x: [y.update( \n",
    "                split_full_names(y,full_name='full_name')  ) if not pd.isnull(\n",
    "                y.get('full_name')) else y for y in x] \n",
    "                                   if type(x)==list \n",
    "                                   else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kk=UDEA['authors_WOS'].combine( UDEA['UDEA_authors'], func=combinewos )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'INICIALES': 'I. C.',\n",
       "  'NOMBRES': 'Isabel Cristina',\n",
       "  'PRIMER APELLIDO': 'Posada',\n",
       "  'SEGUNDO APELLIDO': 'Zapata',\n",
       "  'WOS_affiliation': ['Univ Antioquia, Medellín, Colombia'],\n",
       "  'WOS_author': ['Posada, I. C.'],\n",
       "  'full_name': 'POSADA ZAPATA ISABEL CRISTINA'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA['UDEA_authors'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load output restuls of previous Cell runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build a single profile for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Fill UDEA_authors with WOS_author info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain UDEA_authors DataFrame: `aunly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAMIREZ OSSA DIANA MILENA\n"
     ]
    }
   ],
   "source": [
    "aunly=DataFrame_authors(UDEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not aunly.empty:\n",
    "    aunly.to_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15700, 169)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if RECOVER:\n",
    "    if os.path.exists('UDEA_authors_with_WOS_info.json' ):\n",
    "        aunly=pd.read_json('UDEA_authors_with_WOS_info.json')\n",
    "    else:\n",
    "        aunly=drive_files.read_drive_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aunly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(800, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge UDEA with authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(lambda l:fill_full_wos_author_info(l,aunly) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UDEA['UDEA_authors'].dropna().shape[0]:\n",
    "    UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15700, 169)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=UDEA.authors_WOS.combine(UDEA.UDEA_authors,func=lambda x,y: get_UDEA_authors(x,y,aunly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7072,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.UDEA_authors.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7072,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10960,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8446,), (15700, 169))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.UDEA_authors.dropna().shape,UDEA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "((8446,), (15700, 169))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "((10963,), (15704, 181))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aunly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1461, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1077, 2)\n"
     ]
    }
   ],
   "source": [
    "if not aunly.empty:\n",
    "    print(aunly.drop_duplicates('tmp_author').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not aunly.empty:\n",
    "    aunly.to_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=True\n",
    "if RECOVER:\n",
    "    if os.path.exists('UDEA_authors_with_WOS_info.json' ):\n",
    "        aunly=pd.read_json('UDEA_authors_with_WOS_info.json')\n",
    "    else:\n",
    "        aunly=drive_files.read_drive_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UDEA['UDEA_authors'].dropna().shape[0]:\n",
    "    UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-51-c94594b6b28f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-c94594b6b28f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print 1\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puntaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: pass pandas.load args\n",
    "tmp=drive_files.load_biblio('produccion_fecha_vig_2003_2018.xlsx',prefix='UDEA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Biblio already has a \"Tipo\" column\n"
     ]
    }
   ],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    tmp=drive_files.load_biblio('UDEA_WOS_SCI_SCP_PTJ.json')# TODO CHANGE FOR LAST VERSION IN GOOGLE DRIVE\n",
    "else:\n",
    "    tmp=drive_files.load_biblio('UDEAtmp.json')    \n",
    "#DEBUG\n",
    "#tmp=drive_files.load_biblio('Sample_WOS.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize title translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "septrans=r'(.+)\\((.{10,})\\)$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']['UDEA_título_list']=drive_files.biblio['UDEA'].UDEA_título.str.replace(\n",
    "    septrans,r'\\1;;\\2',re.UNICODE).str.split(';;').apply(\n",
    "   lambda l: [ re.sub( r'^\"','',\n",
    "                      re.sub( r'\"$','', s.strip() )\n",
    "                     ) for s in l] )#.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']['UDEA_doi']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=drive_files.biblio['UDEA'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UDEA'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_files.biblio['UDEA'].Tipo.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0 #1\n",
    "titlec='UDEA_TI'\n",
    "authorc='UDEA_nombre'\n",
    "authorsc='UDEA_autores'\n",
    "drive_files.biblio['UDEA']['UDEA_TI']=drive_files.biblio['UDEA'].UDEA_título_list.str[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46212, 23)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_files.biblio['UDEA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_au=drive_files.biblio['UDEA'][drive_files.biblio['UDEA'].duplicated(subset=[titlec],keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_au=drive_files.biblio['UDEA'][~drive_files.biblio['UDEA'].duplicated(subset=[titlec],keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "single_au[authorsc]=single_au[authorc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46212"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_au.shape[0]+single_au.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDEA_nombre</th>\n",
       "      <th>UDEA_TI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JIMENEZ DEL RIO MARLENE</td>\n",
       "      <td>\"ANALYSIS OF THE HFE GENE (H63D AND C282Y) MUTATIONS IN PATIENTS WITH IRON OVERLOAD, FAMILY MEMBERS AND CONTROLS FROM ANTIOQUIA, NORTHWEST COLOMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VELEZ PARDO CARLOS ALBERTO</td>\n",
       "      <td>\"ANALYSIS OF THE HFE GENE (H63D AND C282Y) MUTATIONS IN PATIENTS WITH IRON OVERLOAD, FAMILY MEMBERS AND CONTROLS FROM ANTIOQUIA, NORTHWEST COLOMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LATORRE SIERRA GUILLERMO</td>\n",
       "      <td>\"ANALYSIS OF THE HFE GENE (H63D AND C282Y) MUTATIONS IN PATIENTS WITH IRON OVERLOAD, FAMILY MEMBERS AND CONTROLS FROM ANTIOQUIA, NORTHWEST COLOMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VILLEGAS LANAU MARIA ISABEL</td>\n",
       "      <td>\"INFECCION DEL SITIO OPERATORIO EN PACIENTES CON TRAUMA ABDOMINAL SOMETIDOS A CIRUGIA: PREDICCION DEL RIESGOY COMPORTAMIENTO DE LOS INDICES NNIS Y SENIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MORALES URIBE CARLOS HERNANDO</td>\n",
       "      <td>\"INFECCION DEL SITIO OPERATORIO EN PACIENTES CON TRAUMA ABDOMINAL SOMETIDOS A CIRUGIA: PREDICCION DEL RIESGOY COMPORTAMIENTO DE LOS INDICES NNIS Y SENIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CARDONA CADAVID HENRY</td>\n",
       "      <td>\"INHERITED TROMBOPHILIA IS ASSOCIATED WITH DEEP VEIN TROMBOSIS IN A COLOMBIAN POPULATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BEDOYA BERRIO GABRIEL DE JESUS</td>\n",
       "      <td>\"INHERITED TROMBOPHILIA IS ASSOCIATED WITH DEEP VEIN TROMBOSIS IN A COLOMBIAN POPULATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      UDEA_nombre  \\\n",
       "0         JIMENEZ DEL RIO MARLENE   \n",
       "1      VELEZ PARDO CARLOS ALBERTO   \n",
       "2        LATORRE SIERRA GUILLERMO   \n",
       "3     VILLEGAS LANAU MARIA ISABEL   \n",
       "4   MORALES URIBE CARLOS HERNANDO   \n",
       "5           CARDONA CADAVID HENRY   \n",
       "6  BEDOYA BERRIO GABRIEL DE JESUS   \n",
       "\n",
       "                                                                                                                                                    UDEA_TI  \n",
       "0       \"ANALYSIS OF THE HFE GENE (H63D AND C282Y) MUTATIONS IN PATIENTS WITH IRON OVERLOAD, FAMILY MEMBERS AND CONTROLS FROM ANTIOQUIA, NORTHWEST COLOMBIA  \n",
       "1       \"ANALYSIS OF THE HFE GENE (H63D AND C282Y) MUTATIONS IN PATIENTS WITH IRON OVERLOAD, FAMILY MEMBERS AND CONTROLS FROM ANTIOQUIA, NORTHWEST COLOMBIA  \n",
       "2       \"ANALYSIS OF THE HFE GENE (H63D AND C282Y) MUTATIONS IN PATIENTS WITH IRON OVERLOAD, FAMILY MEMBERS AND CONTROLS FROM ANTIOQUIA, NORTHWEST COLOMBIA  \n",
       "3  \"INFECCION DEL SITIO OPERATORIO EN PACIENTES CON TRAUMA ABDOMINAL SOMETIDOS A CIRUGIA: PREDICCION DEL RIESGOY COMPORTAMIENTO DE LOS INDICES NNIS Y SENIC  \n",
       "4  \"INFECCION DEL SITIO OPERATORIO EN PACIENTES CON TRAUMA ABDOMINAL SOMETIDOS A CIRUGIA: PREDICCION DEL RIESGOY COMPORTAMIENTO DE LOS INDICES NNIS Y SENIC  \n",
       "5                                                                  \"INHERITED TROMBOPHILIA IS ASSOCIATED WITH DEEP VEIN TROMBOSIS IN A COLOMBIAN POPULATION  \n",
       "6                                                                  \"INHERITED TROMBOPHILIA IS ASSOCIATED WITH DEEP VEIN TROMBOSIS IN A COLOMBIAN POPULATION  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_au=multi_au.sort_values(titlec).reset_index(drop=True)\n",
    "multi_au[[authorc,titlec]][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_old=''\n",
    "au_old=pd.np.nan\n",
    "for i in multi_au.index:\n",
    "    t=multi_au.loc[i,titlec]\n",
    "    if t==t_old:\n",
    "        au_old=au_old+';'+multi_au.loc[i,authorc]\n",
    "        multi_au.loc[i-1,authorsc]=pd.np.nan\n",
    "    else:\n",
    "        t_old=t\n",
    "        multi_au.loc[i-1,authorsc]=au_old\n",
    "        au_old=multi_au.loc[i,authorc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_au[[authorc,authorsc,titlec]][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_au.shape[0],multi_au.dropna(subset=[authorsc]).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=(multi_au.dropna(subset=[authorsc]).append(single_au,sort=False)\n",
    "                           ).reset_index(drop=True)\n",
    "drive_files.biblio['UDEA'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.WOS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS'].Tipo.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS']['UDEA_authors']=drive_files.biblio['WOS'].UDEA_authors.apply(lambda x: \n",
    "                                x if type(x)==list else None).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALREADY in PTJ\n",
    "UDEA_PTJ=drive_files.biblio['WOS'][ ~drive_files.biblio['WOS']['UDEA_authors'].isna()].reset_index(drop=True)\n",
    "# Missing PTJ. To be proccesses below\n",
    "UDEA_PTJ_NOT    =drive_files.biblio['WOS'][ drive_files.biblio['WOS']['UDEA_authors'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_PTJ.shape, UDEA_PTJ_NOT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS']=UDEA_PTJ_NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udea_columns=[c for c in drive_files.biblio['WOS'].columns if c.find('UDEA_')>-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS']=drive_files.biblio['WOS'].drop( udea_columns, axis='columns' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG=False\n",
    "if DEBUG:\n",
    "    drive_files.biblio['UDEA']=drive_files.biblio['UDEA'][:10]\n",
    "    drive_files.biblio['WOS']=drive_files.biblio['WOS'][:10]\n",
    "\n",
    "drive_files.UDEA=drive_files.biblio['UDEA']\n",
    "drive_files.WOS =drive_files.biblio['WOS']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=drive_files.merge(left=\"WOS\", right=\"UDEA\",\n",
    "                     left_DOI=\"DI\", left_TI=\"TI\",\n",
    "                     right_DOI=\"UDEA_doi\", right_TI=\"UDEA_TI\",\n",
    "                     left_author=\"AU\", left_year=\"PY\",\n",
    "                     right_author=\"UDEA_nombre\",right_year=\"UDEA_año realiz\",\n",
    "                     left_extra_journal=\"SO\",\n",
    "                     right_extra_journal=\"UDEA_nombre revista o premio\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare new WOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS_UDEA'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean pure PTJ entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos=drive_files.biblio['WOS_UDEA'][drive_files.WOS_UDEA.Tipo!='UDEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos.shape #expected 7094. Ignoring differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_to_UDEA_PTJ=newwos[newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_to_UDEA_PTJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_not_PTJ=newwos[~newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "new_UDEA_not_PTJ.shape[0]+app_to_UDEA_PTJ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['WOS']=new_UDEA_not_PTJ\n",
    "\n",
    "drive_files.biblio['WOS']=drive_files.biblio['WOS'].drop( \n",
    "     [ c for c in drive_files.biblio['WOS'].columns if c.find('UDEA_')>-1  ],\n",
    "       axis='columns')\n",
    "new_UDEA_not_PTJ.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare new UDEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkk=app_to_UDEA_PTJ[['UDEA_TI','Tipo']].merge(drive_files.biblio['UDEA'],on='UDEA_TI',how='right')\n",
    "drive_files.biblio['UDEA']=kkk[kkk.Tipo_x.isna()].drop('Tipo_x',axis='columns'\n",
    "                                              ).rename({'Tipo_y':'Tipo'},axis='columns'\n",
    "                                              ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "drive_files.biblio['UDEA']['UDEA_TI']=drive_files.biblio['UDEA'].UDEA_título_list.str[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drive_files.biblio['UDEA']=drive_files.biblio['UDEA'].dropna(subset=['UDEA_TI']).reset_index(drop=True)\n",
    "\n",
    "kkk[~kkk.Tipo_x.isna()].shape,drive_files.biblio['UDEA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=wp.fill_NaN(drive_files.biblio['UDEA'])\n",
    "drive_files.biblio['WOS'] =wp.fill_NaN(drive_files.biblio['WOS'])    \n",
    "drive_files.UDEA=drive_files.biblio['UDEA']\n",
    "drive_files.WOS =drive_files.biblio['WOS']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=drive_files.merge(left=\"WOS\", right=\"UDEA\",\n",
    "                     left_DOI=\"DI\", left_TI=\"TI\",\n",
    "                     right_DOI=\"UDEA_doi\", right_TI=\"UDEA_TI\",\n",
    "                     left_author=\"AU\", left_year=\"PY\",\n",
    "                     right_author=\"UDEA_nombre\",right_year=\"UDEA_año realiz\",\n",
    "                     left_extra_journal=\"SO\",\n",
    "                     right_extra_journal=\"UDEA_nombre revista o premio\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos=drive_files.WOS_UDEA[drive_files.WOS_UDEA.Tipo!='UDEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_to_UDEA_PTJ_2=newwos[newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "app_to_UDEA_PTJ_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_not_PTJ=newwos[~newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "new_UDEA_not_PTJ.shape[0]+app_to_UDEA_PTJ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_2=newwos[~newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "drive_files.biblio['WOS']=new_UDEA_not_PTJ\n",
    "\n",
    "drive_files.biblio['WOS']=drive_files.biblio['WOS'].drop( \n",
    "     [ c for c in drive_files.biblio['WOS'].columns if c.find('UDEA_')>-1  ],\n",
    "       axis='columns')\n",
    "drive_files.biblio['WOS'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UDEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkk=app_to_UDEA_PTJ_2[['UDEA_TI','Tipo']].merge(drive_files.biblio['UDEA'],on='UDEA_TI',how='right')\n",
    "drive_files.biblio['UDEA']=kkk[kkk.Tipo_x.isna()].drop('Tipo_x',axis='columns'\n",
    "                                              ).rename({'Tipo_y':'Tipo'},axis='columns'\n",
    "                                              ).reset_index(drop=True)\n",
    "\n",
    "drive_files.biblio['UDEA']['UDEA_TI']=drive_files.biblio['UDEA'].UDEA_título\n",
    "drive_files.biblio['UDEA']=drive_files.biblio['UDEA'].dropna(subset=['UDEA_TI']).reset_index(drop=True)\n",
    "kkk[~kkk.Tipo_x.isna()].shape,drive_files.biblio['UDEA'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=wp.fill_NaN(drive_files.biblio['UDEA'])\n",
    "drive_files.biblio['WOS'] =wp.fill_NaN(drive_files.biblio['WOS'])    \n",
    "drive_files.UDEA=drive_files.biblio['UDEA']\n",
    "drive_files.WOS =drive_files.biblio['WOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=drive_files.merge(left=\"WOS\", right=\"UDEA\",\n",
    "                     left_DOI=\"DI\", left_TI=\"TI\",\n",
    "                     right_DOI=\"UDEA_doi\", right_TI=\"UDEA_título\",\n",
    "                     left_author=\"AU\", left_year=\"PY\",\n",
    "                     right_author=\"UDEA_nombre\",right_year=\"UDEA_año realiz\",\n",
    "                     left_extra_journal=\"SO\",\n",
    "                     right_extra_journal=\"UDEA_nombre revista o premio\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos=drive_files.WOS_UDEA[drive_files.WOS_UDEA.Tipo!='UDEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_to_UDEA_PTJ_tot=newwos[newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "app_to_UDEA_PTJ_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_not_PTJ=newwos[~newwos.Tipo.str.contains('UDEA')].reset_index(drop=True)\n",
    "new_UDEA_not_PTJ.shape[0]+app_to_UDEA_PTJ_tot.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update aunly and pass again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the total UDEA_PTJ ~2500 runs againt WOS_SCI_SCP_PTJ.json  and add UDEA_authors info and extrapolates new ones ~500. We will have new ~3000 for a total of 11000~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qq=pd.read_json('WOS_SCI_SCP_PTJ.json.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ c for c in drive_files.biblio['WOS'].columns if c.find('UDEA_')>-1  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_PTJ=app_to_UDEA_PTJ.append(app_to_UDEA_PTJ_2).append(app_to_UDEA_PTJ_tot).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_not_PTJ=new_UDEA_not_PTJ.drop([ c for c in new_UDEA_not_PTJ.columns if c.find('UDEA_')>-1  ],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_PTJ=new_UDEA_PTJ.drop_duplicates('TI').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_PTJ.shape,new_UDEA_not_PTJ.shape,new_UDEA_PTJ.shape[0]+new_UDEA_not_PTJ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_UDEA_PTJ=pd.read_json('new_UDEA_PTJ.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_PTJ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ c for c in UDEA_PTJ.columns if c.find('UDEA_')>-1  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ c for c in new_UDEA_PTJ.columns if c.find('UDEA_')>-1  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_UDEA_PTJ=new_UDEA_PTJ.rename({'UDEA_DOI':'UDEA_doi','UDEA_nombres':'UDEA_autores'},axis='columns')\n",
    "new_UDEA_PTJ=new_UDEA_PTJ.drop('UDEA_TI',axis='columns')\n",
    "new_UDEA_PTJ=new_UDEA_PTJ.rename({'UDEA_pais prod':'UDEA_país','UDEA_puntos':'UDEA_ptos'},axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_PTJ[['UDEA_título','UDEA_nombre','UDEA_autores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkn=new_UDEA_PTJ.copy()\n",
    "\n",
    "kkn['UDEA_autores']=kkn['UDEA_autores'].str.replace('\\s+',' ')\n",
    "kkn['UDEA_authors']=kkn['UDEA_autores'].str.split(';').apply(lambda x: [{'full_name':y} for y in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kkn.shape[0]:\n",
    "    AU=drive_files.read_drive_excel('Base_de_datos_investigadores_Definitiva.csv')\n",
    "    kkn=update_institutional_authors(kkn,AU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_UDEA_PTJ=kkn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(UDEA_PTJ.shape,new_UDEA_PTJ.shape,new_UDEA_not_PTJ.shape,\n",
    " UDEA_PTJ.shape[0]+new_UDEA_PTJ.shape[0]+new_UDEA_not_PTJ.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA=UDEA_PTJ.append( new_UDEA_PTJ.append( new_UDEA_not_PTJ,sort=False ),\n",
    "                     sort=False ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.to_json('WOS_SCI_SCP_PTJ_CTR.json.gz',compression='gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMP"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "merge.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
