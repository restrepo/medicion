{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/restrepo/medicion/blob/master/cienciometria/WOS_SCI_SCP_PTJ_CTR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDnqho-CsEwj"
   },
   "source": [
    "# WOS+SCI+SCP+PTJ+CTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the bibliographic datasets for \n",
    "* Web of Science (WOS), \n",
    "* Scielo (SCI)\n",
    "* Scopus  (SCP)\n",
    "* Puntaje (UDEA)\n",
    "* Center (CTR)\n",
    "of the scientific articles of Universidad de Antioquia\n",
    "\n",
    "For details see [merge.ipynb in Colaboratory](https://colab.research.google.com/github/restrepo/medicion/blob/master/cienciometria/merge.ipynb)\n",
    "\n",
    "Implementation:\n",
    "The input pure o partially processed database with WOS-SCI-SCP and may be some UDEA entries from PTJ and Center information with additional data about the Full Name UDEA authors.\n",
    "\n",
    "Addtionaly UDEA entries can be captured from:\n",
    "1. A previous WOS-SCI-SCP-UDEA\n",
    "2. A Data Base with a column with full names (FULL LAST NAMES NAMES, e.g VALDEZ GÚZMAN JUAN ALBERTO) and a list of author Aliases in WOS format (Lastname, Name, e.g Valdez-Gúzman, J.A.) with a list of registered affiliations. TODO: Test\n",
    "3. The database from Puntaje (UDEA). \n",
    "\n",
    "Without PTJ? Check: https://www.kaggle.com/aminer/author-disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check why Antonio Enea Romano does not show up in PTJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "VERSION='NEW'\n",
    "if os.getcwd()=='/content':\n",
    "    !pip install openpyxl xlrd wosplus fuzzywuzzy[speedup] > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete UDEA_columns and start from schratch\n",
    "REBUILD=False\n",
    "MERGE_WITH_TRAINED=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhk2ZGEDd2Yo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wosplus as wp\n",
    "pd.set_option('display.max_colwidth',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load wos_sci_scp_ptj_ctr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wos_sci_scp_ptj_ctr import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "JS7jD1f47JUN"
   },
   "source": [
    "##  Configure public links of  files in Google Drive\n",
    "* If it is a Google Spreadsheet the corresponding file is downloaded as CSV\n",
    "* If it is in excel or text file the file is downloaded  directly\n",
    "\n",
    "To define your  own labeled IDs for public google drive files edit the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "hidden": true,
    "id": "T4Rmd2dF7JUQ",
    "outputId": "39a5835e-1b38-48b6-f1a5-e9964c846123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting drive.cfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile drive.cfg\n",
    "[FILES]\n",
    "WOS_SCI_SCP_PTJ_CTR.json.gz=19E1C1kRk4I0V3uXojqko8-NEicWaPp1j\n",
    "WOS_SCP_UDEA_SJR_SIU.xlsx=0BxoOXsn2EUNIQ3R4WDhvSzVLQ2s\n",
    "Base_de_datos_investigadores_Definitiva.csv=12oalgUeKhpvzkTPBP8pXCeHTrF-KO223dy9ov9w9QKs\n",
    "UDEA_authors_with_WOS_info.json=1o1eVT4JD0FMMICq_oxrTJOzWh47veBMw\n",
    "produccion_fecha_vig_2003_2018.xlsx=1WbtX4K__TTLxXRjuLvqUYz9tuHCIlS5v\n",
    "UDEA_WOS_SCI_SCP_PTJ.json=1OkVytKbxJwGvXZDkynkSoUDtkUOTaT4A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0D0hEdAMXUX"
   },
   "source": [
    "##  Load data bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "occzrIeCS7aQ",
    "outputId": "17b144f3-eef0-4c8a-c2b4-10c8fe55802c"
   },
   "outputs": [],
   "source": [
    "affil='Univ Antioquia'\n",
    "drive_files=wp.wosplus('drive.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEBUG: if False stop in UDEA_PTJ!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oq9QM3cBYH0a"
   },
   "source": [
    "if os.path.exists(UDEAjsonfile):\n",
    "    UDEA=               pd.read_json(UDEAjsonfile,compression='gzip').reset_index(drop=True)\n",
    "else:    \n",
    "    UDEA=drive_files.read_drive_json(UDEAjsonfile,compression='gzip').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REBUILD:\n",
    "    !rm WOS_SCI_SCP_PTJ_CTR.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Biblio already has a \"Tipo\" column\n"
     ]
    }
   ],
   "source": [
    "RECOVER=True #False for test purposes\n",
    "UDEAjsonfile='WOS_SCI_SCP_PTJ_CTR.json.gz'\n",
    "#Test purposes\n",
    "#UDEAjsonfile='UDEA_WOS_SCI_SCP_PTJ.json'\n",
    "if RECOVER:\n",
    "    #Requieres latest wosplus!\n",
    "    tmp=drive_files.load_biblio(UDEAjsonfile,compression='gzip')# TODO CHANGE FOR LAST VERSION IN GOOGLE DRIVE\n",
    "else:\n",
    "    tmp=drive_files.load_biblio('UDEAtmp.json')\n",
    "    #drive_files.load_biblio(\n",
    "    #  'https://raw.githubusercontent.com/restrepo/medicion/master/cienciometria/data/UDEAtmp300.json'\n",
    "    #    )#Test: 199+1=200 found\n",
    "    \n",
    "UDEA=drive_files.biblio['WOS'].reset_index(drop=True)\n",
    "#DEBUG\n",
    "#UDEA=UDEA.sample(300,replace=True).reset_index(drop=True) #Test: 77 found\n",
    "#tmp=drive_files.load_biblio('Sample_WOS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11681,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=UDEA\n",
    "UDEA_authors='UDEA_authors'\n",
    "kk=df[UDEA_authors].apply(lambda l:\n",
    "             l if type(l)==list\n",
    "             and len(l)>0 else None\n",
    "                ).dropna().reset_index(drop=True)\n",
    "\n",
    "kk[kk.apply(\n",
    "    lambda l: len([1 for d in l if \n",
    "               d.get('full_name')])>0\n",
    "       )].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7717,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk.apply(\n",
    "    lambda l: len([1 for d in l if \n",
    "               d.get('NOMBRE COMPLETO')])>0\n",
    "       )].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10311\n"
     ]
    }
   ],
   "source": [
    "df=UDEA\n",
    "Tipo='Tipo'\n",
    "x=df[df[Tipo].str.contains(\n",
    "      'UDEA')].shape[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting check_quality.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile check_quality.py\n",
    "def check_quality(df,\n",
    "     authors_WOS='authors_WOS',\n",
    "     Tipo='Tipo',\n",
    "     UDEA_authors='UDEA_authors'\n",
    "    ):\n",
    "    import pandas as pd\n",
    "    if authors_WOS in df.columns:\n",
    "        print(authors_WOS)\n",
    "        x=df[authors_WOS].apply(lambda l:\n",
    "                 l if type(l)==list\n",
    "                 and len(l)>0 else None\n",
    "                    ).dropna().shape[0]\n",
    "        print(x)\n",
    "        kk=df[df['TI']=='Leptonic charged Higgs decays in the Zee model'].reset_index(drop=True)\n",
    "        print(kk.loc[0,'TI'],'; authors_WOS:',kk.loc[0,authors_WOS],'; AU:',kk.loc[0,'AU'])\n",
    "    if Tipo in df.columns:        \n",
    "        print('Tipo contains UDEA')\n",
    "        x=df[df[Tipo].str.contains(\n",
    "             'UDEA')].shape[0]\n",
    "        print(x)\n",
    "    if UDEA_authors in df.columns:\n",
    "        print(UDEA_authors)\n",
    "        kk=df[UDEA_authors].apply(lambda l:\n",
    "             l if type(l)==list\n",
    "             and len(l)>0 else None\n",
    "                ).dropna().reset_index(drop=True)\n",
    "        print(kk.shape[0])\n",
    "\n",
    "        print('UDEA_authors → full_names (Extrapolado puntaje)')\n",
    "        x=kk[kk.apply(lambda l: len([1 for d in l if \n",
    "                   d.get('full_name')])>0\n",
    "               )].shape[0]\n",
    "        print(x)\n",
    "    \n",
    "        print('UDEA_authors → \"NOMBRE COMPLETO\" (Extrapolado CENTRO)')\n",
    "        x=kk[kk.apply(lambda l: len([1 for d in l if \n",
    "                   d.get('NOMBRE COMPLETO')])>0\n",
    "               )].shape[0]\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors_WOS\n",
      "13645\n",
      "Leptonic charged Higgs decays in the Zee model ; authors_WOS: [] ; AU: Sierra, DA\n",
      "Restrepo, D\n",
      "\n",
      "Tipo contains UDEA\n",
      "10311\n",
      "UDEA_authors\n",
      "11681\n",
      "UDEA_authors → full_names (Extrapolado puntaje)\n",
      "11681\n",
      "UDEA_authors → \"NOMBRE COMPLETO\" (Extrapolado CENTRO)\n",
      "7717\n"
     ]
    }
   ],
   "source": [
    "from check_quality import *\n",
    "check_quality(UDEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REBUILD:\n",
    "    UDEA=clean_institutional_columns(UDEA,prefix='UDEA',Tipo='Tipo')\n",
    "    UDEA['UDEA_authors']=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOS_SCP_UDEA:4468\n",
      "WOS_UDEA:716\n",
      "WOS_SCI_SCP_UDEA:599\n",
      "SCI_SCP_UDEA:1269\n",
      "WOS_SCI_UDEA:93\n",
      "SCI_UDEA:2082\n",
      "SCP_UDEA:1084\n",
      "WOS:1168\n",
      "SCP:1489\n",
      "WOS_SCP:1352\n",
      "WOS_SCI_SCP:169\n",
      "SCI_SCP:347\n",
      "WOS_SCI:54\n",
      "SCI:810\n"
     ]
    }
   ],
   "source": [
    "for t in UDEA.Tipo.unique():\n",
    "    print( '{}:{}'.format( t, UDEA[ UDEA.Tipo==t].shape[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15700, 181)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load trained old data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Merge WOS_SCP_SCI with trained data set PTJ_CTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Merge requires split in DI and TI\n",
    "\n",
    "\n",
    "15700 (15700, 152)\n",
    "(7072, 169) (8628, 169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIU=drive_files.read_drive_excel('WOS_SCP_UDEA_SJR_SIU.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15700 (15700, 152)\n",
      "(7072, 168) (8628, 168)\n"
     ]
    }
   ],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    if os.path.exists('WOS_SCP_UDEA_SJR_SIU.xlsx'):\n",
    "        SIU=pd.read_excel('WOS_SCP_UDEA_SJR_SIU.xlsx')\n",
    "    else:    \n",
    "        SIU=drive_files.read_drive_excel('WOS_SCP_UDEA_SJR_SIU.xlsx')\n",
    "        \n",
    "    UDEA,SIU=fill_trained_data(UDEA,SIU)#TODO: Remnove SIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MERGE_WITH_TRAINED:\n",
    "    UDEA.to_json('UDEAtmp.json')\n",
    "    RECOVER=False\n",
    "    if RECOVER:\n",
    "        UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'UDEA_autores' in UDEA.columns and UDEA[UDEA['UDEA_autores']==''].shape[0]:\n",
    "    UDEA['UDEA_autores']=UDEA['UDEA_autores'].apply(lambda s: pd.np.nan if type(s)==str and s=='' else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7072\n"
     ]
    }
   ],
   "source": [
    "if 'UDEA_autores' in UDEA.columns:\n",
    "    print(UDEA[UDEA['UDEA_autores']==''].shape[0],UDEA['UDEA_autores'].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors_WOS\n",
      "13645\n",
      "Leptonic charged Higgs decays in the Zee model ; authors_WOS: [] ; AU: Sierra, DA\n",
      "Restrepo, D\n",
      "\n",
      "Tipo contains UDEA\n",
      "10311\n"
     ]
    }
   ],
   "source": [
    "check_quality(UDEA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puntaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UDEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq=UDEA.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15700, 168)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_files.biblio['WOS']=qq\n",
    "drive_files.biblio['WOS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=drive_files.load_biblio('produccion_fecha_vig_2003_2018.xlsx',prefix='UDEA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp= drive_files.biblio['UDEA'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']=pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32581, 24)\n",
      "va1 0 0\n",
      "................................................................"
     ]
    }
   ],
   "source": [
    "df=merge_puntaje(drive_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Check why not zero\n",
    "if 'UDEA_autores' in df.columns:\n",
    "    print(0,'=',df[df['UDEA_autores']==''].shape[0],'; found:',df['UDEA_autores'].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['UDEA_autores'].apply(lambda s: pd.np.nan if type(s)==str and s=='' else s).dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15700, 181)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_quality(UDEA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fill C1 for not WOS entries in WOS format and extract  affiliation from C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill from SCI_C1\n",
    "UDEA['C1']=SCI_C1_to_C1(UDEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fill from SCP_C1='SCP_Authors with affiliations\n",
    "UDEA['C1']=SCP_Authors_with_affiliations_to_C1(UDEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA[UDEA['C1'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA[UDEA.Tipo=='WOS'].reset_index(drop=True).C1.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#WARNING: some C1 WOS entries are not normalized: Missing authors\n",
    "UDEA['authors_WOS']=UDEA.C1.apply(lambda x: x.split('\\n') if x else x).apply(\n",
    "    lambda x:   [y.replace('[','').replace('] ','; ') for y in x if y.find(affil)>-1 ] if x else x ).apply(\n",
    "     lambda x: get_author_info(x) if x else x)\n",
    "\n",
    "# Improve normalization: remove C1s with only affiliation (from Scielo)\n",
    "UDEA['authors_WOS']=UDEA['authors_WOS'].apply( \n",
    "    lambda x: [d for d in x if d.get('WOS_author').find(affil)==-1] if type(x)==list else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA[UDEA.Tipo=='SCP'].reset_index(drop=True).loc[0].authors_WOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare UDEA columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Remove from fill_trained_data(..)\n",
    "if 'UDEA_autores' in UDEA.columns:\n",
    "    UDEA['UDEA_autores']=UDEA['UDEA_autores'].apply(lambda s: re.sub('\\s+',' ',s) if type(s)==str else s)\n",
    "    UDEA['UDEA_authors']=UDEA['UDEA_autores'].apply(lambda s: s.split(';') if type(s)==str else s).apply(\n",
    "                           lambda l: [{'full_name':y} for y in l ] if type(l)==list else l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Merge with official researcher list: PTJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AU=drive_files.read_drive_excel('Base_de_datos_investigadores_Definitiva.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UPDATE_UDEA_authors_with_AU=True\n",
    "if (UDEA['UDEA_authors'].dropna().shape[0] and \n",
    "    UPDATE_UDEA_authors_with_AU):\n",
    "    kkn=UDEA.copy()\n",
    "    kkn=update_institutional_authors(kkn,AU)\n",
    "    print(kkn.shape,UDEA.shape)\n",
    "    UDEA=kkn.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "key_contains_in_list_of_dictionaries(UDEA,'Restrepo, D',column='authors_WOS',key='WOS_author').loc[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if UPDATE_UDEA_authors_with_AU:\n",
    "    UDEA.to_json('UDEAtmp.json')\n",
    "    RECOVER=False\n",
    "    if RECOVER:\n",
    "        UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_quality(UDEA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add `UDEA.authors_WOS` info* within `UDEA.UDEA_authors` data**\n",
    "(\\*) obtained from `UDEA.C1`\n",
    "\n",
    "(\\*\\*) Obtained from [puntaje trained old UDEA data](./WOS_SCI_SCP_PTJ_GS_LNS.ipynb#Merge-with-trained-data-set) and the [official researcher list](./WOS_SCI_SCP_PTJ_GS_LNS.ipynb#Merge-with-official-researcher-list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Obtain name parts and initials from full name in `UDEA_authors` dictionary and update `UDEA_authors` with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'UDEA_authors' not in UDEA.columns and REBUILD==False:\n",
    "    sys.exit('Make MERGE_WITH_TRAINED True and run again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain spanish name parts from full name\n",
    "dictupdatetmp=UDEA['UDEA_authors'].apply(lambda x: [y.update( \n",
    "                split_full_names(y,full_name='full_name')  ) if not pd.isnull(\n",
    "                y.get('full_name')) else y for y in x] \n",
    "                                   if type(x)==list \n",
    "                                   else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kk=UDEA['authors_WOS'].combine( UDEA['UDEA_authors'], func=combinewos )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load output restuls of previous Cell runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build a single profile for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Fill UDEA_authors with WOS_author info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain UDEA_authors DataFrame: `aunly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aunly=DataFrame_authors(UDEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not aunly.empty:\n",
    "    aunly.to_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if RECOVER:\n",
    "    if os.path.exists('UDEA_authors_with_WOS_info.json' ):\n",
    "        aunly=pd.read_json('UDEA_authors_with_WOS_info.json')\n",
    "    else:\n",
    "        aunly=drive_files.read_drive_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aunly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(1273, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_quality(UDEA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge UDEA with authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With exact author matching and high `lv.ratio` for affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(lambda l:fill_full_wos_author_info(l,aunly) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UDEA['UDEA_authors'].dropna().shape[0]:\n",
    "    UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=UDEA.authors_WOS.combine(UDEA.UDEA_authors,func=lambda x,y: get_UDEA_authors(x,y,aunly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11656,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.UDEA_authors.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7072,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11656,), (15700, 181))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.UDEA_authors.dropna().shape,UDEA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "((10963,), (15704, 181))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aunly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1461, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not aunly.empty:\n",
    "    print(aunly.drop_duplicates('tmp_author').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not aunly.empty:\n",
    "    aunly.to_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RECOVER=False\n",
    "if RECOVER:\n",
    "    if os.path.exists('UDEA_authors_with_WOS_info.json' ):\n",
    "        aunly=pd.read_json('UDEA_authors_with_WOS_info.json')\n",
    "    else:\n",
    "        aunly=drive_files.read_drive_json('UDEA_authors_with_WOS_info.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UDEA['UDEA_authors'].dropna().shape[0]:\n",
    "    UDEA.to_json('UDEAtmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECOVER:\n",
    "    UDEA=pd.read_json('UDEAtmp.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.to_json('WOS_SCI_SCP_PTJ_CTR.json.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'UDEA_autores' in UDEA.columns:\n",
    "    print(UDEA[UDEA['UDEA_autores']==''].shape[0],UDEA['UDEA_autores'].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'UDEA_authors' in UDEA.columns:\n",
    "    print(UDEA[UDEA['UDEA_authors']==''].shape[0],UDEA['UDEA_authors'].dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_quality(UDEA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exactly as before: Used only if 'UDEA_authors' is empty! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECOVER:\n",
    "    UDEA=pd.read_json('WOS_SCI_SCP_PTJ_CTR.json.gz',compression='gzip').reset_index(drop=True)\n",
    "    aunly=drive_files.read_drive_json('UDEA_authors_with_WOS_info.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same function that `get_UDEA_authors??` but for apply instead of combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_institutional_authors(x,author_df,x_author_key='WOS_author',x_affiliation_key='affiliation',\n",
    "                                        author_key='WOS_author',\n",
    "                                        affiliation_key='WOS_affiliation'):\n",
    "    '''\n",
    "    Same function that \n",
    "    get_UDEA_authors?? \n",
    "    but for apply instead of combine\n",
    "    '''\n",
    "    if type(x)!=list:\n",
    "        return None\n",
    "    ll=[]\n",
    "    for j in range(len(x)):\n",
    "        \n",
    "                                #author_WOS→affiliation always have single affiliation\n",
    "        kk=find_author_affiliation(x[j].get(x_author_key),x[j].get(x_affiliation_key)[0],\n",
    "                                        author_df=author_df,\n",
    "                                        author_key=author_key,\n",
    "                                        affiliation_key=affiliation_key,\n",
    "                                        ratio=0.9 )\n",
    "        if kk:\n",
    "            ll.append(kk)\n",
    "    if not ll:\n",
    "        ll=None\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not UDEA['UDEA_authors'].dropna().shape[0]:\n",
    "    UDEA['UDEA_authors']=UDEA.authors_WOS.apply(lambda l: build_institutional_authors(l,aunly) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental: Try a similiraty merge with the remaining entries\n",
    "### TODO: Change by new function\n",
    "### TODO: Fix missing `authors_WOS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_YES=UDEA[~UDEA['UDEA_authors'].isna()].reset_index(drop=True)\n",
    "UDEA_NOT=UDEA[UDEA['UDEA_authors'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11656, 181), (11656,))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[~UDEA['UDEA_authors'].isna()].shape,UDEA['UDEA_authors'].dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzywuzzy.process as fwp\n",
    "from fuzzywuzzy import fuzz\n",
    "df2=aunly.copy()\n",
    "df2=pd.DataFrame( list( df2['UDEA_authors'].values ) )\n",
    "df2['UDEA_authors']=aunly['UDEA_authors']\n",
    "contents=df2[['WOS_author','WOS_affiliation','UDEA_authors','full_name']].reset_index(drop=True)\n",
    "contents['WOS_author']=contents['WOS_author'].astype(str)\n",
    "contents['WOS_affiliation']=contents['WOS_affiliation'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( UDEA_NOT['authors_WOS'].loc[0][0].get('WOS_author'),\n",
    "      fwp.extractOne(  UDEA_NOT['authors_WOS'].loc[0][0].get('WOS_author'),\n",
    "                     contents['WOS_author'],scorer=fuzz.partial_ratio  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnot=UDEA_NOT.copy()\n",
    "dfnot=dfnot.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "def author_quality_match(x,y,scorer=fuzz.token_set_ratio):\n",
    "    \n",
    "    chk={}\n",
    "    chk['simple_wos']=unidecode.unidecode(x).lower().replace(\n",
    "                       '.','').replace(',','').replace('-',' ')\n",
    "    chk['full_name']=unidecode.unidecode(y).lower().replace(\n",
    "                       '.','').replace(',','').replace('-',' ')\n",
    "    sn=re.sub('^(\\w+\\s+\\w+\\s+\\w)\\w+(\\s+\\w)\\w+$',r'\\1\\2',chk['full_name'])\n",
    "    chk['short_name']=re.sub('^(\\w+\\s+\\w+\\s+\\w)\\w+$',r'\\1',sn)\n",
    "    sn=re.sub('^(\\w+\\s+)\\w+\\s+(\\w+)\\s+\\w+$',r'\\1\\2',chk['full_name'])\n",
    "    chk['simple_name']=re.sub('^(\\w+\\s+)\\w+\\s+(\\w+)$',r'\\1\\2',sn)\n",
    "    chk['simple_second_name']=re.sub('^(\\w+\\s+)\\w+\\s+\\w+\\s+(\\w+)$',r'\\1\\2',chk['full_name'])\n",
    "    chk['last_name']=re.sub( '^(\\w+\\s+)\\w+\\s+(\\w+\\s+\\w+)$',r'\\1\\2', chk['full_name'] )\n",
    "    chk['last_names']=re.sub('^(\\w+\\s+\\w+\\s+\\w+)\\s+\\w+$',r'\\1',chk['full_name'])\n",
    "    chk['second_name']=re.sub('^(\\w+\\s+\\w+\\s+)\\w+\\s+(\\w+)$',r'\\1\\2',chk['full_name'])\n",
    "\n",
    "    chk['s1']=fuzz.token_sort_ratio( chk['simple_wos'],chk['full_name'])\n",
    "    chk['s1b']=fuzz.partial_token_sort_ratio( chk['simple_wos'],chk['full_name'])\n",
    "    chk['s2']=scorer( chk['simple_wos'],chk['short_name'])\n",
    "    chk['s3']=fuzz.ratio( chk['simple_wos'],chk['simple_name'])\n",
    "    chk['s3']=fuzz.ratio( chk['simple_wos'],chk['simple_second_name'])\n",
    "    chk['s4']=fuzz.token_sort_ratio( chk['simple_wos'],chk['last_name'])\n",
    "    chk['s5']=fuzz.token_sort_ratio(chk['simple_wos'],chk['last_names'])    \n",
    "    chk['s6']=fuzz.token_sort_ratio(chk['simple_wos'],chk['second_name'])\n",
    "    \n",
    "    chk['max']=max( chk['s1'],chk['s1b'],chk['s2'],chk['s3'],chk['s4'],chk['s5'],chk['s6'])\n",
    "    \n",
    "    return chk\n",
    "\n",
    "#for i in range(20):\n",
    "#l=dfnot['authors_WOS'].loc[i]\n",
    "#93,70\n",
    "\n",
    "def json_fuzzy_merge_full(l,contents,right_target='UDEA_authors',\n",
    "                       left_on='WOS_author',extra_left_on='affiliation',\n",
    "                       right_on='WOS_author',extra_right_on='WOS_affiliation',\n",
    "                       cutoff=95,cutoff_extra=65,scorer=fuzz.partial_ratio,\n",
    "                         full_name='full_name',quality_cutoff=75):\n",
    "    newl=[]\n",
    "    for d in l:\n",
    "        au=d.get(left_on)\n",
    "        aff=d.get(extra_left_on)\n",
    "        # Do not need to be string\n",
    "        r=fwp.extractOne(au,contents[right_on],scorer=scorer)\n",
    "        if r[1]>=cutoff:\n",
    "            raf=scorer( aff, contents.loc[r[2],extra_right_on]  )\n",
    "            fn=contents.loc[r[2],full_name]\n",
    "            chk=author_quality_match(au,fn)\n",
    "            if chk['max']<quality_cutoff:\n",
    "                raf=cutoff_extra-1\n",
    "            if raf>=cutoff_extra:\n",
    "                mthchedd=contents.loc[r[2],right_target]\n",
    "                mthchedd['from_author_WOS_WOS_author']=au\n",
    "                newl=newl+[ mthchedd   ]\n",
    "    if newl:\n",
    "        return newl\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10901, 181)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA_YES.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Find institutional author info with safe json column converted into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time kk=dfnot['authors_WOS'].swifter.apply(lambda l: json_fuzzy_merge_full(l,contents,cutoff_extra=65) if type(l)==list else l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time kk=dfnot['authors_WOS'].apply(lambda l: json_fuzzy_merge_full(l,contents,cutoff_extra=65) if type(l)==list else l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=kk.apply(lambda l: l if type(l)==list else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_NOT['UDEA_authors']=kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA=UDEA_YES.append(UDEA_NOT).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.to_json('kk.json.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_YES=UDEA[~UDEA['UDEA_authors'].isna()].reset_index(drop=True)\n",
    "UDEA_NOT=UDEA[UDEA['UDEA_authors'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11656, 181), (11656,))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[~UDEA['UDEA_authors'].isna()].shape,UDEA['UDEA_authors'].dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15700, 11656)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA_NOT.shape[0]+UDEA_YES.shape[0],UDEA_YES.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Find institutional author info with  json column specific keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wosplus as wp\n",
    "pd.set_option('display.max_colwidth',200)\n",
    "import numpy as np\n",
    "import fuzzywuzzy.process as fwp\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting drive.cfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile drive.cfg\n",
    "[FILES]\n",
    "WOS_SCI_SCP_PTJ_CTR.json.gz=19E1C1kRk4I0V3uXojqko8-NEicWaPp1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Biblio already has a \"Tipo\" column\n",
      "4044 11656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4370c91d9254dcfa48056638dea28e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=4044, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1h 12min 50s, sys: 5.58 s, total: 1h 12min 55s\n",
      "Wall time: 1h 12min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((11656, 181), (4044, 181), (603,))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "import wosplus as wp\n",
    "pd.set_option('display.max_colwidth',200)\n",
    "import numpy as np\n",
    "import fuzzywuzzy.process as fwp\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "\n",
    "affil='Univ Antioquia'\n",
    "drive_files=wp.wosplus('drive.cfg')\n",
    "\n",
    "UDEAjsonfile='WOS_SCI_SCP_PTJ_CTR.json.gz'\n",
    "tmp=drive_files.load_biblio(UDEAjsonfile,compression='gzip')\n",
    "UDEA=drive_files.biblio['WOS'].copy().reset_index(drop=True)\n",
    "aunly=drive_files.read_drive_json('UDEA_authors_with_WOS_info.json').reset_index(drop=True)\n",
    "\n",
    "#json_column='UDEA_authors'\n",
    "#UDEA_NOT=UDEA[UDEA[json_column]==''].reset_index(drop=True)\n",
    "#UDEA_YES=UDEA[UDEA[json_column]!=''].reset_index(drop=True)\n",
    "print( UDEA_NOT.shape[0],UDEA_YES.shape[0] )\n",
    "\n",
    "df2=aunly.copy()\n",
    "df2=pd.DataFrame( list( df2['UDEA_authors'].values ) )\n",
    "df2['UDEA_authors']=aunly['UDEA_authors']\n",
    "contents=df2[['WOS_author','WOS_affiliation','UDEA_authors']].reset_index(drop=True)\n",
    "contents['WOS_author']=contents['WOS_author']#.astype(str)\n",
    "contents['WOS_affiliation']=contents['WOS_affiliation']#.astype(str)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "import unidecode\n",
    "def author_quality_match(x,y,scorer=fuzz.token_set_ratio):\n",
    "    \n",
    "    chk={}\n",
    "    chk['simple_wos']=unidecode.unidecode(x).lower().replace(\n",
    "                       '.','').replace(',','').replace('-',' ')\n",
    "    chk['full_name']=unidecode.unidecode(y).lower().replace(\n",
    "                       '.','').replace(',','').replace('-',' ')\n",
    "    sn=re.sub('^(\\w+\\s+\\w+\\s+\\w)\\w+(\\s+\\w)\\w+$',r'\\1\\2',chk['full_name'])\n",
    "    chk['short_name']=re.sub('^(\\w+\\s+\\w+\\s+\\w)\\w+$',r'\\1',sn)\n",
    "    sn=re.sub('^(\\w+\\s+)\\w+\\s+(\\w+)\\s+\\w+$',r'\\1\\2',chk['full_name'])\n",
    "    chk['simple_name']=re.sub('^(\\w+\\s+)\\w+\\s+(\\w+)$',r'\\1\\2',sn)\n",
    "    chk['simple_second_name']=re.sub('^(\\w+\\s+)\\w+\\s+\\w+\\s+(\\w+)$',r'\\1\\2',chk['full_name'])\n",
    "    chk['last_name']=re.sub( '^(\\w+\\s+)\\w+\\s+(\\w+\\s+\\w+)$',r'\\1\\2', chk['full_name'] )\n",
    "    chk['last_names']=re.sub('^(\\w+\\s+\\w+\\s+\\w+)\\s+\\w+$',r'\\1',chk['full_name'])\n",
    "    chk['second_name']=re.sub('^(\\w+\\s+\\w+\\s+)\\w+\\s+(\\w+)$',r'\\1\\2',chk['full_name'])\n",
    "\n",
    "    chk['s1']=fuzz.token_sort_ratio( chk['simple_wos'],chk['full_name'])\n",
    "    chk['s1b']=fuzz.partial_token_sort_ratio( chk['simple_wos'],chk['full_name'])\n",
    "    chk['s2']=scorer( chk['simple_wos'],chk['short_name'])\n",
    "    chk['s3']=fuzz.ratio( chk['simple_wos'],chk['simple_name'])\n",
    "    chk['s3']=fuzz.ratio( chk['simple_wos'],chk['simple_second_name'])\n",
    "    chk['s4']=fuzz.token_sort_ratio( chk['simple_wos'],chk['last_name'])\n",
    "    chk['s5']=fuzz.token_sort_ratio(chk['simple_wos'],chk['last_names'])    \n",
    "    chk['s6']=fuzz.token_sort_ratio(chk['simple_wos'],chk['second_name'])\n",
    "    \n",
    "    chk['max']=max( chk['s1'],chk['s1b'],chk['s2'],chk['s3'],chk['s4'],chk['s5'],chk['s6'])\n",
    "    \n",
    "    return chk\n",
    "\n",
    "def json_fuzzy_merge(row,UDEA,contents,right_target='UDEA_authors',\n",
    "                       left_on='WOS_author',extra_left_on='affiliation',\n",
    "                       right_on='WOS_author',extra_right_on='WOS_affiliation',\n",
    "                       extra_extra_right_on='full_name',\n",
    "                       cutoff=93,\n",
    "                       cutoff_author=90,\n",
    "                       cutoff_affiliation=70,scorer=fuzz.token_set_ratio,\n",
    "                       DEBUG=False):\n",
    "    l=row['authors_WOS']\n",
    "    so=row['SO']\n",
    "    newl=[]\n",
    "    for d in l:\n",
    "        AUTHOR=False\n",
    "        AFFILIATION=False\n",
    "        JOURNAL=True\n",
    "\n",
    "        dfraf=pd.DataFrame()\n",
    "        au=d.get(left_on)\n",
    "        aff=d.get(extra_left_on)[0]\n",
    "        Q=1\n",
    "        # Try match author to a good degree\n",
    "        rau=fwp.extractOne(au,contents[right_on].apply(pd.Series).stack().unique(),scorer=scorer)\n",
    "        if DEBUG: print(1,rau)\n",
    "        if rau[1]>=cutoff:\n",
    "            AUTHOR=True\n",
    "        #Try match author with less quality: Q\n",
    "        else:\n",
    "            rau=fwp.extractOne(au,contents[right_on].apply(pd.Series).stack().unique(),\n",
    "                       scorer=fuzz.partial_token_sort_ratio)\n",
    "            if DEBUG: print(1.1,rau)            \n",
    "            if rau and rau[1]>=cutoff:\n",
    "                Q=Q-0.1\n",
    "                AUTHOR=True\n",
    "        if DEBUG: print(1.2,'AUTHOR:',AUTHOR)                            \n",
    "        if AUTHOR:\n",
    "            dfraf=contents[contents[right_on].apply( lambda l: rau[0] in l )\n",
    "                                ].reset_index(drop=True)\n",
    "            full_name=dfraf[right_target].loc[0].get(extra_extra_right_on)\n",
    "            chk=author_quality_match(au,full_name,scorer=scorer)\n",
    "            if DEBUG: print(1.3,'chk max:',chk['max'])\n",
    "            if chk['max']<cutoff_author:\n",
    "                AUTHOR=False\n",
    "        if AUTHOR:\n",
    "            raf=fwp.extractOne(aff,dfraf[extra_right_on].loc[0],scorer=fuzz.ratio)\n",
    "            if DEBUG: print(2,raf)\n",
    "            if raf and raf[1]>=cutoff_affiliation:\n",
    "                AFFILIATION=True\n",
    "            else:\n",
    "                Q=Q-0.1\n",
    "                raf=fwp.extractOne(aff,dfraf[extra_right_on].loc[0],\n",
    "                                   scorer=fuzz.partial_token_set_ratio)\n",
    "                if DEBUG: print(2.1,raf)\n",
    "                if raf and raf[1]>=cutoff_affiliation:\n",
    "                    AFFILIATION=True\n",
    "\n",
    "        if DEBUG: print(2.2,'AFFILIATION:',AFFILIATION,'Q:',Q)                \n",
    "        if AUTHOR and Q<1:\n",
    "            cutoff_so=50\n",
    "            if Q<0.9:\n",
    "                cutoff_so=60\n",
    "            if not dfraf.empty and full_name:\n",
    "                kkk=UDEA[UDEA['UDEA_nombre'].str.contains(full_name)\n",
    "                                ].reset_index(drop=True)\n",
    "                rso=fwp.extractOne( so,   kkk.SO, scorer=scorer)\n",
    "                if not rso:\n",
    "                    JOURNAL=False\n",
    "                elif rso[1]<cutoff_so:\n",
    "                    JOURNAL=False\n",
    "            else:\n",
    "                JOURNAL=False\n",
    "        if DEBUG: print(3,'JOURNAL',JOURNAL)                \n",
    "        if AUTHOR and AFFILIATION and JOURNAL:\n",
    "            mthchedd=dfraf.loc[0,right_target]\n",
    "            mthchedd['from_author_WOS_WOS_author']=au\n",
    "            newl=newl+[  mthchedd  ]            \n",
    "            #print('{} → {}'.format(au,newl[0][extra_extra_right_on]) ) \n",
    "    if newl:\n",
    "        return newl\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "%time kkk=UDEA_NOT[['authors_WOS','SO']].swifter.apply(lambda row: json_fuzzy_merge(row,UDEA,contents),axis=1)\n",
    "\n",
    "UDEA_YES.shape,UDEA_NOT.shape,kkk.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk=kkk.apply(lambda l: l if type(l)==list else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4044,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_NOT['UDEA_authors']=kkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA=UDEA_YES.append(UDEA_NOT).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15700, 181)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA_YES=UDEA[~UDEA['UDEA_authors'].isna()].reset_index(drop=True)\n",
    "UDEA_NOT=UDEA[UDEA['UDEA_authors'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12259, 181), (12259,))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[~UDEA['UDEA_authors'].isna()].shape,UDEA['UDEA_authors'].dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12259,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA['UDEA_authors'].dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UDEA_YES=UDEA[UDEA.UDEA_nombre!=''].reset_index(drop=True)\n",
    "UDEA_NOT=UDEA[UDEA.UDEA_nombre==''].reset_index(drop=True)\n",
    "\n",
    "UDEA_YES['Tipo']=UDEA_YES.Tipo.str.replace('([SW][CO][SIP])$',r'\\1_UDEA')\n",
    "\n",
    "UDEA=UDEA_YES.append(UDEA_NOT)\n",
    "UDEA=UDEA.reset_index(drop=True)\n",
    "\n",
    "UDEA[UDEA.Tipo.str.contains('UDEA')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA.to_json('WOS_SCI_SCP_PTJ_CTR.json.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors_WOS\n",
      "13645\n",
      "Leptonic charged Higgs decays in the Zee model ; authors_WOS: [] ; AU: Sierra, DA\n",
      "Restrepo, D\n",
      "\n",
      "Tipo contains UDEA\n",
      "10311\n",
      "UDEA_authors\n",
      "12259\n",
      "UDEA_authors → full_names (Extrapolado puntaje)\n",
      "12259\n",
      "UDEA_authors → \"NOMBRE COMPLETO\" (Extrapolado CENTRO)\n",
      "8158\n"
     ]
    }
   ],
   "source": [
    "check_quality(UDEA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try other approachs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp.merge_with_close_matches??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test.cfg\n",
    "[FILES]\n",
    "Sample_WOS.xlsx = 1--LJZ4mYyQcaJ93xBdbnYj-ZzdjO2Wq2\n",
    "Sample_SCI.xlsx = 1-3a-hguQTk5ko8JRLCx--EKaslxGVscf\n",
    "Sample_SCP.xlsx = 1-IAWlMdp2U-9L2jvZUio04ub1Ym3PX-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cib=wp.wosplus('test.cfg')\n",
    "#cib.Debug=True\n",
    "cib.load_biblio('Sample_WOS.xlsx')\n",
    "cib.load_biblio('Sample_SCI.xlsx',prefix='SCI')\n",
    "cib.load_biblio('Sample_SCP.xlsx',prefix='SCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_matches_Levenshtein(\n",
    "        word,\n",
    "        possibilities,\n",
    "        n=3,\n",
    "        cutoff=0.6,\n",
    "        full=False):\n",
    "    '''Replaces difflib.get_close_matches with faster algortihm based on\n",
    "       Levenshtein.ratio.\n",
    "       HINT: Similarity increase significatively after lower() and unidecode()\n",
    "\n",
    "       Refs: https://en.wikipedia.org/wiki/Levenshtein_distance\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import Levenshtein\n",
    "    if isinstance(possibilities, str):\n",
    "        possibilities = [possibilities]\n",
    "    rs = pd.DataFrame()\n",
    "    MATCH = False\n",
    "    for p in possibilities:\n",
    "        similarity = Levenshtein.ratio(word, p)\n",
    "        # print(word,'::',p,similarity)\n",
    "        # sys.exit()\n",
    "        if similarity >= cutoff:\n",
    "            MATCH = True\n",
    "            rs = rs.append({'similarity': similarity,\n",
    "                            'match': p}, ignore_index=True)\n",
    "\n",
    "    if MATCH:\n",
    "        rs = rs.sort_values(\n",
    "            'similarity', ascending=False).reset_index(drop=True)\n",
    "        if full:\n",
    "            return list(rs['match'][:n].values), list(\n",
    "                rs['similarity'][:n].values)\n",
    "        else:\n",
    "            return list(rs['match'][:n].values)\n",
    "    else:\n",
    "        if full:\n",
    "            return ([], 0)\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer=fuzz.ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_matches_Levenshtein_new(\n",
    "        word,\n",
    "        possibilities,\n",
    "        n=1,\n",
    "        cutoff=0.6,\n",
    "        full=False,\n",
    "        scorer=fuzz.ratio): #\n",
    "    r=fwp.extract(word,possibilities,scorer=scorer,limit=n)\n",
    "    \n",
    "    if r[0][1]/100.>cutoff:\n",
    "        if full:\n",
    "            return [t[0] for t in r],[t[1]/100. for t in r]\n",
    "        else:\n",
    "            return [t[0] for t in r]\n",
    "    else:\n",
    "        if full:\n",
    "            return ([], 0)\n",
    "        else:\n",
    "            return []        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_close_matches_old(\n",
    "        left,\n",
    "        right,\n",
    "        left_on='ST',\n",
    "        right_on='UDEA_simple_título',\n",
    "        left_extra_on='SO',\n",
    "        right_extra_on='UDEA_nombre revista o premio',\n",
    "        how='inner',\n",
    "        n=1,\n",
    "        cutoff=0.6,\n",
    "        full=True,\n",
    "        cutoff_extra=0.6):\n",
    "    '''For each entry of the column: left_on of DataFrame left (cannot have empty fields),\n",
    "       try to find the close match inside each row of right DataFrame, by comparing with\n",
    "       the right_on entry of the row. When a row match is found, the full right row is appended\n",
    "       to the matched row in the left DataFrame.\n",
    "       If the similarity between the entries at left_on and right_on is less than 0.8,\n",
    "       an additional check is performed between the entries left_extra_on and right_extra_on\n",
    "       of the matched row.\n",
    "\n",
    "       how implemented: inner and left (Default: inner)\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from unidecode import unidecode\n",
    "    import pandas as pd\n",
    "    # import sys #import globally\n",
    "    # print(left[left_on][0])\n",
    "    # sys.exit()\n",
    "    words = left[left_on].str.lower().map(unidecode)\n",
    "    possibilities = right[right_on].str.lower().map(unidecode)\n",
    "\n",
    "    joined = pd.DataFrame()\n",
    "    mi = np.array([])\n",
    "    for i in left.index:\n",
    "        if i % 100 == 0:\n",
    "            print('.', end=\"\")\n",
    "        joined_series = left.loc[i]\n",
    "        #joined_series=joined_series.append(pd.Series( {similarity_column:0} ))\n",
    "        title, similarity = get_close_matches_Levenshtein(\n",
    "            words[i], possibilities, n=n, cutoff=cutoff, full=full)\n",
    "        # print(i,words[i],title,similarity) #cutuff 0.6 0.7 0.8 0.85 0.91 0.95\n",
    "        # sys.exit()\n",
    "        if title:\n",
    "            mtch = right[possibilities == title[0]]\n",
    "            # >=cutoff, e.g 0.65 0.95 0.81 0.86 0.9 0.96\n",
    "            chk_cutoff = similarity[0]\n",
    "            crosscheck = cutoff + 0.2  # 0.8 # e.g. 0.8 0.9 0.9 0.9 0.9 0.9\n",
    "            if crosscheck >= 1:\n",
    "                # force check if match worst than this (by experience)\n",
    "                crosscheck = 0.95\n",
    "            if chk_cutoff < crosscheck:  # e.g 0.65<0.8 0.95~<0.9 0.81~<0.0 0.86<0.9 0.91<~0.9 0.96~<0.9\n",
    "                if get_close_matches_Levenshtein(unidecode(left[left_extra_on][i].lower()), [unidecode(\n",
    "                        mtch[right_extra_on][mtch.index[0]].lower())], cutoff=cutoff_extra):  # cutoff=0.6\n",
    "                    chk_cutoff = crosscheck + 0.1\n",
    "\n",
    "            if chk_cutoff >= crosscheck:\n",
    "                joined_series = joined_series.append(mtch.loc[mtch.index[0]])\n",
    "                if how == 'outer':\n",
    "                    mi = np.concatenate((mi, mtch.index.values))\n",
    "                # joined_series[similarity_column]=similarity[0]\n",
    "\n",
    "            #return joined_series\n",
    "            if how == 'inner':\n",
    "                joined = joined.append(joined_series, ignore_index=True)\n",
    "\n",
    "        if (how == 'left' or 'outer'):\n",
    "            joined = joined.append(joined_series, ignore_index=True)\n",
    "    if how == 'outer':\n",
    "        joined = joined.append(right.drop(\n",
    "            right.index[list(mi.astype(int))]).reset_index(drop=True))\n",
    "    return joined\n",
    "\n",
    "def merge_with_close_matches_new(\n",
    "        left,\n",
    "        right,\n",
    "        left_on='ST',\n",
    "        right_on='UDEA_simple_título',\n",
    "        left_extra_on='SO',\n",
    "        right_extra_on='UDEA_nombre revista o premio',\n",
    "        how='inner',\n",
    "        n=1,\n",
    "        cutoff=0.6,\n",
    "        full=True,\n",
    "        cutoff_extra=0.7):\n",
    "    '''For each entry of the column: left_on of DataFrame left (cannot have empty fields),\n",
    "       try to find the close match inside each row of right DataFrame, by comparing with\n",
    "       the right_on entry of the row. When a row match is found, the full right row is appended\n",
    "       to the matched row in the left DataFrame.\n",
    "       If the similarity between the entries at left_on and right_on is less than 0.8,\n",
    "       an additional check is performed between the entries left_extra_on and right_extra_on\n",
    "       of the matched row.\n",
    "\n",
    "       how implemented: inner and left (Default: inner)\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from unidecode import unidecode\n",
    "    import pandas as pd\n",
    "    # import sys #import globally\n",
    "    # print(left[left_on][0])\n",
    "    # sys.exit()\n",
    "    words = left[left_on].str.lower().map(unidecode)\n",
    "    possibilities = right[right_on].str.lower().map(unidecode)\n",
    "\n",
    "    joined = pd.DataFrame()\n",
    "    mi = np.array([])\n",
    "    for i in left.index:\n",
    "        if i % 100 == 0:\n",
    "            print('.', end=\"\")\n",
    "        joined_series = left.loc[i]\n",
    "        #joined_series=joined_series.append(pd.Series( {similarity_column:0} ))\n",
    "        title, similarity = get_close_matches_Levenshtein_new(\n",
    "            words[i], possibilities, n=n, cutoff=cutoff, full=full)\n",
    "        # print(i,words[i],title,similarity) #cutuff 0.6 0.7 0.8 0.85 0.91 0.95\n",
    "        # sys.exit()\n",
    "        if title:\n",
    "            mtch = right[possibilities == title[0]]\n",
    "            # >=cutoff, e.g 0.65 0.95 0.81 0.86 0.9 0.96\n",
    "            chk_cutoff = similarity[0]\n",
    "            crosscheck = cutoff + 0.2  # 0.8 # e.g. 0.8 0.9 0.9 0.9 0.9 0.9\n",
    "            if crosscheck >= 1:\n",
    "                # force check if match worst than this (by experience)\n",
    "                crosscheck = 0.95\n",
    "            if chk_cutoff < crosscheck:  # e.g 0.65<0.8 0.95~<0.9 0.81~<0.0 0.86<0.9 0.91<~0.9 0.96~<0.9\n",
    "                if get_close_matches_Levenshtein_new(unidecode(left[left_extra_on][i].lower()), [unidecode(\n",
    "                        mtch[right_extra_on][mtch.index[0]].lower())], cutoff=cutoff_extra):  # cutoff=0.6\n",
    "                    chk_cutoff = crosscheck + 0.1\n",
    "\n",
    "            if chk_cutoff >= crosscheck:\n",
    "                joined_series = joined_series.append(mtch.loc[mtch.index[0]])\n",
    "                if how == 'outer':\n",
    "                    mi = np.concatenate((mi, mtch.index.values))\n",
    "                # joined_series[similarity_column]=similarity[0]\n",
    "\n",
    "            #return joined_series\n",
    "            if how == 'inner':\n",
    "                joined = joined.append(joined_series, ignore_index=True)\n",
    "\n",
    "        if (how == 'left' or 'outer'):\n",
    "            joined = joined.append(joined_series, ignore_index=True)\n",
    "    if how == 'outer':\n",
    "        joined = joined.append(right.drop(\n",
    "            right.index[list(mi.astype(int))]).reset_index(drop=True))\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cib.biblio['WOS']=UDEA.sample(500).reset_index(drop=True).copy().fillna('')\n",
    "cib.biblio['SCI']=SIU[0:100].copy().fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=drive_files.load_biblio('produccion_fecha_vig_2003_2018.xlsx',prefix='UDEA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_files.biblio['UDEA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time kkold=merge_with_close_matches_old(cib.biblio['WOS'],cib.biblio['SCI'].drop('Tipo',axis='columns'),left_on='TI',right_on='SCI_TI',right_extra_on='SCI_SO',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time kknew=merge_with_close_matches_new(cib.biblio['WOS'],cib.biblio['SCI'].drop('Tipo',axis='columns'),left_on='TI',right_on='SCI_TI',right_extra_on='SCI_SO',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkold.shape,kknew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(kkold['SCI_TI'].apply(lambda s: s if s else pd.np.nan).dropna().shape,\n",
    " kknew['SCI_TI'].apply(lambda s: s if s else pd.np.nan).dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kknew[['TI','SCI_TI']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkold[['TI','SCI_TI']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=time.time()\n",
    "kkold=merge_with_close_matches_old(cib.biblio['WOS'][['TI','SO']],drive_files.biblio['UDEA'][['UDEA_título',\n",
    "                                                            'UDEA_nombre revista o premio']],\n",
    "                            left_on='TI',left_extra_on='SO',right_on='UDEA_título',\n",
    "                            right_extra_on='UDEA_nombre revista o premio',how='left')\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=time.time()\n",
    "kknew=merge_with_close_matches_new(cib.biblio['WOS'][['TI','SO']],drive_files.biblio['UDEA'][['UDEA_título',\n",
    "                                                            'UDEA_nombre revista o premio']],\n",
    "                            left_on='TI',left_extra_on='SO',right_on='UDEA_título',\n",
    "                            right_extra_on='UDEA_nombre revista o premio',how='left')\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(kkold['UDEA_título'].apply(lambda s: s if s else pd.np.nan).dropna().shape,\n",
    " kknew['UDEA_título'].apply(lambda s: s if s else pd.np.nan).dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "merge.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
