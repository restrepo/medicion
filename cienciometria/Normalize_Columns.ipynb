{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/restrepo/medicion/blob/master/cienciometria/Query_CTR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDnqho-CsEwj"
   },
   "source": [
    "# Búsquedas WOS+SCI+SCP+PTJ+CTR para UdeA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Búsquedas en bases bibligráficas  \n",
    "* Web of Science (WOS), \n",
    "* Scielo (SCI)\n",
    "* Scopus  (SCP)\n",
    "* Puntaje (UDEA)\n",
    "* Center (CTR)\n",
    "de los artículos científicos de la UdeA\n",
    "\n",
    "La base de datos se creó con:\n",
    "\n",
    "[WOS_SCI_SCP_PTJ_CTR.ipynb](./WOS_SCI_SCP_PTJ_CTR.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "VERSION='NEW'\n",
    "if os.getcwd()=='/content':\n",
    "    !pip install openpyxl xlrd wosplus fuzzywuzzy[speedup] > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhk2ZGEDd2Yo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wosplus as wp\n",
    "pd.set_option('display.max_colwidth',200)\n",
    "from venn import draw_venn, generate_colors\n",
    "import numpy as np\n",
    "import fuzzywuzzy.process as fwp\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "import json\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import unidecode\n",
    "import itertools\n",
    "import sys\n",
    "idc='CÉDULA'\n",
    "# GENERAL PORPOSE FUNCTIONS\n",
    "def split_names(s):\n",
    "    \"\"\"\n",
    "    Extract the parts of the full name s.\n",
    "    \n",
    "    Works with:\n",
    "    ----\n",
    "        s='LA ROTTA FORERO DANIEL ANDRES'\n",
    "        s='MONTES RAMIREZ MARIA DEL CONSUELO'\n",
    "        s='CALLEJAS POSADA RICARDO DE LA MERCED'\n",
    "        s='DE LA CUESTA BENJUMEA MARIA DEL CARMEN'\n",
    "        s='JARAMILLO OCAMPO NICOLAS CARLOS MARTI'\n",
    "        s='RESTREPO QUINTERO DIEGO ALEJANDRO'\n",
    "        s='RESTREPO QUINTERO DIEGO'\n",
    "        s='RESTREPO DIEGO'\n",
    "    Fails with: \n",
    "    ----\n",
    "        s='RANGEL MARTINEZ VILLAL ANDRES MAURICIO'\n",
    "        s='RESTREPO DIEGO ALEJANDRO'\n",
    "    \"\"\"\n",
    "    s=s.title()\n",
    "    sl=re.sub('(\\s\\w{1,3})\\s',r'\\1-',s,re.UNICODE)\n",
    "    sl=re.sub('^(\\w{1,3})\\s',r'\\1-' ,sl,re.UNICODE)\n",
    "    #if sl.find('-')>-1:\n",
    "    sll=[s.replace('-',' ') for s in sl.split()]\n",
    "    if s.split()==2:\n",
    "        sll=[s.split()[0]]+['']+[s.split()[1]]\n",
    "    #\n",
    "    d={'NOMBRE COMPLETO' : ' '.join(sll[2:]+sll[:2]),\n",
    "     'PRIMER APELLIDO' : sll[0], \n",
    "     'SEGUNDO APELLIDO': sll[1], \n",
    "     'NOMBRES'         :' '.join(sll[2:]), \n",
    "     'INICIALES'       :' '.join( [i[0]+'.' for i in ' '.join(sll[2:]).split() ] )\n",
    "    }\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "JS7jD1f47JUN"
   },
   "source": [
    "##  Configure public links of  files in Google Drive\n",
    "* If it is a Google Spreadsheet the corresponding file is downloaded as CSV\n",
    "* If it is in excel/json or text file the file is downloaded  directly\n",
    "\n",
    "To define your  own labeled IDs for public google drive files edit the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "hidden": true,
    "id": "T4Rmd2dF7JUQ",
    "outputId": "39a5835e-1b38-48b6-f1a5-e9964c846123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting drive.cfg\n"
     ]
    }
   ],
   "source": [
    "%%writefile drive.cfg\n",
    "[FILES]\n",
    "WOS_SCI_SCP_PTJ_CTR.json.gz=19E1C1kRk4I0V3uXojqko8-NEicWaPp1j\n",
    "Base_de_datos_investigadores_Definitiva.csv=12oalgUeKhpvzkTPBP8pXCeHTrF-KO223dy9ov9w9QKs\n",
    "produccion_fecha_vig_2003_2018.xlsx=1WbtX4K__TTLxXRjuLvqUYz9tuHCIlS5v\n",
    "producción_reconocida_2002_2016_doi.xlsx=0BxoOXsn2EUNIY2lzVmNMT0VXaGs\n",
    "oaudea.xlsx             = 1CcwobiEFACIbffNzNdLxpdxQukr8cZ5x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0D0hEdAMXUX"
   },
   "source": [
    "##  Load data bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "occzrIeCS7aQ",
    "outputId": "17b144f3-eef0-4c8a-c2b4-10c8fe55802c"
   },
   "outputs": [],
   "source": [
    "affil='Univ Antioquia'\n",
    "drive_files=wp.wosplus('drive.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Biblio already has a \"Tipo\" column\n"
     ]
    }
   ],
   "source": [
    "UDEAjsonfile='WOS_SCI_SCP_PTJ_CTR.json.gz'\n",
    "tmp=drive_files.load_biblio(UDEAjsonfile,compression='gzip')\n",
    "UDEA=drive_files.biblio['WOS'].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AU=drive_files.read_drive_excel('Base_de_datos_investigadores_Definitiva.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTJ=drive_files.read_drive_excel('produccion_fecha_vig_2003_2018.xlsx')\n",
    "AU_PTJ=PTJ[['cedula','nombre']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL=True\n",
    "if LOCAL:\n",
    "    UDEA.to_json('WOS_SCI_SCP_PTJ_CTR.json.gz',orient='records')\n",
    "    AU.to_json('AU.json')\n",
    "    AU_PTJ.to_json('AU_PTJ.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_LOAD=False\n",
    "if LOCAL_LOAD:\n",
    "    UDEA=pd.read_json('WOS_SCI_SCP_PTJ_CTR.json.gz')\n",
    "    AU=pd.read_json('AU.json').reset_index(drop=True)\n",
    "    AU_PTJ=pd.read_json('AU_PTJ.json').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UDEA=pd.read_json('/home/restrepo/Downloads/WOS_SCI_SCP_PTJ_CTR.json.gz').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15642, 184)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[UDEA['UDEA_authors']!=''].reset_index(drop=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15642, 184)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relacionada con autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize `'AU'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['AU']=UDEA['AU'].apply(lambda l: l if re.search('\\n$',l) \n",
    "                 else \n",
    "                 '\\n'.join(\n",
    "            [\n",
    "    re.sub( '([\\w\\-\\s]+)(\\s[\\w]\\.)',r'\\1,\\2',s ,re.UNICODE   ) \n",
    "                 for s in l.split(', ')]+['']\n",
    "           ).replace('.','') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 184)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[~UDEA['AU'].str.contains('\\n$')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize `'authors_WOS'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specific entries\n",
    "#('mcewen, juan g', 65) → mc ewen\n",
    "#'hincape, me' → hincapie\n",
    "def fix_WOS_author_Trujilloii(l):\n",
    "    for i in range(len(l)):\n",
    "        if l[i].get('WOS_author') and l[i].get('WOS_author')=='Trujilloii, S. B.':\n",
    "            l[i]={'WOS_author': 'Trujillo, S. B.',\n",
    "                  'affiliation': [\n",
    "                    'Facultad de Medicina, Sede de Investigación Universitaria (SIU), Univ Antioquia, Medellín, Colombia'\n",
    "                   ],\n",
    "                  'i': 3}\n",
    "        if l[i].get('WOS_author') and l[i].get('WOS_author')=='Manuel, J':\n",
    "            l[i]={'WOS_author':'Senior Sanchez, Juan Manuel'}\n",
    "            \n",
    "        if l[i].get('WOS_author') and l[i].get('WOS_author')=='Balthazar, Vital':\n",
    "            l[i]={'WOS_author': 'Baltazar, Vital',\n",
    "                  'affiliation': ['Univ Antioquia, Colombia.'],\n",
    "                  'i': 4}\n",
    "        if l[i].get('WOS_author') and l[i].get('WOS_author')=='Oliviera-Angel, M':\n",
    "            l[i]={'WOS_author': 'Olivera-Angel, M',\n",
    "              'affiliation': ['Univ Antioquia, Fac Ciencias Agrarias Fisiol & Biotecnol Reprod, Antioquia, Colombia.']}            \n",
    "    return l\n",
    "UDEA['authors_WOS']=UDEA['authors_WOS'].apply( fix_WOS_author_Trujilloii )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_affilitions_to_authors_WOS(row_authors_WOS,row_C1,row_SCP_Affiliations):\n",
    "    l=row_authors_WOS\n",
    "    #Get rid of multiple author affiliations\n",
    "    #TODO: Count multiple author affiliations\n",
    "    row_C1=re.sub(r'\\[[\\w\\.\\s,]+\\n[\\w\\.\\s,]+\\]','',row_C1,re.UNICODE)\n",
    "    afwos=row_C1.strip().split('\\n')\n",
    "    afscp=row_SCP_Affiliations.strip().split('; ')\n",
    "    if len(afwos)==1:\n",
    "        af=re.sub('\\[.*\\]\\s*','',afwos[0])\n",
    "        for i in range( len(l) ):\n",
    "            if not l[i].get('affiliation'):\n",
    "                l[i].update({'affiliation':[af]})\n",
    "\n",
    "    if len(afwos)==len(l):\n",
    "        for i in range( len(l) ):\n",
    "            if not l[i].get('affiliation'):\n",
    "                af=re.sub('\\[.*\\]\\s*','',afwos[i])\n",
    "                l[i].update({'affiliation':[af]})\n",
    "            \n",
    "    elif len(afscp)==len(l):\n",
    "        for i in range( len(l) ):\n",
    "            if not l[i].get('affiliation'):\n",
    "                l[i].update({'affiliation':[afscp[i]]})\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_authors_WOS(row):\n",
    "    '''\n",
    "    if row 'authors_WOS' is empty, try to fill it\n",
    "    with AU and C1.\n",
    "    if not empty just return it\n",
    "    '''\n",
    "    l=[]\n",
    "    if len(row['authors_WOS'])==0:\n",
    "        if row['AU']:\n",
    "            l=[ {'WOS_author':a} for a in row['AU'].strip().split('\\n') ]\n",
    "        #Affiliations:\n",
    "        row_C1=row['C1']\n",
    "        row_SCP_Affiliations=row['SCP_Affiliations']\n",
    "        l=add_affilitions_to_authors_WOS(l,row_C1,row_SCP_Affiliations)\n",
    "    else:\n",
    "        l=row['authors_WOS']\n",
    "                     \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['authors_WOS']=UDEA.apply(missing_authors_WOS,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_AU_authors(AU1,AU2,fuzz_partial_ratio=60):\n",
    "    '''\n",
    "    Check if two authors in the WOS AU format are the same\n",
    "    '''\n",
    "    AU1_eq_AU2=False\n",
    "    #Check last name\n",
    "    au1=AU1.split(', ')\n",
    "    au2=AU2.split(', ')\n",
    "    au1=[unidecode.unidecode(a.lower()) for a in au1]\n",
    "    au2=[unidecode.unidecode(a.lower()) for a in au2]\n",
    "    ln=np.intersect1d(au1[0].split(),au2[0].split()).shape[0]\n",
    "    if ln>0:\n",
    "        fn=np.intersect1d(  \n",
    "            [ l[0] for l in au1[-1].split()],\n",
    "            [l[0] for l in au2[-1].split()] ).shape[0]\n",
    "        if fn>0:\n",
    "            if fuzz.partial_ratio( AU1,AU2 )>fuzz_partial_ratio:\n",
    "                AU1_eq_AU2=True\n",
    "    return AU1_eq_AU2\n",
    "\n",
    "def AU_to_authors_WOS(row,DEBUG=False):\n",
    "    '''\n",
    "     Compare 'WOS_author' → 'authors_WOS' with\n",
    "             'AU' splitted list\n",
    "     and fill for the missing 'authors_WOS' and\n",
    "                              'affiliations'\n",
    "    '''\n",
    "    auwos=[d.get('WOS_author') for d in row['authors_WOS']]\n",
    "    aurow=row['AU'].strip().split('\\n')\n",
    "    if len(auwos)<len(aurow):\n",
    "        for au in aurow:\n",
    "            NEW_AU=True\n",
    "            for ws in auwos:\n",
    "                if DEBUG:\n",
    "                    print(au,'::',ws,'→',  check_AU_authors( au,ws) )\n",
    "                if check_AU_authors( au,ws):\n",
    "                    NEW_AU=False\n",
    "                    break\n",
    "            if NEW_AU:\n",
    "                row['authors_WOS'].append(  \n",
    "                    {'WOS_author':au})\n",
    "        row['authors_WOS']=add_affilitions_to_authors_WOS(row['authors_WOS'],\n",
    "                                       row['C1'],\n",
    "                                       row['SCP_Affiliations'])\n",
    "    return row['authors_WOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['authors_WOS']=UDEA.apply(AU_to_authors_WOS,axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize `'UDEA_authors'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_long_names(l):\n",
    "    if len(l)>0:\n",
    "        for i in range( len(l) ):\n",
    "            if  l[i].get('full_name') and len(l[i].get('full_name').split())>4:\n",
    "                dd=split_names(l[i].get('full_name'))\n",
    "                l[i].update(dd)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply( fix_long_names  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(l):\n",
    "    \"\"\"\n",
    "    Find duplicates in UDEA_authors by 'CÉDULA'\n",
    "    \"\"\"\n",
    "    if len(l)>1:\n",
    "        #Try to find duplicates j-times\n",
    "        for j in range( int((len(l)+1)/2)   ):\n",
    "            c=[]\n",
    "            #In each try remove duplicated\n",
    "            for i in range(len(l)):\n",
    "                if l[i].get('CÉDULA') in c:\n",
    "                    l.pop(i)\n",
    "                    break\n",
    "                else:\n",
    "                    c.append(l[i].get('CÉDULA'))\n",
    "            #Exit when not more duplicate found\n",
    "            if not c:\n",
    "                break\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(drop_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_NOMBRE_COMPLETOS(l):\n",
    "    #for d in l:\n",
    "    for i in range(len(l)):\n",
    "        if not l[i].get('NOMBRE COMPLETO'):\n",
    "            d['NOMBRE COMPLETO']=''\n",
    "            if l[i].get('NOMBRES'):\n",
    "                l[i]['NOMBRE COMPLETO']=l[i]['NOMBRE COMPLETO']+l[i].get('NOMBRES')\n",
    "            if l[i].get('PRIMER APELLIDO'):\n",
    "                l[i]['NOMBRE COMPLETO']=l[i]['NOMBRE COMPLETO']+' '+l[i].get('PRIMER APELLIDO')\n",
    "            if l[i].get('SEGUNDO APELLIDO'):\n",
    "                l[i]['NOMBRE COMPLETO']=l[i]['NOMBRE COMPLETO']+' '+l[i].get('SEGUNDO APELLIDO')            \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(fix_NOMBRE_COMPLETOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfid=UDEA[['UDEA_nombre','UDEA_cedula']]\n",
    "dfid=dfid[dfid['UDEA_cedula'].apply(lambda n: n!=0 if isinstance(n,int) else False)].reset_index(drop=True)\n",
    "dfid=dfid[dfid['UDEA_nombre']!=''].drop_duplicates().reset_index(drop=True)\n",
    "dfid.shape\n",
    "\n",
    "def get_cedula(l,fullnames_with_id=dfid):\n",
    "    #for d in l:\n",
    "    for i in range(len(l)):\n",
    "        if not l[i].get('CÉDULA') and l[i].get('full_name'):\n",
    "            try:\n",
    "                l[i]['CÉDULA']=dfid[ ( dfid['UDEA_nombre']==l[i].get('full_name')) \n",
    "                            & ( dfid['UDEA_cedula']!=0 ) \n",
    "                            ].reset_index(\n",
    "                          drop=True)['UDEA_cedula'].loc[0]\n",
    "            except KeyError:\n",
    "                pass\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(get_cedula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_cedula(l,AU=AU):\n",
    "    '''\n",
    "    AU: Data Frame with author info\n",
    "    Added Facultad y afiliacion WOS\n",
    "    '''\n",
    "    for i in range(len(l)):\n",
    "        if not l[i].get('CÉDULA'):\n",
    "            au=AU[AU['NOMBRE COMPLETO']==l[i].get('NOMBRE COMPLETO')\n",
    "                 ].reset_index(drop=True)\n",
    "            if not au.empty:\n",
    "                au=au.loc[0]\n",
    "                l[i]['CÉDULA']=au['CÉDULA']\n",
    "                if not l[i].get('DEPARTAMENTO'):\n",
    "                    l[i]['DEPARTAMENTO']=au['DEPARTAMENTO']\n",
    "                if not l[i].get('FACULTAD'):\n",
    "                    l[i]['FACULTAD']=au['FACULTAD']\n",
    "                if not l[i].get('NOMBRES'):\n",
    "                    l[i]['NOMBRES']=au['NOMBRES']\n",
    "                if not l[i].get('PRIMER APELLIDO'):\n",
    "                    l[i]['PRIMER APELLIDO']=au['PRIMER APELLIDO']\n",
    "                if not l[i].get('SEGUNDO APELLIDO'):\n",
    "                    l[i]['SEGUNDO APELLIDO']=au['SEGUNDO APELLIDO']\n",
    "                if not l[i].get('INICIALES'):\n",
    "                    s=au['NOMBRES']\n",
    "                    l[i]['INICIALES']=' '.join(\n",
    "                        [ I[0]+'.' for I in s.split() ])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(get_missing_cedula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_cedula(l,df=AU_PTJ,full_name='nombre',identification='cedula'):\n",
    "    '''\n",
    "    Get missing identification from an external database with\n",
    "    the full name in the proper format:\n",
    "     `full name`: LAST NAME FIRST NAME\n",
    "    For each row, rebuild the list of dictionaries\n",
    "    and if CÉDULA is missing try to fix it\n",
    "    '''\n",
    "    for i in range(len(l)):\n",
    "        if not l[i].get('CÉDULA'):\n",
    "            try:\n",
    "                l[i]['CÉDULA']=df[df[nombre]==l[i].get('full_name')\n",
    "                     ].reset_index(drop=True).loc[\n",
    "                    0,identification]\n",
    "            except:\n",
    "                pass\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(fix_cedula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['C1']=UDEA['C1'].str.replace('deAntioquia','de Antioquia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_WOS_author_and_WOS_affiliation_to_UDEA_authores(l,i,df,j):\n",
    "    if not l[i].get('WOS_author'):\n",
    "        l[i]['WOS_author']=[df.loc[j,'WOS_author']]\n",
    "    if 'UDEA_affiliation' in df.columns:\n",
    "        if not l[i].get('UDEA_affiliation'):\n",
    "            l[i]['UDEA_affiliation']=df.loc[j,'affiliation']\n",
    "    return l[i]\n",
    "\n",
    "def compare_names(l,i,ll,j,smin=70,DEBUG=False):\n",
    "    '''\n",
    "    Compare dictionaries with UDEA_authors keys\n",
    "    with DataFrame ll authors_WOS columns\n",
    "    1. Select first matching first last name\n",
    "       a. If failed select first mathcing second last name\n",
    "          with extra quality check in full name\n",
    "    2. First mathching names\n",
    "       a. If failed first matching initials\n",
    "    '''\n",
    "    #j=-1 initialized in main function\n",
    "    if DEBUG: print('i:',i)\n",
    "    #Find First last name\n",
    "    r=process.extractOne( unidecode.unidecode( l[i].get('PRIMER APELLIDO').lower() ),  \n",
    "                       ll['WOS_author'].str.lower().apply(unidecode.unidecode\n",
    "                                    ).str.split(', ').str[0],scorer=fuzz.partial_ratio )\n",
    "    if DEBUG: print(r)\n",
    "    if r[1]==100:\n",
    "        j=r[2]\n",
    "        \n",
    "    #If failed, try with the second last name\n",
    "    if r[1]<100:\n",
    "        r=process.extractOne( unidecode.unidecode( l[i].get('SEGUNDO APELLIDO').lower() ),  \n",
    "                           ll['WOS_author'].str.lower().apply(unidecode.unidecode\n",
    "                                        ).str.split(', ').str[0],scorer=fuzz.partial_ratio )\n",
    "        #Additional quality check\n",
    "        j=r[2]\n",
    "        s=fuzz.token_set_ratio( \n",
    "            unidecode.unidecode( l[i].get('NOMBRE COMPLETO').lower().replace('.','') ) ,\n",
    "            unidecode.unidecode(ll['WOS_author'].loc[j].lower().replace('.','')  ) )\n",
    "        if DEBUG: print(r)\n",
    "        #print(s)\n",
    "        if r[1]==100 and s>smin:\n",
    "            j=r[2]\n",
    "        else:\n",
    "            j=-1\n",
    "        \n",
    "    #For names filter Initials:\n",
    "    kk=ll[ll['WOS_author'].str.lower().apply(unidecode.unidecode\n",
    "                        ).str.split(\n",
    "                    ', ').str[-1].str.replace(\n",
    "                 '\\.','').apply(len)>2]\n",
    "    if not kk.empty:\n",
    "        if DEBUG: print(unidecode.unidecode( l[i].get('NOMBRES').lower().split(' ')[0] ) )\n",
    "        r=process.extractOne( unidecode.unidecode( l[i].get('NOMBRES').lower().split(' ')[0] )\n",
    "                           ,  kk['WOS_author'].str.lower().apply(unidecode.unidecode).str.split(', ').str[-1],scorer=fuzz.partial_ratio )\n",
    "        if r[1]==100 and r[2]==j:\n",
    "            if DEBUG: print('found FN j=',r[2])\n",
    "            l[i]=add_WOS_author_and_WOS_affiliation_to_UDEA_authores(l,i,ll,j)\n",
    "            return l,i,ll,j\n",
    "\n",
    "        if DEBUG: print(r)\n",
    "        #if not 100 try second name: fail proof\n",
    "        if DEBUG: print(unidecode.unidecode( l[i].get('NOMBRES').lower().split(' ')[-1]) ) \n",
    "        r=process.extractOne( unidecode.unidecode( l[i].get('NOMBRES').lower().split(' ')[-1] )\n",
    "                           ,  kk['WOS_author'].str.lower().apply(unidecode.unidecode).str.split(', ').str[-1],scorer=fuzz.partial_ratio )\n",
    "        if DEBUG: print(r)\n",
    "        if r[1]==100 and r[2]==j:\n",
    "            if DEBUG: print('found SN j=',r[2])\n",
    "            l[i]=add_WOS_author_and_WOS_affiliation_to_UDEA_authores(l,i,ll,j)        \n",
    "            return l,i,ll,j\n",
    "    \n",
    "    #if not 100 try first intial: fail proof\n",
    "    if DEBUG: print(unidecode.unidecode( l[i].get('INICIALES').lower().replace('.','').split(' ')[0]) )\n",
    "    r=process.extract( unidecode.unidecode( l[i].get('INICIALES').lower().replace('.','').split(' ')[0]) \n",
    "                       ,  ll['WOS_author'].str.lower().apply(unidecode.unidecode\n",
    "                                            ).str.replace('\\.','').str.split(', ').str[-1],scorer=fuzz.partial_ratio )\n",
    "    if DEBUG: print(r)\n",
    "    rrr=[(rr[1],rr[2]) for rr in r if rr[2]==j]\n",
    "    if rrr and rrr[0][0]==100:\n",
    "        if DEBUG: print('found FI j=',rrr[0][1])\n",
    "        l[i]=add_WOS_author_and_WOS_affiliation_to_UDEA_authores(l,i,ll,j)        \n",
    "        return l,i,ll,j\n",
    "\n",
    "    #if not 100 try second intial: fail proof\n",
    "    if DEBUG: print(unidecode.unidecode( l[i].get('INICIALES').lower().replace('.','').split(' ')[-1]) )\n",
    "    r=process.extract( unidecode.unidecode( l[i].get('INICIALES').lower().replace('.','').split(' ')[-1]) \n",
    "                       ,ll['WOS_author'].str.lower().apply(unidecode.unidecode\n",
    "                                        ).str.replace('\\.','').str.split(', ').str[-1],scorer=fuzz.partial_ratio )\n",
    "    if DEBUG: print(r)\n",
    "    rrr=[(rr[1],rr[2]) for rr in r if rr[2]==j]\n",
    "    if rrr and rrr[0][0]==100:\n",
    "        if DEBUG: print('found SI j=',rrr[0][1])\n",
    "        l[i]=add_WOS_author_and_WOS_affiliation_to_UDEA_authores(l,i,ll,j)\n",
    "        return l,i,ll,j\n",
    "\n",
    "    #Some times the first last are confused with the first names\n",
    "    #'Luis Fernando Restrepo Betancur' → 'Luis Restrepo, B.''\n",
    "    # One of the last name is already covered so only the initials are affected\n",
    "    #if not 100 try second intial: fail proof\n",
    "    r=process.extract( unidecode.unidecode( l[i].get('PRIMER APELLIDO').lower()[0] )\n",
    "                       ,ll['WOS_author'].str.lower().apply(unidecode.unidecode\n",
    "                                        ).str.replace('\\.','').str.split(', ').str[-1],scorer=fuzz.partial_ratio )\n",
    "    if DEBUG: print(r)\n",
    "    rrr=[(rr[1],rr[2]) for rr in r if rr[2]==j]\n",
    "    if rrr and rrr[0][0]==100:\n",
    "        if DEBUG: print('found SI j=',rrr[0][1])\n",
    "        l[i]=add_WOS_author_and_WOS_affiliation_to_UDEA_authores(l,i,ll,j)\n",
    "        return l,i,ll,j\n",
    "\n",
    "    if l[i].get('SEGUNDO APELLIDO'):\n",
    "        r=process.extract( unidecode.unidecode( l[i].get('SEGUNDO APELLIDO').lower()[0] ) \n",
    "                           ,ll['WOS_author'].str.lower().apply(unidecode.unidecode\n",
    "                                            ).str.replace('\\.','').str.split(', ').str[-1],scorer=fuzz.partial_ratio )\n",
    "        if DEBUG: print(r)\n",
    "        rrr=[(rr[1],rr[2]) for rr in r if rr[2]==j]\n",
    "        if rrr and rrr[0][0]==100:\n",
    "            if DEBUG: print('found SI j=',rrr[0][1])\n",
    "            l[i]=add_WOS_author_and_WOS_affiliation_to_UDEA_authores(l,i,ll,j)\n",
    "            return l,i,ll,j\n",
    "                      \n",
    "    \n",
    "    \n",
    "    #print('final result: extract WOS_author and affiliauntion as lists:',lll[j])\n",
    "\n",
    "    return l,i,ll,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_wos_authors_in_udea_authors(row):\n",
    "    '''\n",
    "    Compare UDEA_authors with authors_WOS and\n",
    "    fill: \n",
    "    A) mising 'WOS_author' list in  UDEA_authors\n",
    "    B) mising 'affiliation' list in  UDEA_authors\n",
    "    1. Select first matching first last name\n",
    "       a. If failed select first mathcing second last name\n",
    "          with extra quality check in full name\n",
    "    2. First mathching names\n",
    "       a. If failed first matching initials\n",
    "    '''    \n",
    "    i=0\n",
    "    j=-1\n",
    "    l  =row['UDEA_authors']\n",
    "    lll=row['authors_WOS']\n",
    "    if lll:\n",
    "        ll=pd.DataFrame(lll)\n",
    "    else:\n",
    "        ll=pd.DataFrame()\n",
    "    #if not ll.empty:\n",
    "    for i in range(len(l)):\n",
    "        if not l[i].get('WOS_author'):\n",
    "            l,i,ll,j=compare_names(l,i,ll,j,DEBUG=False)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA.apply(missing_wos_authors_in_udea_authors,axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove bad identified authors from the list in `UDEA_authors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['Index']=list(UDEA.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_WOS_author_to_UDEA_authors(row_UDEA_authors_i,au,row_authors_WOS,iau):\n",
    "    if not row_UDEA_authors_i.get('WOS_author'):\n",
    "        row_UDEA_authors_i['WOS_author']=[au]\n",
    "    else: #'WOS_author' list exists\n",
    "        udeaiw=[unidecode.unidecode(s.lower().replace('.','').replace('-',' ')\n",
    "                                   ) for s in  row_UDEA_authors_i['WOS_author']]\n",
    "        if au not in udeaiw:\n",
    "            #print('Check au not on WOS_author:',row_authors_WOS[iau].get('WOS_author'),row_UDEA_authors_i['WOS_author'])\n",
    "            row_UDEA_authors_i['WOS_author'].append(row_authors_WOS[iau].get('WOS_author'))\n",
    "    if not row_UDEA_authors_i.get('WOS_affiliation') and row_authors_WOS[iau].get('affiliation'):\n",
    "        aff=row_authors_WOS[iau]['affiliation'] \n",
    "        row_UDEA_authors_i['WOS_affiliation']=aff\n",
    "                \n",
    "                \n",
    "def Quality_UDEA_authors(row,maxlmin=74,DEBUG=False):\n",
    "    '''\n",
    "    Check the Quality for the match \n",
    "      UDEA_authors \n",
    "    with \n",
    "      authors_WOS\n",
    "    '''\n",
    "    #print('**',row['Index'])\n",
    "    wos_list =[ unidecode.unidecode( d.get('WOS_author').lower(\n",
    "                                     ).replace('.',''\n",
    "                                     ).replace('-',' ')\n",
    "                                   )\n",
    "               for d in row.get('authors_WOS')]\n",
    "\n",
    "    #If WOS_author not in row.get('UDEA_authors') is usually to be droppend\n",
    "    \n",
    "    \n",
    "    udea_list=[ \n",
    "            [\n",
    "              unidecode.unidecode( dd.lower(\n",
    "                                     ).replace('.',''\n",
    "                                     ).replace('-',' ')\n",
    "                                 ) \n",
    "              for dd in d.get('WOS_author')\n",
    "            ]\n",
    "                if d.get('WOS_author') \n",
    "                else \n",
    "            [      \n",
    "                unidecode.unidecode(\n",
    "                  '{} {}, {}'.format(d.get('PRIMER APELLIDO'),\n",
    "                                     d.get('SEGUNDO APELLIDO'),\n",
    "                                     d.get('NOMBRES')\n",
    "                                    ).replace(' ,',','\n",
    "                                    ).strip(\n",
    "                                    ).lower()\n",
    "                  )\n",
    "             ]\n",
    "                  for d in row.get('UDEA_authors')\n",
    "           ]    \n",
    "    udea_list=[ list(set(l)) for l in udea_list  ]\n",
    "    \n",
    "    if not udea_list:\n",
    "        if DEBUG: print('==1==')\n",
    "        Q=True\n",
    "        return Q\n",
    "    for i in range(len(udea_list)): #=len(row['UDEA_authors'])\n",
    "    #for l in udea_list: #=len(row['UDEA_authors'])\n",
    "        Q=False\n",
    "        for au in wos_list:\n",
    "            #Exact match\n",
    "            r=np.intersect1d( [au],udea_list[i] ).shape[0]\n",
    "            if r>0:\n",
    "                if DEBUG: print('==2==')\n",
    "                Q=True\n",
    "                break\n",
    "            else:\n",
    "                #Similarity match\n",
    "                #print(au,udea_list[i])\n",
    "                rr=process.extractOne(au,udea_list[i],scorer=fuzz.partial_ratio)\n",
    "                if rr[1]==100:\n",
    "                    kk=add_WOS_author_to_UDEA_authors(row['UDEA_authors'][i],au,\n",
    "                                                      row['authors_WOS'],wos_list.index(au) )                                        \n",
    "                    if DEBUG: print('==3==')\n",
    "                    Q=True\n",
    "                    break\n",
    "                #print(rr)\n",
    "                rr=process.extractOne(au,udea_list[i],scorer=fuzz.token_set_ratio)\n",
    "                if rr[1]==100:\n",
    "                    kk=add_WOS_author_to_UDEA_authors(row['UDEA_authors'][i],au,\n",
    "                                                      row['authors_WOS'],wos_list.index(au) )                                        \n",
    "                    if DEBUG: print('==4==')\n",
    "                    Q=True\n",
    "                    break\n",
    "                #keep only the first letter of names\n",
    "                fnau=re.sub('([\\w\\s]+\\,\\s\\w)[\\w\\s]+',r'\\1',au)\n",
    "                l=[re.sub('([\\w\\s]+\\,\\s\\w)[\\w\\s]+',r'\\1',ll) for ll in udea_list[i]]\n",
    "                #print(l)\n",
    "                rr=process.extractOne(fnau,l,scorer=fuzz.token_set_ratio)\n",
    "                if rr[1]==100:\n",
    "                    kk=add_WOS_author_to_UDEA_authors(row['UDEA_authors'][i],au,\n",
    "                                                      row['authors_WOS'],wos_list.index(au) )                    \n",
    "                    if DEBUG: print('==5==')\n",
    "                    Q=True\n",
    "                    break\n",
    "                    \n",
    "                #keep only first letter of second last name\n",
    "                l=[re.sub('(\\s\\w)\\w+\\,',r'\\1,',ll) for ll in udea_list[i]]\n",
    "                #print(l)\n",
    "                rr=process.extractOne(au,l,scorer=fuzz.token_set_ratio)\n",
    "                if rr[1]==100:\n",
    "                    kk=add_WOS_author_to_UDEA_authors(row['UDEA_authors'][i],au,\n",
    "                                                      row['authors_WOS'],wos_list.index(au) )                    \n",
    "                    if DEBUG: print('==6==')\n",
    "                    Q=True\n",
    "                    break\n",
    "\n",
    "                #remove first last name from udea_list[i] and the first letter of names\n",
    "                l=[re.sub('^\\w+\\s(\\w\\w+\\,\\s\\w)\\w+',r'\\1',ll) for ll in udea_list[i]]\n",
    "                #print(l)\n",
    "                rr=process.extractOne(au,l,scorer=fuzz.token_set_ratio)\n",
    "                if rr[1]==100:\n",
    "                    kk=add_WOS_author_to_UDEA_authors(row['UDEA_authors'][i],au,\n",
    "                                                      row['authors_WOS'],wos_list.index(au) )                    \n",
    "                    if DEBUG: print('==7==')\n",
    "                    Q=True\n",
    "                    break\n",
    "                #Very similar names in any order\n",
    "                #print('*',au,udea_list[i])\n",
    "                rr=process.extractOne(au,udea_list[i],scorer=fuzz.token_sort_ratio)\n",
    "                if rr[1]>95:\n",
    "                    kk=add_WOS_author_to_UDEA_authors(row['UDEA_authors'][i],au,\n",
    "                                                      row['authors_WOS'],wos_list.index(au) )                    \n",
    "                    if DEBUG: print('==8==')\n",
    "                    Q=True\n",
    "                    break\n",
    "                #Keep only first last name and the first letter of names\n",
    "                fnau= re.sub('(^\\w\\w+)\\s\\w+(\\,\\s\\w)[\\s\\w]*',r'\\1\\2',au)\n",
    "                l   =[re.sub('(^\\w\\w+)\\s\\w+(\\,\\s\\w)[\\s\\w]*',r'\\1\\2',ll) for ll in udea_list[i]]\n",
    "                #print(l)\n",
    "                rr=process.extractOne(fnau,l,scorer=fuzz.token_set_ratio)\n",
    "                if rr[1]==100:\n",
    "                    kk=add_WOS_author_to_UDEA_authors(row['UDEA_authors'][i],au,\n",
    "                                                      row['authors_WOS'],wos_list.index(au) )                    \n",
    "                    if DEBUG: print('==9==')\n",
    "                    Q=True\n",
    "                    break\n",
    "                \n",
    "                #Q=False\n",
    "        if not Q:\n",
    "            maxl=0\n",
    "            for j in range(len(udea_list[i])):\n",
    "                rr=process.extractOne(udea_list[i][j],wos_list,scorer=fuzz.ratio)\n",
    "                if DEBUG: print(rr)\n",
    "                if rr[1]>maxl:\n",
    "                    maxl=rr[1]\n",
    "            if DEBUG: print(udea_list[i],i,j,maxl)\n",
    "            #keep if maxl>maxlmin See step: ==10===\n",
    "            #print('*',row['UDEA_authors'],i)\n",
    "            if maxl>maxlmin:\n",
    "                #udea_list[i][j],wos_list\n",
    "                #print('Check rr[0] not on WOS_author:',rr[0],row['UDEA_authors'][i].get('WOS_author'))\n",
    "\n",
    "                kk=add_WOS_author_to_UDEA_authors(row['UDEA_authors'][i],rr[0],\n",
    "                                                      row['authors_WOS'],wos_list.index(rr[0]) )\n",
    "                if DEBUG: print('==10==')\n",
    "                Q=True\n",
    "                return Q\n",
    "            else:  #Remove and exit\n",
    "                row['UDEA_authors'].pop(i)\n",
    "                return Q\n",
    "            \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=7\n",
    "#UDEA.loc[[i]].apply(lambda row:Quality_UDEA_authors(row,DEBUG=True),axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "kold=pd.np.inf\n",
    "while True:\n",
    "    Q=UDEA.apply(Quality_UDEA_authors,axis='columns')\n",
    "    kk=UDEA[~Q].shape[0]\n",
    "    print(kk)\n",
    "    if kk==0 or kk==kold:\n",
    "        kold=kk\n",
    "        UDEA['NEW_Q']=Q\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new `NEW_authors` column with full authors in JSON format. ONLY AFTER PREVIOUS NORMALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wos(d):\n",
    "    dd={}\n",
    "    for k, v in d.items():\n",
    "        if k=='affiliation':\n",
    "            dd['WOS_{}'.format(k)]=v\n",
    "        elif k=='WOS_author':\n",
    "            dd[k]=[v]\n",
    "        else:\n",
    "            dd[k]=v\n",
    "    return dd\n",
    "    \n",
    "def authors(row,DEBUG=False):\n",
    "    '''\n",
    "    Check the Quality for the match \n",
    "      UDEA_authors \n",
    "    with \n",
    "      authors_WOS\n",
    "    '''\n",
    "    ll=[]\n",
    "    if not row['NEW_Q']:\n",
    "        print('WARNING: bad quality record!')\n",
    "        return ll\n",
    "\n",
    "    wos_list =[  d.get('WOS_author') for d in row.get('authors_WOS')]\n",
    "    \n",
    "    udea_list=[  [dd for dd in d.get('WOS_author')]\n",
    "                   if d.get('WOS_author') \n",
    "                   else []\n",
    "                for d in row.get('UDEA_authors') ]\n",
    "    \n",
    "    udea_list=[ list(set(l)) for l in udea_list  ]\n",
    "    \n",
    "    if not udea_list:\n",
    "        for d in row['authors_WOS']:\n",
    "            ll.append(add_wos(d))\n",
    "        if DEBUG: print('==1==')\n",
    "        return ll\n",
    "\n",
    "    for i in range(len(wos_list)):\n",
    "        dd={}\n",
    "        ADD=True\n",
    "        for j in range(len(udea_list)): #=len(row['UDEA_authors'])\n",
    "            r=np.intersect1d( [wos_list[i]],udea_list[j] ).shape[0]\n",
    "            if r>0:\n",
    "                ADD=False\n",
    "                ll.append( row['UDEA_authors'][j].copy()  )\n",
    "                if DEBUG: print('==2==')                \n",
    "                break\n",
    "        if ADD:\n",
    "            ll.append(add_wos( row['authors_WOS'][i] ) )\n",
    "            if DEBUG: print('==2==')\n",
    "            \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=1\n",
    "#UDEA.loc[[i]].apply(lambda row:authors(row,DEBUG=True),axis='columns').loc[i]\n",
    "#UDEA.loc[[i]].apply(lambda row:authors(row,DEBUG=True),axis='columns').loc[i]\n",
    "#UDEA.loc[i,'authors_WOS']#[0]['WOS_author']='manuel, j'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['NEW_authors']=UDEA.apply(authors,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_authors']=UDEA['UDEA_authors'].apply(lambda l: l if l else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12110, 184)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[UDEA['UDEA_authors'].apply(lambda l: len(l)>0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15642, 184)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UDEA[UDEA['NEW_authors'].apply(lambda l: len(l)>0)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['DI']=UDEA.apply( \n",
    "     lambda row: row['DI'] if row['DI'] else row['SCP_DOI'],axis=1 ).str.strip().str.lower()\n",
    "UDEA['DI']=UDEA.apply( \n",
    "     lambda row: row['DI'] if row['DI'] else row['SCI_DI'],axis=1 ).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_NAME(row,WOS_NAME,SCI_NAME,SCP_NAME,UDEA_NAME,\n",
    "                   SCI_sub=('',''),SCP_sub=('',''),UDEA_sub=('',''),\n",
    "                  DEBUG=False):\n",
    "    '''\n",
    "    If the WOS of Science column is empty, copy the\n",
    "    data from a filled column either from \n",
    "    * SCI\n",
    "    * SCP\n",
    "    * UDEA\n",
    "    '''\n",
    "    sn=row[WOS_NAME]\n",
    "    if not sn:\n",
    "        if SCI_NAME and row[SCI_NAME]:\n",
    "            sn=re.sub( SCI_sub[0],SCI_sub[1], str( row[SCI_NAME] ) )\n",
    "            if DEBUG:\n",
    "                print('SCI: {}:{}'.format(row[SCI_NAME], sn))\n",
    "        elif SCP_NAME and row[SCP_NAME]:\n",
    "            sn=re.sub( SCP_sub[0],SCP_sub[1], str( row[SCP_NAME] ) )\n",
    "        elif UDEA_NAME and row[UDEA_NAME]:\n",
    "            sn=re.sub( SCP_sub[0],SCP_sub[1], str( row[UDEA_NAME] ) )\n",
    "            if DEBUG:\n",
    "                print('UDEA: {}:{}'.format(row[UDEA_NAME], sn))            \n",
    "    return sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_NAME ='SN'\n",
    "UDEA[WOS_NAME]=UDEA.apply(lambda row: \n",
    "                       normalize_NAME(row,WOS_NAME,\n",
    "                                      SCI_NAME ='SCI_SN',\n",
    "                                      SCP_NAME ='SCP_ISSN',\n",
    "                                      UDEA_NAME='UDEA_issn rev',\n",
    "                                      SCP_sub=( '^([\\w]{4})([\\w]{4})$',r'\\1-\\2\\n'  ),\n",
    "                                      UDEA_sub=('(\\w)$',r'\\1\\n')\n",
    "                                     )\n",
    "                      ,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_NAME ='DI'\n",
    "UDEA[WOS_NAME]=UDEA.apply(lambda row: \n",
    "                       normalize_NAME(row,WOS_NAME,\n",
    "                                      SCI_NAME ='SCI_DI',\n",
    "                                      SCP_NAME ='SCP_DOI',\n",
    "                                      UDEA_NAME='UDEA_doi')\n",
    "                      ,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_NAME ='VL'\n",
    "UDEA[WOS_NAME]=UDEA.apply(lambda row: \n",
    "                       normalize_NAME(row,WOS_NAME,\n",
    "                                      SCI_NAME ='SCI_VL',\n",
    "                                      SCP_NAME ='SCP_Volume',\n",
    "                                      UDEA_NAME='',\n",
    "                                      SCI_sub=('(\\w)$',r'\\1\\n'),\n",
    "                                      SCP_sub=('(\\w)$',r'\\1\\n')\n",
    "                                     )\n",
    "                      ,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_NAME ='IS'\n",
    "UDEA[WOS_NAME]=UDEA.apply(lambda row: \n",
    "                       normalize_NAME(row,WOS_NAME,\n",
    "                                      SCI_NAME ='SCI_IS',\n",
    "                                      SCP_NAME ='SCP_Issue',\n",
    "                                      UDEA_NAME='',\n",
    "                                      SCP_sub=('(\\w)$',r'\\1\\n')\n",
    "                                     )\n",
    "                      ,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_NAME ='BP'\n",
    "UDEA[WOS_NAME]=UDEA.apply(lambda row: \n",
    "                       normalize_NAME(row,WOS_NAME,\n",
    "                                      SCI_NAME ='SCI_BP',\n",
    "                                      SCP_NAME ='SCP_Page start',\n",
    "                                      UDEA_NAME='',\n",
    "                                      SCP_sub=('(\\w)$',r'\\1\\n')\n",
    "                                     )\n",
    "                      ,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_NAME ='EP'\n",
    "UDEA[WOS_NAME]=UDEA.apply(lambda row: \n",
    "                       normalize_NAME(row,WOS_NAME,\n",
    "                                      SCI_NAME ='SCI_EP',\n",
    "                                      SCP_NAME ='SCP_Page end',\n",
    "                                      UDEA_NAME='',\n",
    "                                      SCP_sub=('(\\w)$',r'\\1\\n')\n",
    "                                     )\n",
    "                      ,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "UDEA['UDEA_idioma']=UDEA['UDEA_idioma'].apply(lambda s: 'Spanish' if s=='ESPA?' else s)\n",
    "UDEA['UDEA_idioma']=UDEA['UDEA_idioma'].apply(lambda s: 'English' if s=='INGLE' else s)\n",
    "WOS_NAME ='LA'\n",
    "UDEA[WOS_NAME]=UDEA.apply(lambda row: \n",
    "                       normalize_NAME(row,WOS_NAME,\n",
    "                                      SCI_NAME ='SCI_LA',\n",
    "                                      SCP_NAME ='SCP_Language of Original Document',\n",
    "                                      UDEA_NAME='UDEA_idioma',\n",
    "                                      SCI_sub =('\\t',r''),\n",
    "                                      SCP_sub =('(\\w)$',r'\\1\\n'),\n",
    "                                      UDEA_sub=('(\\w)$',r'\\1\\n')\n",
    "                                     )\n",
    "                      ,axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "udea=UDEA.copy()\n",
    "udea=udea[udea['UDEA_authors'].apply(lambda l: len(l)>0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dictionary_keys_of_list_of_dictionaries_to_column_dataframe(df,\n",
    "                            json_column='UDEA_authors',dictionary_key='FACULTAD',sep='; '):\n",
    "    return df[json_column].apply(lambda l:  \n",
    "       [d.get(dictionary_key) for d in  l if type(l)==list and d.get(dictionary_key) ]  \n",
    "               ).apply(\n",
    "        pd.np.unique\n",
    "        ).apply(sep.join)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON=True\n",
    "if not JSON:\n",
    "    udea['FACULTAD']=convert_dictionary_keys_of_list_of_dictionaries_to_column_dataframe(udea,\n",
    "                                            json_column='UDEA_authors',dictionary_key='FACULTAD')\n",
    "    udea['DEPARTAMENTO']=convert_dictionary_keys_of_list_of_dictionaries_to_column_dataframe(udea,\n",
    "                                            json_column='UDEA_authors',dictionary_key='DEPARTAMENTO')\n",
    "    udea['GRUPO']=convert_dictionary_keys_of_list_of_dictionaries_to_column_dataframe(udea,\n",
    "                                            json_column='UDEA_authors',dictionary_key='GRUPO')\n",
    "    udea['autores_UDEA']=convert_dictionary_keys_of_list_of_dictionaries_to_column_dataframe(udea,\n",
    "                                            json_column='UDEA_authors',dictionary_key='full_name')\n",
    "if JSON:\n",
    "    año='annio'; título='tituloArticulo'; revista='nombreRevista'\n",
    "    issn='issn'; doi='doi'; volumen='volumen'; número='numero'\n",
    "    páginas='paginas'; semestre='semestre'; idioma='idioma'\n",
    "    tipoRevista='tipoRevista';     Colciencias='clasificacionColciencias'\n",
    "    proyecto='proyectoAsociado'\n",
    "    autores='autores'\n",
    "else:\n",
    "    año='Año';   título='Título del Artículo'; revista='Nombre de la Revista'\n",
    "    issn='ISSN'; doi='DOI'; volumen='Volumen'; número='numero'\n",
    "    páginas='Páginas'; semestre='Semestre'; idioma='Idioma'\n",
    "    tipoRevista='Tipo de Revista'; Colciencias='Clasificación Colciencias'\n",
    "    proyecto='Producto asociado a un proyecto de extensión o investigación'\n",
    "    udea['Nombre del proyecto de extensión o investigación']=''\n",
    "    autores='Autores'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('example.json','w')\n",
    "f.write(\n",
    "'''\n",
    "[{\n",
    "  \"autores\" : [ \n",
    "      {\n",
    "          \"nombreAutor\" : \"Jonathan Aguilar Bedoya\",\n",
    "          \"identificacionAutor\" : null,\n",
    "          \"tipoAutor\" : \"Estudiante de posgrado\",\n",
    "          \"programaAcademico\" : [ \n",
    "              \"60178-MAESTRÍA EN INGENIERÍA MECÁNICA-INVESTIGACIÓN\"\n",
    "          ],\n",
    "          \"grupoInvestigacion\" : [ \n",
    "              \"Grupo de Energía Alternativa\"\n",
    "          ]\n",
    "      }, \n",
    "      {\n",
    "          \"nombreAutor\" : \"Ainhoa Rubio Celemente\",\n",
    "          \"tipoAutor\" : \"Autor externo\",\n",
    "          \"grupoInvestigacion\" : [ \n",
    "              \"Grupo de Energía Alternativa\"\n",
    "          ],\n",
    "          \"institucion\" : \"Tecnológico de Antioquia. Institución Universitaria\",\n",
    "          \"pais\" : \"Colombia\"\n",
    "      }, \n",
    "      {\n",
    "          \"nombreAutor\" : \"Laura Isable Velasquez Garcia\",\n",
    "          \"tipoAutor\" : \"Profesor ocasional\",\n",
    "          \"programaAcademico\" : [ \n",
    "              \"516-INGENIERÍA MECÁNICA\"\n",
    "          ],\n",
    "          \"grupoInvestigacion\" : [ \n",
    "              \"Grupo de Energía Alternativa\"\n",
    "          ]\n",
    "      }, \n",
    "      {\n",
    "          \"nombreAutor\" : \"Edwin Lenin Chica Arrieta\",\n",
    "          \"identificacionAutor\" : \"...\",\n",
    "          \"tipoAutor\" : \"Profesor vinculado\",\n",
    "          \"programaAcademico\" : [ \n",
    "              \"516-INGENIERÍA MECÁNICA\"\n",
    "          ],\n",
    "          \"grupoInvestigacion\" : [ \n",
    "              \"Grupo de Energía Alternativa\"\n",
    "          ]\n",
    "      }\n",
    "  ],\n",
    "  \"tituloArticulo\" : \"Design and Optimization of a Multi-Element Hydrofoil for a Horizontal-Axis Hydrokinetic Turbine\",\n",
    "  \"nombreRevista\" : \"Energies\",\n",
    "  \"issn\" : \"1996-1073\",\n",
    "  \"doi\" : \"10.3390/en12244679\",\n",
    "  \"volumen\" : 12,\n",
    "  \"numero\" : 24,\n",
    "  \"paginas\" : \"1-18\",\n",
    "  \"annio\" : 2019,\n",
    "  \"semestre\" : \"2019-2\",\n",
    "  \"idioma\" : \"Inglés\",\n",
    "  \"tipoRevista\" : \"Revista Internacional Indexada\",\n",
    "  \"clasificacionColciencias\" : \"A1\",\n",
    "  \"proyectoAsociado\" : null\n",
    "}\n",
    "]\n",
    "'''\n",
    ")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_Autores(l,nombre='nombreAutor',tipo='tipoAutor',identificación='identificacionAutor',\n",
    "                institución='institucion',país='pais',grupo='grupoInvestigacion',\n",
    "                facultad='facultad',departamento='departamento'):\n",
    "    ll=[]\n",
    "    for d in l:\n",
    "        dd={}\n",
    "        if d.get('CÉDULA'):\n",
    "            dd[identificación]=int(d['CÉDULA'])\n",
    "\n",
    "        if d.get('NOMBRE COMPLETO') and d.get('full_name'):\n",
    "            dd[nombre]=d['NOMBRE COMPLETO']\n",
    "            dd[tipo]='Profesor vinculado'\n",
    "            dd[institución]='Universidad de Antioquia'\n",
    "            dd[país]='Colombia'\n",
    "        else:\n",
    "            if d.get('WOS_author'):\n",
    "                l=d['WOS_author'][0].split(', ')\n",
    "                dd[nombre]=l[-1]+' '+l[0]\n",
    "            if d.get('WOS_affiliation'):\n",
    "                dd[institución]=d['WOS_affiliation'][0]\n",
    "        if d.get('GRUPO'):\n",
    "            dd[grupo]=[d['GRUPO']]\n",
    "        if d.get('DEPARTAMENTO'):\n",
    "            dd[departamento]=d['DEPARTAMENTO']\n",
    "        if d.get('FACULTAD'):\n",
    "            dd[facultad]=d['FACULTAD']\n",
    "            \n",
    "        ll.append(dd)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "udea[autores]=udea['NEW_authors'].apply(new_Autores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "udea[título]=udea['TI']\n",
    "udea[revista]=udea['SO'].replace('\\n',' ')\n",
    "udea[issn]=udea['SN'].str.replace('\\n','')\n",
    "udea[doi]=udea['DI'].apply(lambda s: s if s else None)\n",
    "udea[volumen]=udea['VL'].str.replace('\\n','').apply(lambda s: s if s else None)\n",
    "udea[número]=udea['IS'].str.replace('\\n','')\n",
    "udea[páginas]=udea.apply(lambda row:\n",
    "                  row['BP'].replace('\\n','')+'-'+row['EP'].replace('\\n','') \n",
    "                  if row['BP'] \n",
    "                  else row['BP'],axis='columns').str.replace('\\-$','')\n",
    "udea[año]=udea['PY']\n",
    "udea[semestre]=None\n",
    "udea[idioma]=udea['LA'].str.replace('\\n','')\n",
    "udea[tipoRevista]=udea.apply(lambda row: 'Revista Internacional Indexada' \n",
    "           if row.get('Tipo').find('WOS')>-1 or row.get('Tipo').find('SCP')\n",
    "           else 'Revista Indexada en SCIELO',axis='columns')\n",
    "udea[Colciencias]=udea['UDEA_tipo mat'].str.replace('^\\w+([ABC][12]*)$',r'\\1' ).apply(\n",
    "                       lambda s:s if len(s)<3 else None)\n",
    "udea[proyecto]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JSON:\n",
    "    new_format=pd.read_json( 'example.json' )\n",
    "else:\n",
    "    new_format=pd.read_excel('https://docs.google.com/spreadsheets/d/e/2PACX-1vTiaxuZSGmI-aFgMUVjRAU3ws7WN9xmtjMEWu_SLOd5kAq_ZAuUtJUVr8qxNl3sMcp_fjE2gLVt_tdp/pub?output=xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls=[\"autores\",\"tituloArticulo\",\"nombreRevista\",\"issn\",\"doi\",\"volumen\",\"numero\",\n",
    "     \"paginas\",\"annio\",\"semestre\",\"idioma\",\"tipoRevista\",\n",
    "     \"clasificacionColciencias\",\"proyectoAsociado\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype='<U24')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.np.setdiff1d(cls,list(new_format.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autores</th>\n",
       "      <th>tituloArticulo</th>\n",
       "      <th>nombreRevista</th>\n",
       "      <th>issn</th>\n",
       "      <th>doi</th>\n",
       "      <th>volumen</th>\n",
       "      <th>numero</th>\n",
       "      <th>paginas</th>\n",
       "      <th>annio</th>\n",
       "      <th>semestre</th>\n",
       "      <th>idioma</th>\n",
       "      <th>tipoRevista</th>\n",
       "      <th>clasificacionColciencias</th>\n",
       "      <th>proyectoAsociado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'institucion': 'Universidad de Antioquia', 'nombreAutor': 'Edwin Garcia Quintero', 'tipoAutor': 'Profesor vinculado', 'grupoInvestigacion': ['Grupo de Investigación en Materiales y Sistemas Ener...</td>\n",
       "      <td>Methodology for evaluation of voltage sags</td>\n",
       "      <td>REVISTA FACULTAD DE INGENIERIA-UNIVERSIDAD DE ANTIOQUIA</td>\n",
       "      <td>0120-6230</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>53</td>\n",
       "      <td>196-204</td>\n",
       "      <td>2010</td>\n",
       "      <td>None</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Revista Internacional Indexada</td>\n",
       "      <td>A1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                   autores  \\\n",
       "0  [{'institucion': 'Universidad de Antioquia', 'nombreAutor': 'Edwin Garcia Quintero', 'tipoAutor': 'Profesor vinculado', 'grupoInvestigacion': ['Grupo de Investigación en Materiales y Sistemas Ener...   \n",
       "\n",
       "                               tituloArticulo  \\\n",
       "0  Methodology for evaluation of voltage sags   \n",
       "\n",
       "                                             nombreRevista       issn   doi  \\\n",
       "0  REVISTA FACULTAD DE INGENIERIA-UNIVERSIDAD DE ANTIOQUIA  0120-6230  None   \n",
       "\n",
       "  volumen numero  paginas  annio semestre   idioma  \\\n",
       "0    None     53  196-204   2010     None  Spanish   \n",
       "\n",
       "                      tipoRevista clasificacionColciencias proyectoAsociado  \n",
       "0  Revista Internacional Indexada                       A1             None  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udea[cls][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "udea[cls].to_json('udea.json',orient='records',force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=pd.read_json('udea.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"udea.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTA\n",
    "También se ha añadido \n",
    "* `departamento`: Dependencia de la Facultad a la que está adscrito el profesor"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "merge.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
